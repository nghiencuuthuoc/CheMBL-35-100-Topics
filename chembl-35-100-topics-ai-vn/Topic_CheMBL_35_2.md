# PharmApp Suite
## üß† AI for Drug Discovery and Development üß™
| Copyright 2025 | Nghi√™n C·ª©u Thu·ªëc | www.nghiencuuthuoc.com | Zalo: +84888999311 |

üß© Topic: D·ª± ƒëo√°n ho·∫°t t√≠nh sinh h·ªçc t·ª´ c√°c ƒë·∫∑c tr∆∞ng ph√¢n t·ª≠
---
Tuy·ªát v·ªùi! D·ª± √°n ph√¢n t√≠ch d·ªØ li·ªáu ChEMBL 35 k·∫øt h·ª£p RDKit l√† m·ªôt h∆∞·ªõng ƒëi r·∫•t ti·ªÅm nƒÉng trong nghi√™n c·ª©u v√† ph√°t tri·ªÉn thu·ªëc. D∆∞·ªõi ƒë√¢y l√† ph√¢n t√≠ch chi ti·∫øt, h∆∞·ªõng d·∫´n song ng·ªØ v√† code m·∫´u ƒë·ªÉ b·∫°n tham kh·∫£o, t·∫≠p trung v√†o ch·ªß ƒë·ªÅ "Topic_CheMBL_35_2":

**1. Ph√¢n t√≠ch m√¥ h√¨nh ph√¢n t√≠ch (Analysis of the Analysis Model)**

Ch·ªß ƒë·ªÅ "Topic_CheMBL_35_2" c√≥ th·ªÉ t·∫≠p trung v√†o nhi·ªÅu kh√≠a c·∫°nh kh√°c nhau c·ªßa d·ªØ li·ªáu ChEMBL 35. ƒê·ªÉ ƒë∆∞a ra m·ªôt m√¥ h√¨nh ph√¢n t√≠ch c·ª• th·ªÉ, ch√∫ng ta c·∫ßn x√°c ƒë·ªãnh c√¢u h·ªèi nghi√™n c·ª©u (research question) m√† b·∫°n mu·ªën tr·∫£ l·ªùi. D∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë g·ª£i √Ω v√† h∆∞·ªõng ti·∫øp c·∫≠n:

*   **D·ª± ƒëo√°n ho·∫°t t√≠nh (Activity Prediction):** X√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n ho·∫°t t√≠nh c·ªßa c√°c h·ª£p ch·∫•t d·ª±a tr√™n c·∫•u tr√∫c h√≥a h·ªçc c·ªßa ch√∫ng.
    *   **Ph√¢n t√≠ch:** S·ª≠ d·ª•ng c√°c descriptor h√≥a h·ªçc (t√≠nh ch·∫•t v·∫≠t l√Ω, h√≥a h·ªçc) ƒë∆∞·ª£c t√≠nh to√°n t·ª´ c·∫•u tr√∫c (v√≠ d·ª•: MW, cLogP, HBA, HBD) l√†m ƒë·∫ßu v√†o cho c√°c m√¥ h√¨nh machine learning (v√≠ d·ª•: Random Forest, Support Vector Machine, Neural Networks).
    *   **M·ª•c ti√™u:** X√°c ƒë·ªãnh c√°c y·∫øu t·ªë c·∫•u tr√∫c quan tr·ªçng ·∫£nh h∆∞·ªüng ƒë·∫øn ho·∫°t t√≠nh v√† d·ª± ƒëo√°n ho·∫°t t√≠nh c·ªßa c√°c h·ª£p ch·∫•t m·ªõi.
*   **Ph√¢n c·ª•m h·ª£p ch·∫•t (Compound Clustering):** Ph√¢n nh√≥m c√°c h·ª£p ch·∫•t c√≥ c·∫•u tr√∫c v√†/ho·∫∑c ho·∫°t t√≠nh t∆∞∆°ng t·ª± nhau.
    *   **Ph√¢n t√≠ch:** S·ª≠ d·ª•ng c√°c thu·∫≠t to√°n clustering (v√≠ d·ª•: k-means, hierarchical clustering) d·ª±a tr√™n c√°c descriptor h√≥a h·ªçc ho·∫∑c fingerprint c·∫•u tr√∫c.
    *   **M·ª•c ti√™u:** T√¨m ki·∫øm c√°c scaffold (khung c·∫•u tr√∫c) ph·ªï bi·∫øn, x√°c ƒë·ªãnh c√°c "druglike" compound v√† kh√°m ph√° kh√¥ng gian h√≥a h·ªçc.
*   **Ph√¢n t√≠ch m·ªëi quan h·ªá c·∫•u tr√∫c-ho·∫°t t√≠nh (Structure-Activity Relationship - SAR):** Nghi√™n c·ª©u m·ªëi li√™n h·ªá gi·ªØa c·∫•u tr√∫c h√≥a h·ªçc v√† ho·∫°t t√≠nh sinh h·ªçc c·ªßa c√°c h·ª£p ch·∫•t.
    *   **Ph√¢n t√≠ch:** S·ª≠ d·ª•ng c√°c ph∆∞∆°ng ph√°p th·ªëng k√™ v√† machine learning ƒë·ªÉ x√°c ƒë·ªãnh c√°c nh√≥m th·∫ø (substituents) quan tr·ªçng ·∫£nh h∆∞·ªüng ƒë·∫øn ho·∫°t t√≠nh.
    *   **M·ª•c ti√™u:** T·ªëi ∆∞u h√≥a c·∫•u tr√∫c c·ªßa c√°c h·ª£p ch·∫•t ƒë·ªÉ tƒÉng c∆∞·ªùng ho·∫°t t√≠nh mong mu·ªën.
*   **Ph√¢n t√≠ch c√°c ƒë·∫∑c t√≠nh d∆∞·ª£c ƒë·ªông h·ªçc (ADMET Prediction):** D·ª± ƒëo√°n c√°c ƒë·∫∑c t√≠nh h·∫•p th·ª•, ph√¢n b·ªë, chuy·ªÉn h√≥a v√† th·∫£i tr·ª´ (ADMET) c·ªßa c√°c h·ª£p ch·∫•t.
    *   **Ph√¢n t√≠ch:** S·ª≠ d·ª•ng c√°c m√¥ h√¨nh QSAR (Quantitative Structure-Activity Relationship) ƒë·ªÉ d·ª± ƒëo√°n c√°c ƒë·∫∑c t√≠nh ADMET d·ª±a tr√™n c·∫•u tr√∫c h√≥a h·ªçc.
    *   **M·ª•c ti√™u:** L·ªçc c√°c h·ª£p ch·∫•t c√≥ ƒë·∫∑c t√≠nh ADMET kh√¥ng ph√π h·ª£p trong giai ƒëo·∫°n ƒë·∫ßu c·ªßa qu√° tr√¨nh ph√°t tri·ªÉn thu·ªëc.

**2. H∆∞·ªõng d·∫´n song ng·ªØ (Bilingual Instructions)**

D∆∞·ªõi ƒë√¢y l√† h∆∞·ªõng d·∫´n chi ti·∫øt cho t·ª´ng b∆∞·ªõc th·ª±c hi·ªán, k√®m theo gi·∫£i th√≠ch b·∫±ng c·∫£ ti·∫øng Anh v√† ti·∫øng Vi·ªát:

**B∆∞·ªõc 1: Truy v·∫•n d·ªØ li·ªáu t·ª´ ChEMBL 35 (Querying Data from ChEMBL 35)**

*   **Ti·∫øng Anh:** Use PostgreSQL (psql) via pgAdmin to extract relevant data from the ChEMBL 35 database. Store the results in CSV files in the `../data/` directory.
*   **Ti·∫øng Vi·ªát:** S·ª≠ d·ª•ng PostgreSQL (psql) th√¥ng qua pgAdmin ƒë·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu li√™n quan t·ª´ c∆° s·ªü d·ªØ li·ªáu ChEMBL 35. L∆∞u k·∫øt qu·∫£ v√†o c√°c file CSV trong th∆∞ m·ª•c `../data/`.

**B∆∞·ªõc 3: X·ª≠ l√Ω d·ªØ li·ªáu v√† x√¢y d·ª±ng m√¥ h√¨nh (Data Processing and Model Building)**

*   **Ti·∫øng Anh:** Use Jupyter Notebook with Python and RDKit to process the data, calculate molecular descriptors, and build machine learning models.
*   **Ti·∫øng Vi·ªát:** S·ª≠ d·ª•ng Jupyter Notebook v·ªõi Python v√† RDKit ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu, t√≠nh to√°n c√°c descriptor ph√¢n t·ª≠ v√† x√¢y d·ª±ng c√°c m√¥ h√¨nh machine learning.

**B∆∞·ªõc 4: ƒê√°nh gi√° v√† gi·∫£i th√≠ch m√¥ h√¨nh (Model Evaluation and Interpretation)**

*   **Ti·∫øng Anh:** Evaluate the performance of the models using appropriate metrics (e.g., AUC, RMSE, R-squared). Interpret the results to gain insights into the SAR or other relationships.
*   **Ti·∫øng Vi·ªát:** ƒê√°nh gi√° hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c ch·ªâ s·ªë ph√π h·ª£p (v√≠ d·ª•: AUC, RMSE, R-squared). Gi·∫£i th√≠ch k·∫øt qu·∫£ ƒë·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ SAR ho·∫∑c c√°c m·ªëi quan h·ªá kh√°c.

**3. Code m·∫´u (Code Examples)**

D∆∞·ªõi ƒë√¢y l√† 5 v√≠ d·ª• code m·∫´u, bao g·ªìm c·∫£ SQL v√† Python, minh h·ªça c√°c b∆∞·ªõc kh√°c nhau trong quy tr√¨nh ph√¢n t√≠ch:

**V√≠ d·ª• 1: SQL - Tr√≠ch xu·∫•t d·ªØ li·ªáu ho·∫°t t√≠nh (Extract Activity Data)**

```sql
-- English
-- Extracting activity data for a specific target (e.g., target_chembl_id = 'CHEMBL205')
SELECT
    act.molregno,
    act.standard_value,
    act.standard_units,
    act.standard_type,
    md.chembl_id
FROM
    activities act
JOIN
    molecule_dictionary md ON act.molregno = md.molregno
WHERE
    act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.relation = '='
    AND act.target_chembl_id = 'CHEMBL205'
    AND act.standard_value IS NOT NULL
    AND act.standard_value > 0
    AND act.standard_value ~ '^[0-9\.]+$' --Fix l·ªói a
LIMIT 100;

-- Vietnamese
-- Tr√≠ch xu·∫•t d·ªØ li·ªáu ho·∫°t t√≠nh cho m·ªôt m·ª•c ti√™u c·ª• th·ªÉ (v√≠ d·ª•: target_chembl_id = 'CHEMBL205')
SELECT
    act.molregno,
    act.standard_value,
    act.standard_units,
    act.standard_type,
    md.chembl_id
FROM
    activities act
JOIN
    molecule_dictionary md ON act.molregno = md.molregno
WHERE
    act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.relation = '='
    AND act.target_chembl_id = 'CHEMBL205'
    AND act.standard_value IS NOT NULL
    AND act.standard_value > 0
    AND act.standard_value ~ '^[0-9\.]+$' --Fix l·ªói a
LIMIT 100;
```

**V√≠ d·ª• 2: Python - ƒê·ªçc d·ªØ li·ªáu t·ª´ CSV v√† t√≠nh to√°n descriptor (Read CSV Data and Calculate Descriptors)**

```python
# English
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors

# Define the base path
base_path = "."  # Replace with your actual base path

# Construct the file path
csv_file_path = os.path.join(base_path, "data", "activity_data.csv")

# Read the CSV file
df = pd.read_csv(csv_file_path)

# Function to calculate molecular weight
def calculate_mw(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.MolWt(mol)
    else:
        return None

# Apply the function to create a new column
df['molecular_weight'] = df['canonical_smiles'].apply(calculate_mw)

# Print the first few rows with the new descriptor
print(df.head())

# Vietnamese
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import os

# ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n g·ªëc
base_path = "."  # Thay th·∫ø b·∫±ng ƒë∆∞·ªùng d·∫´n g·ªëc th·ª±c t·∫ø c·ªßa b·∫°n

# T·∫°o ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn file CSV
csv_file_path = os.path.join(base_path, "data", "activity_data.csv")


# ƒê·ªçc file CSV
df = pd.read_csv(csv_file_path)

# H√†m t√≠nh to√°n kh·ªëi l∆∞·ª£ng ph√¢n t·ª≠
def calculate_mw(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.MolWt(mol)
    else:
        return None

# √Åp d·ª•ng h√†m ƒë·ªÉ t·∫°o m·ªôt c·ªôt m·ªõi
df['molecular_weight'] = df['canonical_smiles'].apply(calculate_mw)

# In ra m·ªôt v√†i d√≤ng ƒë·∫ßu ti√™n v·ªõi descriptor m·ªõi
print(df.head())
```

**V√≠ d·ª• 3: Python - X√¢y d·ª±ng m√¥ h√¨nh Random Forest (Build Random Forest Model)**

```python
# English
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Assuming you have 'molecular_weight' and 'standard_value' columns
# Prepare data
df = df.dropna(subset=['molecular_weight', 'standard_value']) # Drop rows with missing values
X = df[['molecular_weight']]  # Features
y = np.log10(df['standard_value'])  # Target variable (log transformed)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Evaluate model
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')

# Vietnamese
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Gi·∫£ s·ª≠ b·∫°n c√≥ c√°c c·ªôt 'molecular_weight' v√† 'standard_value'
# Chu·∫©n b·ªã d·ªØ li·ªáu
df = df.dropna(subset=['molecular_weight', 'standard_value']) # Lo·∫°i b·ªè c√°c d√≤ng c√≥ gi√° tr·ªã b·ªã thi·∫øu
X = df[['molecular_weight']]  # C√°c ƒë·∫∑c tr∆∞ng
y = np.log10(df['standard_value'])  # Bi·∫øn m·ª•c ti√™u (ƒë√£ ƒë∆∞·ª£c logarit h√≥a)

# Chia d·ªØ li·ªáu
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Hu·∫•n luy·ªán m√¥ h√¨nh
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# ƒê√°nh gi√° m√¥ h√¨nh
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')
```

**V√≠ d·ª• 4: Python - Ph√¢n c·ª•m K-means (K-means Clustering)**

```python
# English
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Prepare data - using molecular weight and logP as example features
df = df.dropna(subset=['molecular_weight', 'alogp'])  # Drop rows with missing values
X = df[['molecular_weight', 'alogp']]

# Scale the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Determine optimal number of clusters using the Elbow method
inertia = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, random_state=42, 
                    n_init='auto')  # Explicitly set n_init
    kmeans.fit(X_scaled)
    inertia.append(kmeans.inertia_)

# Plot the Elbow method graph
plt.plot(range(1, 11), inertia, marker='o')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.show()

# Apply K-means clustering
kmeans = KMeans(n_clusters=3, random_state=42, 
                n_init='auto')  # Explicitly set n_init
df['cluster'] = kmeans.fit_predict(X_scaled)

print(df[['chembl_id', 'cluster']].head())

# Vietnamese
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Chu·∫©n b·ªã d·ªØ li·ªáu - s·ª≠ d·ª•ng kh·ªëi l∆∞·ª£ng ph√¢n t·ª≠ v√† logP l√†m v√≠ d·ª•
df = df.dropna(subset=['molecular_weight', 'alogp'])  # Lo·∫°i b·ªè c√°c d√≤ng c√≥ gi√° tr·ªã b·ªã thi·∫øu
X = df[['molecular_weight', 'alogp']]

# Chu·∫©n h√≥a d·ªØ li·ªáu
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# X√°c ƒë·ªãnh s·ªë l∆∞·ª£ng cluster t·ªëi ∆∞u b·∫±ng ph∆∞∆°ng ph√°p Elbow
inertia = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, random_state=42, 
                    n_init='auto')  # Explicitly set n_init
    kmeans.fit(X_scaled)
    inertia.append(kmeans.inertia_)

# V·∫Ω bi·ªÉu ƒë·ªì Elbow method
plt.plot(range(1, 11), inertia, marker='o')
plt.title('Ph∆∞∆°ng ph√°p Elbow ƒë·ªÉ t√¨m k t·ªëi ∆∞u')
plt.xlabel('S·ªë l∆∞·ª£ng Cluster')
plt.ylabel('Inertia')
plt.show()

# √Åp d·ª•ng ph√¢n c·ª•m K-means
kmeans = KMeans(n_clusters=3, random_state=42, 
                n_init='auto')  # Explicitly set n_init
df['cluster'] = kmeans.fit_predict(X_scaled)

print(df[['chembl_id', 'cluster']].head())
```

**V√≠ d·ª• 5: Python - Ph√¢n t√≠ch SAR ƒë∆°n gi·∫£n (Simple SAR Analysis)**

```python
# English
# Group by a specific structural feature (e.g., number of aromatic rings)
df['num_aromatic_rings'] = df['canonical_smiles'].apply(lambda x: Chem.MolFromSmiles(x).GetAromaticRingCount() if Chem.MolFromSmiles(x) else None)

# Aggregate activity values for each group
sar_analysis = df.groupby('num_aromatic_rings')['standard_value'].mean()

print(sar_analysis)

# Vietnamese
# Nh√≥m theo m·ªôt ƒë·∫∑c ƒëi·ªÉm c·∫•u tr√∫c c·ª• th·ªÉ (v√≠ d·ª•: s·ªë l∆∞·ª£ng v√≤ng th∆°m)
df['num_aromatic_rings'] = df['canonical_smiles'].apply(lambda x: Chem.MolFromSmiles(x).GetAromaticRingCount() if Chem.MolFromSmiles(x) else None)

# T√≠nh to√°n gi√° tr·ªã ho·∫°t t√≠nh trung b√¨nh cho m·ªói nh√≥m
sar_analysis = df.groupby('num_aromatic_rings')['standard_value'].mean()

print(sar_analysis)
```

**L∆∞u √Ω quan tr·ªçng:**

*   **L·ªói a (Error a):** L·ªói "operator does not exist: numeric ~ unknown" x·∫£y ra do b·∫°n ƒëang c·ªë g·∫Øng so s√°nh m·ªôt c·ªôt ki·ªÉu s·ªë (numeric) v·ªõi m·ªôt chu·ªói (unknown). ƒê·ªÉ kh·∫Øc ph·ª•c, h√£y ƒë·∫£m b·∫£o r·∫±ng c·ªôt `act.standard_value` th·ª±c s·ª± l√† ki·ªÉu s·ªë. N·∫øu kh√¥ng, b·∫°n c√≥ th·ªÉ √©p ki·ªÉu n√≥ ho·∫∑c s·ª≠ d·ª•ng m·ªôt h√†m kh√°c ƒë·ªÉ ki·ªÉm tra xem gi√° tr·ªã c√≥ ph·∫£i l√† s·ªë hay kh√¥ng. V√≠ d·ª•: `AND act.standard_value::text ~ '^[0-9\.]+$'`
*   **Phi√™n b·∫£n scikit-learn (Scikit-learn version):** N·∫øu b·∫°n ƒëang s·ª≠ d·ª•ng phi√™n b·∫£n scikit-learn c≈©, h√£y c√¢n nh·∫Øc n√¢ng c·∫•p l√™n phi√™n b·∫£n m·ªõi h∆°n ƒë·ªÉ h·ªó tr·ª£ tham s·ªë `squared=False` trong h√†m `mean_squared_error`. N·∫øu kh√¥ng th·ªÉ n√¢ng c·∫•p, b·∫°n c√≥ th·ªÉ t√≠nh cƒÉn b·∫≠c hai c·ªßa MSE ƒë·ªÉ c√≥ ƒë∆∞·ª£c RMSE (Root Mean Squared Error).
*   **ƒê∆∞·ªùng d·∫´n (Path):** Thay th·∫ø `"./data/activity_data.csv"` b·∫±ng ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø ƒë·∫øn file CSV c·ªßa b·∫°n.

Ch√∫c b·∫°n th√†nh c√¥ng v·ªõi d·ª± √°n c·ªßa m√¨nh! N·∫øu b·∫°n c√≥ b·∫•t k·ª≥ c√¢u h·ªèi n√†o kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i h·ªèi.
