# PharmApp Suite
## ðŸ§  AI for Drug Discovery and Development ðŸ§ª
| Copyright 2025 | NghiÃªn Cá»©u Thuá»‘c | www.nghiencuuthuoc.com | Zalo: +84888999311 |

ðŸ§© Topic: SÃ ng lá»c thuá»‘c tÃ¡c Ä‘á»™ng há»‡ tháº§n kinh trung Æ°Æ¡ng
---
Tuyá»‡t vá»i! TÃ´i ráº¥t vui Ä‘Æ°á»£c há»— trá»£ báº¡n trong dá»± Ã¡n phÃ¢n tÃ­ch dá»¯ liá»‡u ChEMBL 35 sá»­ dá»¥ng RDKit. Vá»›i vai trÃ² lÃ  má»™t chuyÃªn gia R&D dÆ°á»£c há»c, tÃ´i hiá»ƒu rÃµ táº§m quan trá»ng cá»§a viá»‡c phÃ¢n tÃ­ch dá»¯ liá»‡u má»™t cÃ¡ch hiá»‡u quáº£ Ä‘á»ƒ khÃ¡m phÃ¡ vÃ  phÃ¡t triá»ƒn thuá»‘c má»›i.

DÆ°á»›i Ä‘Ã¢y lÃ  phÃ¢n tÃ­ch chi tiáº¿t, hÆ°á»›ng dáº«n song ngá»¯, code máº«u SQL vÃ  Python, cÃ¹ng vá»›i 5 vÃ­ dá»¥ cá»¥ thá»ƒ, táº­p trung vÃ o viá»‡c xá»­ lÃ½ lá»—i báº¡n gáº·p pháº£i vÃ  tá»‘i Æ°u hÃ³a quy trÃ¬nh lÃ m viá»‡c theo chuáº©n AIMLOps.

**1. PhÃ¢n tÃ­ch MÃ´ hÃ¬nh PhÃ¢n tÃ­ch (Analysis Model)**

Má»¥c tiÃªu cá»§a báº¡n lÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u ChEMBL 35 Ä‘á»ƒ tÃ¬m ra cÃ¡c má»‘i tÆ°Æ¡ng quan giá»¯a cáº¥u trÃºc hÃ³a há»c cá»§a cÃ¡c há»£p cháº¥t vÃ  hoáº¡t tÃ­nh sinh há»c cá»§a chÃºng. ÄÃ¢y lÃ  má»™t bÃ i toÃ¡n QSAR (Quantitative Structure-Activity Relationship) Ä‘iá»ƒn hÃ¬nh.

**CÃ¡c bÆ°á»›c chÃ­nh trong mÃ´ hÃ¬nh phÃ¢n tÃ­ch:**

1.  **Thu tháº­p vÃ  Chuáº©n bá»‹ Dá»¯ liá»‡u (Data Acquisition and Preparation):**
    *   TrÃ­ch xuáº¥t dá»¯ liá»‡u tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u ChEMBL 35 (sá»­ dá»¥ng SQL).
    *   LÃ m sáº¡ch vÃ  tiá»n xá»­ lÃ½ dá»¯ liá»‡u (loáº¡i bá» dá»¯ liá»‡u trÃ¹ng láº·p, xá»­ lÃ½ giÃ¡ trá»‹ thiáº¿u, chuáº©n hÃ³a Ä‘Æ¡n vá»‹).
2.  **TÃ­nh toÃ¡n Äáº·c trÆ°ng PhÃ¢n tá»­ (Molecular Feature Calculation):**
    *   Sá»­ dá»¥ng RDKit Ä‘á»ƒ tÃ­nh toÃ¡n cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n tá»­ (vÃ­ dá»¥: trá»ng lÆ°á»£ng phÃ¢n tá»­, logP, sá»‘ lÆ°á»£ng liÃªn káº¿t, diá»‡n tÃ­ch bá» máº·t).
3.  **Lá»±a chá»n Äáº·c trÆ°ng (Feature Selection):**
    *   Chá»n cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n tá»­ quan trá»ng nháº¥t cÃ³ liÃªn quan Ä‘áº¿n hoáº¡t tÃ­nh sinh há»c (sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p thá»‘ng kÃª hoáº·c há»c mÃ¡y).
4.  **XÃ¢y dá»±ng MÃ´ hÃ¬nh (Model Building):**
    *   XÃ¢y dá»±ng mÃ´ hÃ¬nh QSAR báº±ng cÃ¡c thuáº­t toÃ¡n há»c mÃ¡y (vÃ­ dá»¥: há»“i quy tuyáº¿n tÃ­nh, SVM, Random Forest).
5.  **ÄÃ¡nh giÃ¡ MÃ´ hÃ¬nh (Model Evaluation):**
    *   ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh trÃªn táº­p dá»¯ liá»‡u kiá»ƒm tra (sá»­ dá»¥ng cÃ¡c chá»‰ sá»‘ nhÆ° R-squared, RMSE, AUC).
6.  **Diá»…n giáº£i MÃ´ hÃ¬nh (Model Interpretation):**
    *   Diá»…n giáº£i mÃ´ hÃ¬nh Ä‘á»ƒ hiá»ƒu cÃ¡c yáº¿u tá»‘ cáº¥u trÃºc nÃ o áº£nh hÆ°á»Ÿng Ä‘áº¿n hoáº¡t tÃ­nh sinh há»c.

**2. HÆ°á»›ng dáº«n Song ngá»¯ (Bilingual Guide)**

*   **Data Extraction (TrÃ­ch xuáº¥t dá»¯ liá»‡u):** Use SQL queries to extract relevant data from the ChEMBL database.
    *   Sá»­ dá»¥ng truy váº¥n SQL Ä‘á»ƒ trÃ­ch xuáº¥t dá»¯ liá»‡u liÃªn quan tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u ChEMBL.
*   **Data Cleaning (LÃ m sáº¡ch dá»¯ liá»‡u):** Remove duplicates, handle missing values, and standardize units.
    *   Loáº¡i bá» dá»¯ liá»‡u trÃ¹ng láº·p, xá»­ lÃ½ giÃ¡ trá»‹ thiáº¿u vÃ  chuáº©n hÃ³a Ä‘Æ¡n vá»‹.
*   **Feature Calculation (TÃ­nh toÃ¡n Ä‘áº·c trÆ°ng):** Use RDKit to calculate molecular descriptors (e.g., molecular weight, logP).
    *   Sá»­ dá»¥ng RDKit Ä‘á»ƒ tÃ­nh toÃ¡n cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n tá»­ (vÃ­ dá»¥: trá»ng lÆ°á»£ng phÃ¢n tá»­, logP).
*   **Model Building (XÃ¢y dá»±ng mÃ´ hÃ¬nh):** Train machine learning models to predict biological activity.
    *   XÃ¢y dá»±ng mÃ´ hÃ¬nh há»c mÃ¡y Ä‘á»ƒ dá»± Ä‘oÃ¡n hoáº¡t tÃ­nh sinh há»c.
*   **Model Evaluation (ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh):** Evaluate model performance using appropriate metrics (e.g., R-squared, RMSE).
    *   ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh báº±ng cÃ¡c chá»‰ sá»‘ phÃ¹ há»£p (vÃ­ dá»¥: R-squared, RMSE).

**3. Code SQL vÃ  Python (SQL and Python Code)**

**SQL (Ä‘á»ƒ trÃ­ch xuáº¥t dá»¯ liá»‡u):**

```sql
-- English
-- Extract 100 data from chembl_35
SELECT
    act.molregno,
    act.standard_value,
    act.standard_units,
    act.assay_id,
    md.molfile
FROM
    activities act
JOIN
    molecule_dictionary md ON act.molregno = md.molregno
WHERE
    act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.standard_value IS NOT NULL
    AND act.standard_value > 0
    AND act.standard_value < 10000 -- Filter values
    --AND act.standard_value ~ '^[0-9\.]+$'  -- Removed this line because it causes errors
LIMIT 100;
```

```sql
-- Vietnamese
-- TrÃ­ch xuáº¥t 100 dÃ²ng dá»¯ liá»‡u tá»« chembl_35
SELECT
    act.molregno,
    act.standard_value,
    act.standard_units,
    act.assay_id,
    md.molfile
FROM
    activities act
JOIN
    molecule_dictionary md ON act.molregno = md.molregno
WHERE
    act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.standard_value IS NOT NULL
    AND act.standard_value > 0
    AND act.standard_value < 10000 -- Lá»c giÃ¡ trá»‹
    --AND act.standard_value ~ '^[0-9\.]+$'  -- ÄÃ£ xÃ³a dÃ²ng nÃ y vÃ¬ gÃ¢y ra lá»—i
LIMIT 100;
```

**LÃ½ do loáº¡i bá» `act.standard_value ~ '^[0-9\.]+$'`:** Lá»—i `operator does not exist: numeric ~ unknown` xáº£y ra vÃ¬ toÃ¡n tá»­ `~` Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ so sÃ¡nh chuá»—i vá»›i regular expression, nhÆ°ng `act.standard_value` lÃ  kiá»ƒu sá»‘ (numeric). Äá»ƒ kháº¯c phá»¥c, báº¡n cÃ³ thá»ƒ bá» qua Ä‘iá»u kiá»‡n nÃ y (náº¿u báº¡n cháº¯c cháº¯n ráº±ng dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÃ m sáº¡ch) hoáº·c chuyá»ƒn Ä‘á»•i `act.standard_value` thÃ nh kiá»ƒu chuá»—i trÆ°á»›c khi so sÃ¡nh (nhÆ°ng Ä‘iá»u nÃ y cÃ³ thá»ƒ khÃ´ng cáº§n thiáº¿t).

**Python (sá»­ dá»¥ng RDKit):**

```python
# English
import os
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# Define base path
base_path = "../data"

# Load data from CSV
csv_file = "chembl_35_data.csv"  # Replace with your actual file name
data = pd.read_csv(os.path.join(base_path, csv_file))

# Handle missing molfile values
data = data.dropna(subset=['molfile'])

# Function to calculate molecular descriptors
def calculate_descriptors(molfile):
    mol = Chem.MolFromMolBlock(molfile)
    if mol is None:
        return None
    descriptors = {}
    descriptors['MW'] = Descriptors.MolWt(mol)
    descriptors['LogP'] = Chem.Crippen.MolLogP(mol)
    descriptors['HBD'] = Chem.Lipinski.NumHDonors(mol)
    descriptors['HBA'] = Chem.Lipinski.NumHAcceptors(mol)
    return descriptors

# Apply descriptor calculation
data['descriptors'] = data['molfile'].apply(calculate_descriptors)
data = data.dropna(subset=['descriptors'])

# Convert descriptors to DataFrame
data = pd.concat([data.drop(['descriptors'], axis=1), data['descriptors'].apply(pd.Series)], axis=1)

# Convert standard_value to numeric, handling errors
data['standard_value'] = pd.to_numeric(data['standard_value'], errors='coerce')
data = data.dropna(subset=['standard_value'])

# Prepare data for modeling
X = data[['MW', 'LogP', 'HBD', 'HBA']]  # Use selected descriptors
y = np.log10(data['standard_value'])  # log transform target variable

# Data scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train a linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

```python
# Vietnamese
import os
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# Äá»‹nh nghÄ©a Ä‘Æ°á»ng dáº«n gá»‘c
base_path = "../data"

# Táº£i dá»¯ liá»‡u tá»« file CSV
csv_file = "chembl_35_data.csv"  # Thay tháº¿ báº±ng tÃªn file cá»§a báº¡n
data = pd.read_csv(os.path.join(base_path, csv_file))

# Xá»­ lÃ½ giÃ¡ trá»‹ molfile bá»‹ thiáº¿u
data = data.dropna(subset=['molfile'])

# HÃ m tÃ­nh toÃ¡n cÃ¡c descriptor phÃ¢n tá»­
def calculate_descriptors(molfile):
    mol = Chem.MolFromMolBlock(molfile)
    if mol is None:
        return None
    descriptors = {}
    descriptors['MW'] = Descriptors.MolWt(mol)
    descriptors['LogP'] = Chem.Crippen.MolLogP(mol)
    descriptors['HBD'] = Chem.Lipinski.NumHDonors(mol)
    descriptors['HBA'] = Chem.Lipinski.NumHAcceptors(mol)
    return descriptors

# Ãp dá»¥ng tÃ­nh toÃ¡n descriptor
data['descriptors'] = data['molfile'].apply(calculate_descriptors)
data = data.dropna(subset=['descriptors'])

# Chuyá»ƒn Ä‘á»•i descriptor thÃ nh DataFrame
data = pd.concat([data.drop(['descriptors'], axis=1), data['descriptors'].apply(pd.Series)], axis=1)

# Chuyá»ƒn Ä‘á»•i standard_value sang kiá»ƒu sá»‘, xá»­ lÃ½ lá»—i
data['standard_value'] = pd.to_numeric(data['standard_value'], errors='coerce')
data = data.dropna(subset=['standard_value'])

# Chuáº©n bá»‹ dá»¯ liá»‡u cho mÃ´ hÃ¬nh
X = data[['MW', 'LogP', 'HBD', 'HBA']]  # Sá»­ dá»¥ng cÃ¡c descriptor Ä‘Ã£ chá»n
y = np.log10(data['standard_value'])  # log transform biáº¿n má»¥c tiÃªu

# Chuáº©n hÃ³a dá»¯ liá»‡u
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Chia dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n vÃ  kiá»ƒm tra
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Huáº¥n luyá»‡n mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh
model = LinearRegression()
model.fit(X_train, y_train)

# Dá»± Ä‘oÃ¡n
y_pred = model.predict(X_test)

# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

**4. VÃ­ dá»¥ Code (Code Examples)**

**VÃ­ dá»¥ 1: TÃ­nh toÃ¡n nhiá»u descriptor hÆ¡n (Calculating More Descriptors)**

**SQL:** (KhÃ´ng thay Ä‘á»•i)

**Python:**

```python
# English
from rdkit.Chem import AllChem

def calculate_descriptors(molfile):
    mol = Chem.MolFromMolBlock(molfile)
    if mol is None:
        return None
    descriptors = {}
    descriptors['MW'] = Descriptors.MolWt(mol)
    descriptors['LogP'] = Chem.Crippen.MolLogP(mol)
    descriptors['HBD'] = Chem.Lipinski.NumHDonors(mol)
    descriptors['HBA'] = Chem.Lipinski.NumHAcceptors(mol)
    descriptors['TPSA'] = Chem.QED.properties(mol).PSA
    descriptors['RotatableBonds'] = Chem.Lipinski.NumRotatableBonds(mol)
    return descriptors
```

```python
# Vietnamese
from rdkit.Chem import AllChem

def calculate_descriptors(molfile):
    mol = Chem.MolFromMolBlock(molfile)
    if mol is None:
        return None
    descriptors = {}
    descriptors['MW'] = Descriptors.MolWt(mol)
    descriptors['LogP'] = Chem.Crippen.MolLogP(mol)
    descriptors['HBD'] = Chem.Lipinski.NumHDonors(mol)
    descriptors['HBA'] = Chem.Lipinski.NumHAcceptors(mol)
    descriptors['TPSA'] = Chem.QED.properties(mol).PSA
    descriptors['RotatableBonds'] = Chem.Lipinski.NumRotatableBonds(mol)
    return descriptors
```

**VÃ­ dá»¥ 2: Sá»­ dá»¥ng Random Forest (Using Random Forest)**

**SQL:** (KhÃ´ng thay Ä‘á»•i)

**Python:**

```python
# English
from sklearn.ensemble import RandomForestRegressor

# Train a Random Forest model
model = RandomForestRegressor(n_estimators=100, random_state=42) # you can adjust the hyperparameters of the model, such as n_estimators.
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

```python
# Vietnamese
from sklearn.ensemble import RandomForestRegressor

# Huáº¥n luyá»‡n mÃ´ hÃ¬nh Random Forest
model = RandomForestRegressor(n_estimators=100, random_state=42) # Báº¡n cÃ³ thá»ƒ Ä‘iá»u chá»‰nh cÃ¡c siÃªu tham sá»‘ cá»§a mÃ´ hÃ¬nh, cháº³ng háº¡n nhÆ° n_estimators.
model.fit(X_train, y_train)

# Dá»± Ä‘oÃ¡n
y_pred = model.predict(X_test)

# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

**VÃ­ dá»¥ 3: Feature Selection (Lá»±a chá»n Äáº·c trÆ°ng)**

**SQL:** (KhÃ´ng thay Ä‘á»•i)

**Python:**

```python
# English
from sklearn.feature_selection import SelectKBest, f_regression

# Feature selection using SelectKBest
selector = SelectKBest(score_func=f_regression, k=3)
X_new = selector.fit_transform(X_scaled, y)

# Get the selected features
selected_features = X.columns[selector.get_support()]
print("Selected Features:", selected_features)

# Split data into training and testing sets using selected features
X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)

# Train a linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

```python
# Vietnamese
from sklearn.feature_selection import SelectKBest, f_regression

# Lá»±a chá»n Ä‘áº·c trÆ°ng sá»­ dá»¥ng SelectKBest
selector = SelectKBest(score_func=f_regression, k=3)
X_new = selector.fit_transform(X_scaled, y)

# Láº¥y cÃ¡c Ä‘áº·c trÆ°ng Ä‘Ã£ chá»n
selected_features = X.columns[selector.get_support()]
print("Selected Features:", selected_features)

# Chia dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n vÃ  kiá»ƒm tra sá»­ dá»¥ng cÃ¡c Ä‘áº·c trÆ°ng Ä‘Ã£ chá»n
X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)

# Huáº¥n luyá»‡n mÃ´ hÃ¬nh há»“i quy tuyáº¿n tÃ­nh
model = LinearRegression()
model.fit(X_train, y_train)

# Dá»± Ä‘oÃ¡n
y_pred = model.predict(X_test)

# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

**VÃ­ dá»¥ 4: LÆ°u MÃ´ hÃ¬nh (Saving the Model)**

**SQL:** (KhÃ´ng thay Ä‘á»•i)

**Python:**

```python
# English
import joblib

# Train your model (e.g., Linear Regression)
model = LinearRegression()
model.fit(X_train, y_train)

# Save the model to a file
model_filename = "linear_regression_model.pkl"
joblib.dump(model, os.path.join(base_path, model_filename))

print(f"Model saved to {os.path.join(base_path, model_filename)}")

# Load the model from the file
loaded_model = joblib.load(os.path.join(base_path, model_filename))

# Use the loaded model to make predictions
y_pred = loaded_model.predict(X_test)
```

```python
# Vietnamese
import joblib

# Huáº¥n luyá»‡n mÃ´ hÃ¬nh cá»§a báº¡n (vÃ­ dá»¥: Há»“i quy tuyáº¿n tÃ­nh)
model = LinearRegression()
model.fit(X_train, y_train)

# LÆ°u mÃ´ hÃ¬nh vÃ o má»™t file
model_filename = "linear_regression_model.pkl"
joblib.dump(model, os.path.join(base_path, model_filename))

print(f"MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o {os.path.join(base_path, model_filename)}")

# Táº£i mÃ´ hÃ¬nh tá»« file
loaded_model = joblib.load(os.path.join(base_path, model_filename))

# Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Ã£ táº£i Ä‘á»ƒ dá»± Ä‘oÃ¡n
y_pred = loaded_model.predict(X_test)
```

**VÃ­ dá»¥ 5: Sá»­ dá»¥ng mÃ´ hÃ¬nh SVM (Support Vector Machine)**

**SQL:** (KhÃ´ng thay Ä‘á»•i)

**Python:**
```python
#English
from sklearn.svm import SVR

# Train the SVM model
model = SVR(kernel='linear')  # You can also use other kernels like 'rbf', 'poly', etc.
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

```python
#Vietnamese
from sklearn.svm import SVR

# Huáº¥n luyá»‡n mÃ´ hÃ¬nh SVM
model = SVR(kernel='linear')  # Báº¡n cÅ©ng cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c kernel khÃ¡c nhÆ° 'rbf', 'poly', vv.
model.fit(X_train, y_train)

# Dá»± Ä‘oÃ¡n
y_pred = model.predict(X_test)

# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

**LÆ°u Ã½ quan trá»ng:**

*   **PhiÃªn báº£n Scikit-learn:** Äáº£m báº£o báº¡n Ä‘ang sá»­ dá»¥ng phiÃªn báº£n Scikit-learn má»›i nháº¥t Ä‘á»ƒ há»— trá»£ tham sá»‘ `squared=False` trong hÃ m `mean_squared_error`. Náº¿u khÃ´ng, hÃ£y loáº¡i bá» tham sá»‘ nÃ y. Trong cÃ¡c phiÃªn báº£n má»›i, `squared=False` khÃ´ng cÃ²n cáº§n thiáº¿t vÃ  máº·c Ä‘á»‹nh tráº£ vá» RMSE (Root Mean Squared Error).
*   **ÄÆ°á»ng dáº«n:** Sá»­ dá»¥ng `os.path.join(base_path, filename)` Ä‘á»ƒ Ä‘áº£m báº£o tÃ­nh di Ä‘á»™ng cá»§a code.
*   **Xá»­ lÃ½ lá»—i:** LuÃ´n kiá»ƒm tra vÃ  xá»­ lÃ½ cÃ¡c lá»—i cÃ³ thá»ƒ xáº£y ra trong quÃ¡ trÃ¬nh tÃ­nh toÃ¡n Ä‘áº·c trÆ°ng vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh.
*   **Chuáº©n hÃ³a dá»¯ liá»‡u:** Chuáº©n hÃ³a dá»¯ liá»‡u trÆ°á»›c khi Ä‘Æ°a vÃ o mÃ´ hÃ¬nh há»c mÃ¡y Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t.
*   **Lá»±a chá»n mÃ´ hÃ¬nh:** Thá»­ nghiá»‡m vá»›i nhiá»u mÃ´ hÃ¬nh há»c mÃ¡y khÃ¡c nhau Ä‘á»ƒ tÃ¬m ra mÃ´ hÃ¬nh tá»‘t nháº¥t cho bÃ i toÃ¡n cá»§a báº¡n.
*   **LÆ°u trá»¯ dá»¯ liá»‡u:** LÆ°u trá»¯ dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ vÃ  mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng vÃ  so sÃ¡nh.

Hy vá»ng nhá»¯ng hÆ°á»›ng dáº«n vÃ  vÃ­ dá»¥ nÃ y sáº½ giÃºp báº¡n hoÃ n thÃ nh dá»± Ã¡n phÃ¢n tÃ­ch dá»¯ liá»‡u ChEMBL 35 má»™t cÃ¡ch hiá»‡u quáº£! Náº¿u báº¡n cÃ³ báº¥t ká»³ cÃ¢u há»i nÃ o khÃ¡c, Ä‘á»«ng ngáº§n ngáº¡i há»i.
