# PharmApp Suite
## üß† AI for Drug Discovery and Development üß™
| Copyright 2025 | Nghi√™n C·ª©u Thu·ªëc | www.nghiencuuthuoc.com | Zalo: +84888999311 |

üß© Topic: Ph√¢n t√≠ch thu·ªëc d√†nh cho tr·∫ª em
---
Tuy·ªát v·ªùi! D·ª± √°n ph√¢n t√≠ch d·ªØ li·ªáu ChEMBL 35 b·∫±ng RDKit l√† m·ªôt h∆∞·ªõng ƒëi r·∫•t ti·ªÅm nƒÉng trong nghi√™n c·ª©u v√† ph√°t tri·ªÉn thu·ªëc. V·ªõi vai tr√≤ l√† chuy√™n gia R&D D∆∞·ª£c h·ªçc, t√¥i s·∫Ω h·ªó tr·ª£ b·∫°n x√¢y d·ª±ng quy tr√¨nh ph√¢n t√≠ch hi·ªáu qu·∫£, kh·∫Øc ph·ª•c c√°c l·ªói v√† ƒë∆∞a ra c√°c v√≠ d·ª• code c·ª• th·ªÉ.

**T·ªïng quan v·ªÅ ch·ªß ƒë·ªÅ Topic_CheMBL_35_58**

Ch·ªß ƒë·ªÅ n√†y c√≥ v·∫ª t·∫≠p trung v√†o m·ªôt kh√≠a c·∫°nh c·ª• th·ªÉ trong ChEMBL 35, c√≥ th·ªÉ l√† m·ªôt nh√≥m h·ª£p ch·∫•t, m·ªôt lo·∫°i m·ª•c ti√™u sinh h·ªçc (target), ho·∫∑c m·ªôt t√≠nh ch·∫•t h√≥a l√Ω n√†o ƒë√≥. ƒê·ªÉ ƒë∆∞a ra ph√¢n t√≠ch ch√≠nh x√°c h∆°n, t√¥i c·∫ßn bi·∫øt t√™n ch·ªß ƒë·ªÅ ƒë·∫ßy ƒë·ªß ho·∫∑c m√¥ t·∫£ chi ti·∫øt h∆°n v·ªÅ m·ª•c ti√™u c·ªßa b·∫°n. Tuy nhi√™n, d·ª±a tr√™n th√¥ng tin b·∫°n cung c·∫•p, t√¥i s·∫Ω x√¢y d·ª±ng m·ªôt quy tr√¨nh ph√¢n t√≠ch t·ªïng qu√°t, c√≥ th·ªÉ √°p d·ª•ng v√† ƒëi·ªÅu ch·ªânh cho nhi·ªÅu ch·ªß ƒë·ªÅ kh√°c nhau trong ChEMBL 35.

**1. Ph√¢n t√≠ch m√¥ h√¨nh ph√¢n t√≠ch (Analysis Model)**

M√¥ h√¨nh ph√¢n t√≠ch c·ªßa ch√∫ng ta s·∫Ω bao g·ªìm c√°c b∆∞·ªõc sau:

1.  **Data Extraction (Tr√≠ch xu·∫•t d·ªØ li·ªáu):** S·ª≠ d·ª•ng SQL ƒë·ªÉ truy v·∫•n d·ªØ li·ªáu t·ª´ c∆° s·ªü d·ªØ li·ªáu ChEMBL 35, t·∫≠p trung v√†o c√°c b·∫£ng quan tr·ªçng nh∆∞ `activities`, `molecule_dictionary`, `compound_structures`, v√† `target_dictionary`.
2.  **Data Cleaning and Preprocessing (L√†m s·∫°ch v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu):**
    *   Lo·∫°i b·ªè c√°c gi√° tr·ªã null ho·∫∑c kh√¥ng h·ª£p l·ªá.
    *   Chu·∫©n h√≥a d·ªØ li·ªáu (v√≠ d·ª•: chuy·ªÉn ƒë·ªïi IC50, Ki v·ªÅ m·ªôt ƒë∆°n v·ªã chung).
    *   L·ªçc d·ªØ li·ªáu d·ª±a tr√™n c√°c ti√™u ch√≠ c·ª• th·ªÉ (v√≠ d·ª•: ch·ªâ gi·ªØ l·∫°i c√°c ho·∫°t ch·∫•t c√≥ IC50 < 10¬µM).
3.  **Feature Engineering (X√¢y d·ª±ng ƒë·∫∑c tr∆∞ng):** S·ª≠ d·ª•ng RDKit ƒë·ªÉ t√≠nh to√°n c√°c ƒë·∫∑c tr∆∞ng ph√¢n t·ª≠ (molecular descriptors) t·ª´ c·∫•u tr√∫c h√≥a h·ªçc c·ªßa c√°c h·ª£p ch·∫•t. C√°c ƒë·∫∑c tr∆∞ng n√†y c√≥ th·ªÉ bao g·ªìm:
    *   T√≠nh ch·∫•t v·∫≠t l√Ω (v√≠ d·ª•: LogP, MW, TPSA).
    *   H√¨nh d·∫°ng ph√¢n t·ª≠ (v√≠ d·ª•: s·ªë v√≤ng, s·ªë nh√°nh).
    *   C√°c ƒë·∫∑c tr∆∞ng d·ª±a tr√™n fingerprint (v√≠ d·ª•: Morgan fingerprint, MACCS keys).
4.  **Data Analysis and Modeling (Ph√¢n t√≠ch d·ªØ li·ªáu v√† x√¢y d·ª±ng m√¥ h√¨nh):**
    *   **Exploratory Data Analysis (EDA):** Th·ªëng k√™ m√¥ t·∫£, tr·ª±c quan h√≥a d·ªØ li·ªáu ƒë·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ ph√¢n b·ªë v√† m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn.
    *   **Machine Learning (ML):** X√¢y d·ª±ng c√°c m√¥ h√¨nh d·ª± ƒëo√°n ho·∫°t t√≠nh sinh h·ªçc (v√≠ d·ª•: s·ª≠ d·ª•ng Random Forest, Support Vector Machines) ho·∫∑c ph√¢n lo·∫°i h·ª£p ch·∫•t (v√≠ d·ª•: d·ª±a tr√™n c·∫•u tr√∫c ho·∫∑c ho·∫°t t√≠nh).
5.  **Model Evaluation and Interpretation (ƒê√°nh gi√° v√† gi·∫£i th√≠ch m√¥ h√¨nh):** ƒê√°nh gi√° hi·ªáu nƒÉng c·ªßa m√¥ h√¨nh b·∫±ng c√°c metrics ph√π h·ª£p (v√≠ d·ª•: AUC, ROC, RMSE) v√† gi·∫£i th√≠ch c√°c y·∫øu t·ªë quan tr·ªçng ·∫£nh h∆∞·ªüng ƒë·∫øn ho·∫°t t√≠nh.

**2. H∆∞·ªõng d·∫´n song ng·ªØ (Bilingual Instructions)**

D∆∞·ªõi ƒë√¢y l√† h∆∞·ªõng d·∫´n chi ti·∫øt cho t·ª´ng b∆∞·ªõc, k√®m theo gi·∫£i th√≠ch b·∫±ng c·∫£ ti·∫øng Anh v√† ti·∫øng Vi·ªát:

**Step 1: Data Extraction (Tr√≠ch xu·∫•t d·ªØ li·ªáu)**

*   **English:** Use SQL to query data from the ChEMBL 35 database, focusing on tables like `activities`, `molecule_dictionary`, `compound_structures`, and `target_dictionary`.
*   **Ti·∫øng Vi·ªát:** S·ª≠ d·ª•ng SQL ƒë·ªÉ truy v·∫•n d·ªØ li·ªáu t·ª´ c∆° s·ªü d·ªØ li·ªáu ChEMBL 35, t·∫≠p trung v√†o c√°c b·∫£ng nh∆∞ `activities`, `molecule_dictionary`, `compound_structures`, v√† `target_dictionary`.

**Step 2: Data Cleaning and Preprocessing (L√†m s·∫°ch v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu)**

*   **English:**
    *   Remove null or invalid values.
    *   Standardize data (e.g., convert IC50, Ki to a common unit).
    *   Filter data based on specific criteria (e.g., keep only compounds with IC50 < 10¬µM).
*   **Ti·∫øng Vi·ªát:**
    *   Lo·∫°i b·ªè c√°c gi√° tr·ªã null ho·∫∑c kh√¥ng h·ª£p l·ªá.
    *   Chu·∫©n h√≥a d·ªØ li·ªáu (v√≠ d·ª•: chuy·ªÉn ƒë·ªïi IC50, Ki v·ªÅ m·ªôt ƒë∆°n v·ªã chung).
    *   L·ªçc d·ªØ li·ªáu d·ª±a tr√™n c√°c ti√™u ch√≠ c·ª• th·ªÉ (v√≠ d·ª•: ch·ªâ gi·ªØ l·∫°i c√°c h·ª£p ch·∫•t c√≥ IC50 < 10¬µM).

**Step 3: Feature Engineering (X√¢y d·ª±ng ƒë·∫∑c tr∆∞ng)**

*   **English:** Use RDKit to calculate molecular descriptors from the chemical structures of the compounds. These descriptors can include:
    *   Physicochemical properties (e.g., LogP, MW, TPSA).
    *   Molecular shape (e.g., number of rings, number of branches).
    *   Fingerprint-based features (e.g., Morgan fingerprint, MACCS keys).
*   **Ti·∫øng Vi·ªát:** S·ª≠ d·ª•ng RDKit ƒë·ªÉ t√≠nh to√°n c√°c ƒë·∫∑c tr∆∞ng ph√¢n t·ª≠ t·ª´ c·∫•u tr√∫c h√≥a h·ªçc c·ªßa c√°c h·ª£p ch·∫•t. C√°c ƒë·∫∑c tr∆∞ng n√†y c√≥ th·ªÉ bao g·ªìm:
    *   T√≠nh ch·∫•t v·∫≠t l√Ω (v√≠ d·ª•: LogP, MW, TPSA).
    *   H√¨nh d·∫°ng ph√¢n t·ª≠ (v√≠ d·ª•: s·ªë v√≤ng, s·ªë nh√°nh).
    *   C√°c ƒë·∫∑c tr∆∞ng d·ª±a tr√™n fingerprint (v√≠ d·ª•: Morgan fingerprint, MACCS keys).

**Step 4: Data Analysis and Modeling (Ph√¢n t√≠ch d·ªØ li·ªáu v√† x√¢y d·ª±ng m√¥ h√¨nh)**

*   **English:**
    *   **Exploratory Data Analysis (EDA):** Descriptive statistics, data visualization to understand the distribution and relationships between variables.
    *   **Machine Learning (ML):** Build models to predict biological activity (e.g., using Random Forest, Support Vector Machines) or classify compounds (e.g., based on structure or activity).
*   **Ti·∫øng Vi·ªát:**
    *   **Exploratory Data Analysis (EDA):** Th·ªëng k√™ m√¥ t·∫£, tr·ª±c quan h√≥a d·ªØ li·ªáu ƒë·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ ph√¢n b·ªë v√† m·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn.
    *   **Machine Learning (ML):** X√¢y d·ª±ng c√°c m√¥ h√¨nh d·ª± ƒëo√°n ho·∫°t t√≠nh sinh h·ªçc (v√≠ d·ª•: s·ª≠ d·ª•ng Random Forest, Support Vector Machines) ho·∫∑c ph√¢n lo·∫°i h·ª£p ch·∫•t (v√≠ d·ª•: d·ª±a tr√™n c·∫•u tr√∫c ho·∫∑c ho·∫°t t√≠nh).

**Step 5: Model Evaluation and Interpretation (ƒê√°nh gi√° v√† gi·∫£i th√≠ch m√¥ h√¨nh)**

*   **English:** Evaluate the performance of the model using appropriate metrics (e.g., AUC, ROC, RMSE) and interpret the important factors affecting activity.
*   **Ti·∫øng Vi·ªát:** ƒê√°nh gi√° hi·ªáu nƒÉng c·ªßa m√¥ h√¨nh b·∫±ng c√°c metrics ph√π h·ª£p (v√≠ d·ª•: AUC, ROC, RMSE) v√† gi·∫£i th√≠ch c√°c y·∫øu t·ªë quan tr·ªçng ·∫£nh h∆∞·ªüng ƒë·∫øn ho·∫°t t√≠nh.

**3. Code SQL, Python (English)**

D∆∞·ªõi ƒë√¢y l√† c√°c v√≠ d·ª• code SQL v√† Python, t·∫≠p trung v√†o vi·ªác tr√≠ch xu·∫•t d·ªØ li·ªáu, x√¢y d·ª±ng ƒë·∫∑c tr∆∞ng v√† ph√¢n t√≠ch c∆° b·∫£n.

**SQL (PostgreSQL)**

```sql
-- Example 1: Extracting data for a specific target (e.g., CHEMBL205)
SELECT
    act.standard_value,
    act.standard_units,
    md.chembl_id,
    cs.canonical_smiles
FROM
    activities act
JOIN
    molecule_dictionary md ON act.molregno = md.molregno
JOIN
    compound_structures cs ON md.molregno = cs.molregno
WHERE
    act.target_chembl_id = 'CHEMBL205'  -- Replace with your target CHEMBL_ID
    AND act.standard_type = 'IC50'
    AND act.standard_relation = '='
    AND act.standard_value IS NOT NULL
    AND act.standard_value > 0
    AND act.standard_value < 10000 -- Filter IC50 values
    AND cs.canonical_smiles IS NOT NULL
LIMIT 100;

-- Example 2:  Corrected SQL to filter numeric values for standard_value
SELECT
    act.standard_value,
    act.standard_units,
    md.chembl_id,
    cs.canonical_smiles
FROM
    activities act
JOIN
    molecule_dictionary md ON act.molregno = md.molregno
JOIN
    compound_structures cs ON md.molregno = cs.molregno
WHERE
    act.target_chembl_id = 'CHEMBL205'
    AND act.standard_type = 'IC50'
    AND act.standard_relation = '='
    AND act.standard_value IS NOT NULL
    AND act.standard_value::TEXT ~ '^[0-9\.]+$'  -- Ensure standard_value is numeric
    AND act.standard_value::NUMERIC > 0
    AND act.standard_value::NUMERIC < 10000
    AND cs.canonical_smiles IS NOT NULL
LIMIT 100;

-- Example 3: Extracting data for a specific activity type (e.g., Ki)
SELECT
    act.standard_value,
    act.standard_units,
    md.chembl_id,
    cs.canonical_smiles
FROM
    activities act
JOIN
    molecule_dictionary md ON act.molregno = md.molregno
JOIN
    compound_structures cs ON md.molregno = cs.molregno
WHERE
    act.standard_type = 'Ki'
    AND act.standard_relation = '='
    AND act.standard_value IS NOT NULL
    AND act.standard_value::TEXT ~ '^[0-9\.]+$'
    AND act.standard_value::NUMERIC > 0
    AND act.standard_value::NUMERIC < 10000
    AND cs.canonical_smiles IS NOT NULL
LIMIT 100;

-- Example 4: Extracting data with specific units (e.g., nM)
SELECT
    act.standard_value,
    act.standard_units,
    md.chembl_id,
    cs.canonical_smiles
FROM
    activities act
JOIN
    molecule_dictionary md ON act.molregno = md.molregno
JOIN
    compound_structures cs ON md.molregno = cs.molregno
WHERE
    act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.standard_relation = '='
    AND act.standard_value IS NOT NULL
    AND act.standard_value::TEXT ~ '^[0-9\.]+$'
    AND act.standard_value::NUMERIC > 0
    AND act.standard_value::NUMERIC < 10000
    AND cs.canonical_smiles IS NOT NULL
LIMIT 100;

-- Example 5: Extracting data for a specific protein target type
SELECT
    act.standard_value,
    act.standard_units,
    md.chembl_id,
    cs.canonical_smiles
FROM
    activities act
JOIN
    molecule_dictionary md ON act.molregno = md.molregno
JOIN
    compound_structures cs ON md.molregno = cs.molregno
JOIN
    target_dictionary td ON act.tid = td.tid
WHERE
    td.target_type = 'PROTEIN'
    AND act.standard_type = 'IC50'
    AND act.standard_relation = '='
    AND act.standard_value IS NOT NULL
    AND act.standard_value::TEXT ~ '^[0-9\.]+$'
    AND act.standard_value::NUMERIC > 0
    AND act.standard_value::NUMERIC < 10000
    AND cs.canonical_smiles IS NOT NULL
LIMIT 100;
```

**Python (Jupyter Notebook)**

```python
import os
import pandas as pd
import psycopg2
from rdkit import Chem
from rdkit.Chem import Descriptors
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Database credentials
DB_HOST = "192.168.206.136"
DB_USER = "rd"
DB_PASS = "rd"
DB_NAME = "chembl_35"
base_path = "." # Assuming the notebook is in the root directory

# Function to connect to the database
def connect_to_db(host, user, password, database):
    conn = psycopg2.connect(host=host, user=user, password=password, database=database)
    return conn

# Function to execute SQL query and return a Pandas DataFrame
def execute_sql_query(conn, query):
    df = pd.read_sql_query(query, conn)
    return df

# Function to calculate molecular descriptors using RDKit
def calculate_descriptors(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    descriptors = {}
    descriptors['MW'] = Descriptors.MolWt(mol)
    descriptors['LogP'] = Descriptors.MolLogP(mol)
    # Add more descriptors as needed
    return descriptors

# Main function
def main():
    # Connect to the database
    conn = connect_to_db(DB_HOST, DB_USER, DB_PASS, DB_NAME)

    # SQL query to extract data
    sql_query = """
        SELECT
            act.standard_value,
            act.standard_units,
            md.chembl_id,
            cs.canonical_smiles
        FROM
            activities act
        JOIN
            molecule_dictionary md ON act.molregno = md.molregno
        JOIN
            compound_structures cs ON md.molregno = cs.molregno
        WHERE
            act.target_chembl_id = 'CHEMBL205'  -- Replace with your target CHEMBL_ID
            AND act.standard_type = 'IC50'
            AND act.standard_relation = '='
            AND act.standard_value IS NOT NULL
            AND act.standard_value::TEXT ~ '^[0-9\.]+$'  -- Ensure standard_value is numeric
            AND act.standard_value::NUMERIC > 0
            AND act.standard_value::NUMERIC < 10000
            AND cs.canonical_smiles IS NOT NULL
        LIMIT 100;
    """

    # Execute the SQL query
    df = execute_sql_query(conn, sql_query)
    conn.close()

    # Data Cleaning and Preprocessing
    df = df.dropna(subset=['canonical_smiles', 'standard_value']) # Drop rows with missing SMILES or standard_value
    df['standard_value'] = pd.to_numeric(df['standard_value']) # Ensure standard_value is numeric

    # Feature Engineering
    descriptors_list = []
    for smiles in df['canonical_smiles']:
        descriptors = calculate_descriptors(smiles)
        descriptors_list.append(descriptors)

    descriptors_df = pd.DataFrame(descriptors_list)
    df = pd.concat([df, descriptors_df], axis=1)
    df = df.dropna()  # Drop rows with missing descriptors

    # Data Analysis and Modeling
    X = df[['MW', 'LogP']]  # Features
    y = np.log10(df['standard_value'])  # Target variable (log transform for better distribution)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    # Model Evaluation
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"Mean Squared Error: {mse}")
    print(f"R-squared: {r2}")

    # Save the DataFrame to a CSV file (optional)
    output_file = os.path.join(base_path, "data", "chembl_data.csv")
    df.to_csv(output_file, index=False)
    print(f"Data saved to {output_file}")

if __name__ == "__main__":
    main()
```

**Explanation:**

*   **SQL:** The SQL query extracts `standard_value`, `standard_units`, `chembl_id`, and `canonical_smiles` for a specific target from the ChEMBL database.  The `WHERE` clause filters the data based on the target ID, activity type (IC50), relation (=), and ensures that the `standard_value` is numeric, not null, and within a reasonable range. The `LIMIT` clause restricts the output to the first 100 rows.  The corrected SQL uses `::TEXT ~ '^[0-9\.]+$'` and `::NUMERIC` to properly handle numeric filtering.
*   **Python:**
    *   The Python code connects to the ChEMBL database using the provided credentials.
    *   It executes the SQL query and loads the data into a Pandas DataFrame.
    *   It calculates molecular descriptors (MW and LogP) using RDKit.
    *   It builds a Random Forest Regression model to predict the `standard_value` based on the calculated descriptors.
    *   It evaluates the model using Mean Squared Error (MSE) and R-squared.
    *   Finally, it saves the processed DataFrame to a CSV file.

**Fixing the Errors:**

*   **Error a: `ERROR: operator does not exist: numeric ~ unknown LINE 12: AND act.standard_value ~ '^[0-9\.]+$'`**

    This error occurs because PostgreSQL's `~` operator (regular expression match) is not directly applicable to numeric columns. To fix this, you need to cast the `standard_value` to text before using the `~` operator and cast to numeric for comparison:

    ```sql
    AND act.standard_value::TEXT ~ '^[0-9\.]+$'  -- Ensure standard_value is numeric
    AND act.standard_value::NUMERIC > 0
    AND act.standard_value::NUMERIC < 10000
    ```

*   **Error b: `mean_squared_error` does not support `squared=False`**

    This error indicates that you are using an older version of scikit-learn.  Either upgrade scikit-learn to a version that supports `squared=False` (which returns the root mean squared error (RMSE) directly) or calculate the RMSE manually:

    ```python
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse) # Calculate RMSE manually
    print(f"Mean Squared Error: {mse}")
    print(f"Root Mean Squared Error: {rmse}") # Print RMSE
    ```

**4. Five Examples of SQL and Python Code**

Here are five more examples demonstrating different data extraction and analysis techniques:

**Example 1:  Filtering by Molecular Weight (SQL & Python)**

*   **SQL:** Extract compounds with molecular weight between 200 and 500.  This requires joining with a table that contains molecular weight information (which may require creating a custom table or function if not directly available in ChEMBL).  The example assumes a table called `molecule_properties` with a `molregno` and `molecular_weight` column.

```sql
SELECT
    act.standard_value,
    act.standard_units,
    md.chembl_id,
    cs.canonical_smiles
FROM
    activities act
JOIN
    molecule_dictionary md ON act.molregno = md.molregno
JOIN
    compound_structures cs ON md.molregno = cs.molregno
LEFT JOIN
    molecule_properties mp ON md.molregno = mp.molregno -- Assuming a table with MW info
WHERE
    act.target_chembl_id = 'CHEMBL205'
    AND act.standard_type = 'IC50'
    AND act.standard_relation = '='
    AND act.standard_value IS NOT NULL
    AND act.standard_value::TEXT ~ '^[0-9\.]+$'
    AND act.standard_value::NUMERIC > 0
    AND act.standard_value::NUMERIC < 10000
    AND cs.canonical_smiles IS NOT NULL
    AND mp.molecular_weight BETWEEN 200 AND 500 -- Filter by molecular weight
LIMIT 100;

```

*   **Python:** Add molecular weight filtering after extracting the data using RDKit.

```python
# ... (previous code) ...

    # Feature Engineering (including MW calculation)
    descriptors_list = []
    for smiles in df['canonical_smiles']:
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            descriptors_list.append(None)
            continue
        descriptors = {}
        descriptors['MW'] = Descriptors.MolWt(mol)
        descriptors['LogP'] = Descriptors.MolLogP(mol)
        descriptors_list.append(descriptors)

    descriptors_df = pd.DataFrame(descriptors_list)
    df = pd.concat([df, descriptors_df], axis=1)
    df = df.dropna()

    # Filter by molecular weight
    df = df[(df['MW'] >= 200) & (df['MW'] <= 500)]

    # ... (rest of the code) ...
```

**Example 2:  Using Morgan Fingerprints (Python)**

*   **Python:**  Calculate Morgan fingerprints and use them as features in the model.

```python
from rdkit.Chem import AllChem

# Function to calculate Morgan Fingerprint
def calculate_morgan_fingerprint(smiles, radius=2, nBits=2048):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)
    return fp

# ... (previous code) ...

    # Feature Engineering (including Morgan Fingerprint)
    fingerprints = []
    for smiles in df['canonical_smiles']:
        fp = calculate_morgan_fingerprint(smiles)
        if fp is None:
            fingerprints.append(None)
        else:
            fingerprints.append(fp)

    df['fingerprint'] = fingerprints
    df = df.dropna(subset=['fingerprint'])

    # Convert fingerprints to a matrix for machine learning
    X = np.array([list(fp) for fp in df['fingerprint']])
    y = np.log10(df['standard_value'])

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # ... (rest of the code) ...
```

**Example 3:  Extracting Data for Multiple Target CHEMBL IDs (SQL & Python)**

*   **SQL:** Extract data for several targets at once.

```sql
SELECT
    act.standard_value,
    act.standard_units,
    md.chembl_id,
    cs.canonical_smiles
FROM
    activities act
JOIN
    molecule_dictionary md ON act.molregno = md.molregno
JOIN
    compound_structures cs ON md.molregno = cs.molregno
WHERE
    act.target_chembl_id IN ('CHEMBL205', 'CHEMBL206', 'CHEMBL207') -- Multiple targets
    AND act.standard_type = 'IC50'
    AND act.standard_relation = '='
    AND act.standard_value IS NOT NULL
    AND act.standard_value::TEXT ~ '^[0-9\.]+$'
    AND act.standard_value::NUMERIC > 0
    AND act.standard_value::NUMERIC < 10000
    AND cs.canonical_smiles IS NOT NULL
LIMIT 100;
```

*   **Python:** No significant changes needed in the Python code, as it processes the data returned by the SQL query.

**Example 4:  Calculating TPSA (Topological Polar Surface Area) (Python)**

*   **Python:** Add TPSA calculation to the molecular descriptor calculation.

```python
from rdkit.Chem import rdMolDescriptors

# Function to calculate molecular descriptors including TPSA
def calculate_descriptors(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    descriptors = {}
    descriptors['MW'] = Descriptors.MolWt(mol)
    descriptors['LogP'] = Descriptors.MolLogP(mol)
    descriptors['TPSA'] = rdMolDescriptors.CalcTPSA(mol) # Add TPSA
    return descriptors

# ... (rest of the code) ...
```

**Example 5:  Using a Different Machine Learning Model (Python)**

*   **Python:**  Replace the Random Forest Regressor with a Support Vector Regressor (SVR).

```python
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

# ... (previous code) ...

    # Data Analysis and Modeling
    X = df[['MW', 'LogP']]
    y = np.log10(df['standard_value'])

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Feature scaling is often important for SVR
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Create an SVR model
    model = make_pipeline(SVR(kernel='rbf'))  # Use a pipeline for scaling and SVR
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    # Model Evaluation
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"Mean Squared Error: {mse}")
    print(f"R-squared: {r2}")

    # ... (rest of the code) ...
```

**Important Considerations:**

*   **Database Connection:**  Ensure your database connection details (IP address, username, password, database name) are correct.  It's best practice to store these credentials in environment variables rather than hardcoding them in your script.
*   **Error Handling:** Add more robust error handling to your code, especially when dealing with database connections, file I/O, and RDKit calculations.
*   **Data Scaling:**  For machine learning models like SVR and linear regression, scaling your data (e.g., using `StandardScaler`) can significantly improve performance.
*   **Feature Selection:**  Experiment with different sets of molecular descriptors to find the features that best predict activity.
*   **Model Tuning:**  Tune the hyperparameters of your machine learning models (e.g., `n_estimators` for Random Forest, `C` and `gamma` for SVR) using techniques like cross-validation to optimize performance.
*   **Virtual Environments:**  Use virtual environments (e.g., `venv` or `conda`) to manage your Python dependencies and ensure reproducibility.
*   **Logging:** Implement logging to track the progress of your script and debug any issues.
*   **File Paths:**  Double-check all file paths to ensure they are correct and that you have the necessary permissions to read and write files.

By following these guidelines and adapting the examples to your specific needs, you can build a powerful and effective data analysis pipeline for your ChEMBL 35 project. Let me know if you have any further questions or need more specific assistance!
