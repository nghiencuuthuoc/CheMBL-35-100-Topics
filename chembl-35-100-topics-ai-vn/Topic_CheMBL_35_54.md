# PharmApp Suite
## üß† AI for Drug Discovery and Development üß™
| Copyright 2025 | Nghi√™n C·ª©u Thu·ªëc | www.nghiencuuthuoc.com | Zalo: +84888999311 |

üß© Topic: Ph√¢n t√≠ch thu·ªëc th·∫ßn kinh ‚Äì t√¢m th·∫ßn
---
Tuy·ªát v·ªùi! V·ªõi vai tr√≤ l√† chuy√™n gia R&D d∆∞·ª£c h·ªçc, t√¥i r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n trong d·ª± √°n ph√¢n t√≠ch d·ªØ li·ªáu ChEMBL 35. D∆∞·ªõi ƒë√¢y l√† ph√¢n t√≠ch chi ti·∫øt, h∆∞·ªõng d·∫´n song ng·ªØ v√† c√°c v√≠ d·ª• code ƒë·ªÉ b·∫°n tham kh·∫£o, t·∫≠p trung v√†o ch·ªß ƒë·ªÅ "Topic_CheMBL_35_54".

**1. Ph√¢n t√≠ch m√¥ h√¨nh (Analysis Model)**

Ch·ªß ƒë·ªÅ "Topic_CheMBL_35_54" c√≥ th·ªÉ li√™n quan ƒë·∫øn nhi·ªÅu kh√≠a c·∫°nh kh√°c nhau trong ph√°t tri·ªÉn thu·ªëc, v√≠ d·ª•:

*   **Ph√¢n t√≠ch SAR/QSAR (Structure-Activity Relationship/Quantitative Structure-Activity Relationship):** X√°c ƒë·ªãnh m·ªëi li√™n h·ªá gi·ªØa c·∫•u tr√∫c h√≥a h·ªçc c·ªßa c√°c ph√¢n t·ª≠ v√† ho·∫°t t√≠nh sinh h·ªçc c·ªßa ch√∫ng.
*   **Ph√¢n t√≠ch s√†ng l·ªçc ·∫£o (Virtual Screening Analysis):** S·ª≠ d·ª•ng c√°c m√¥ h√¨nh m√°y t√≠nh ƒë·ªÉ d·ª± ƒëo√°n kh·∫£ nƒÉng li√™n k·∫øt c·ªßa c√°c ph√¢n t·ª≠ v·ªõi m·ª•c ti√™u (target) v√† ∆∞u ti√™n c√°c ·ª©ng vi√™n ti·ªÅm nƒÉng.
*   **Ph√¢n t√≠ch t√≠nh ch·∫•t d∆∞·ª£c ƒë·ªông h·ªçc (Pharmacokinetic Property Analysis):** Nghi√™n c·ª©u c√°ch c∆° th·ªÉ h·∫•p th·ª•, ph√¢n ph·ªëi, chuy·ªÉn h√≥a v√† th·∫£i tr·ª´ thu·ªëc (ADME).
*   **Ph√¢n t√≠ch ƒë·ªôc t√≠nh (Toxicity Analysis):** ƒê√°nh gi√° kh·∫£ nƒÉng g√¢y h·∫°i c·ªßa c√°c ph√¢n t·ª≠ ƒë·ªëi v·ªõi c∆° th·ªÉ.

**M√¥ h√¨nh ph√¢n t√≠ch ƒë·ªÅ xu·∫•t:**

D·ª±a tr√™n kinh nghi·ªám c·ªßa t√¥i, t√¥i ƒë·ªÅ xu·∫•t m·ªôt quy tr√¨nh ph√¢n t√≠ch k·∫øt h·ª£p c√°c b∆∞·ªõc sau:

1.  **Thu th·∫≠p v√† chu·∫©n b·ªã d·ªØ li·ªáu (Data Collection and Preparation):**
    *   Truy v·∫•n d·ªØ li·ªáu t·ª´ c∆° s·ªü d·ªØ li·ªáu ChEMBL 35 b·∫±ng SQL.
    *   S·ª≠ d·ª•ng RDKit ƒë·ªÉ t√≠nh to√°n c√°c descriptor ph√¢n t·ª≠ (v√≠ d·ª•: tr·ªçng l∆∞·ª£ng ph√¢n t·ª≠, logP, di·ªán t√≠ch b·ªÅ m·∫∑t ph√¢n c·ª±c).
    *   L√†m s·∫°ch v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu (x·ª≠ l√Ω gi√° tr·ªã thi·∫øu, lo·∫°i b·ªè outlier).
2.  **Ph√¢n t√≠ch m√¥ t·∫£ (Descriptive Analysis):**
    *   Th·ªëng k√™ m√¥ t·∫£ c√°c descriptor v√† ho·∫°t t√≠nh sinh h·ªçc.
    *   Tr·ª±c quan h√≥a d·ªØ li·ªáu (v√≠ d·ª•: bi·ªÉu ƒë·ªì ph√¢n t√°n, bi·ªÉu ƒë·ªì h·ªôp) ƒë·ªÉ kh√°m ph√° c√°c xu h∆∞·ªõng v√† m·ªëi quan h·ªá ti·ªÅm nƒÉng.
3.  **X√¢y d·ª±ng m√¥ h√¨nh SAR/QSAR (SAR/QSAR Model Building):**
    *   Ch·ªçn c√°c descriptor ph√π h·ª£p l√†m ƒë·∫ßu v√†o cho m√¥ h√¨nh.
    *   S·ª≠ d·ª•ng c√°c thu·∫≠t to√°n h·ªçc m√°y (v√≠ d·ª•: h·ªìi quy tuy·∫øn t√≠nh, c√¢y quy·∫øt ƒë·ªãnh, m·∫°ng n∆°-ron) ƒë·ªÉ x√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n ho·∫°t t√≠nh.
    *   ƒê√°nh gi√° hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh b·∫±ng c√°c ch·ªâ s·ªë ph√π h·ª£p (v√≠ d·ª•: R-squared, RMSE, AUC).
4.  **Gi·∫£i th√≠ch m√¥ h√¨nh v√† r√∫t ra k·∫øt lu·∫≠n (Model Interpretation and Conclusion):**
    *   X√°c ƒë·ªãnh c√°c descriptor quan tr·ªçng ·∫£nh h∆∞·ªüng ƒë·∫øn ho·∫°t t√≠nh.
    *   ƒê·ªÅ xu·∫•t c√°c h∆∞·ªõng ƒëi ti·ªÅm nƒÉng ƒë·ªÉ t·ªëi ∆∞u h√≥a c·∫•u tr√∫c ph√¢n t·ª≠.

**2. H∆∞·ªõng d·∫´n song ng·ªØ (Bilingual Guidance)**

*   **Ti·∫øng Anh (English):**

    *   **Data Retrieval:** Use SQL queries to extract relevant data from the ChEMBL 35 database.
    *   **Molecular Descriptors:** Utilize RDKit to compute molecular descriptors that capture the structural and physicochemical properties of the compounds.
    *   **Model Building:** Employ machine learning algorithms to build predictive models that relate molecular descriptors to biological activity.
    *   **Model Validation:** Evaluate the performance of the models using appropriate metrics and validation techniques.
    *   **Interpretation:** Interpret the models to identify key structural features that influence activity and guide further optimization efforts.
*   **Ti·∫øng Vi·ªát (Vietnamese):**

    *   **Truy xu·∫•t d·ªØ li·ªáu:** S·ª≠ d·ª•ng truy v·∫•n SQL ƒë·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu li√™n quan t·ª´ c∆° s·ªü d·ªØ li·ªáu ChEMBL 35.
    *   **Descriptor ph√¢n t·ª≠:** S·ª≠ d·ª•ng RDKit ƒë·ªÉ t√≠nh to√°n c√°c descriptor ph√¢n t·ª≠, n·∫Øm b·∫Øt c√°c ƒë·∫∑c t√≠nh c·∫•u tr√∫c v√† l√Ω h√≥a c·ªßa c√°c h·ª£p ch·∫•t.
    *   **X√¢y d·ª±ng m√¥ h√¨nh:** S·ª≠ d·ª•ng c√°c thu·∫≠t to√°n h·ªçc m√°y ƒë·ªÉ x√¢y d·ª±ng c√°c m√¥ h√¨nh d·ª± ƒëo√°n li√™n h·ªá gi·ªØa c√°c descriptor ph√¢n t·ª≠ v√† ho·∫°t t√≠nh sinh h·ªçc.
    *   **X√°c th·ª±c m√¥ h√¨nh:** ƒê√°nh gi√° hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c s·ªë li·ªáu v√† k·ªπ thu·∫≠t x√°c th·ª±c ph√π h·ª£p.
    *   **Gi·∫£i th√≠ch:** Gi·∫£i th√≠ch c√°c m√¥ h√¨nh ƒë·ªÉ x√°c ƒë·ªãnh c√°c ƒë·∫∑c ƒëi·ªÉm c·∫•u tr√∫c ch√≠nh ·∫£nh h∆∞·ªüng ƒë·∫øn ho·∫°t ƒë·ªông v√† h∆∞·ªõng d·∫´n c√°c n·ªó l·ª±c t·ªëi ∆∞u h√≥a h∆°n n·ªØa.

**3. Code m·∫´u (Code Examples)**

**3.1 SQL (l·∫•y 100 d√≤ng d·ªØ li·ªáu, tr√°nh l·ªói `numeric ~ unknown`)**

```sql
-- English
-- Select 100 rows of data, ensuring that standard_value is numeric
SELECT
    act.molregno,
    act.standard_value,
    act.standard_units,
    cmp.smiles
FROM
    activities act
JOIN
    molecule_dictionary cmp ON act.molregno = cmp.molregno
WHERE
    act.standard_type = 'IC50'  -- Example: Filter by IC50 values
    AND act.standard_relation = '='
    AND act.standard_value IS NOT NULL
    AND act.standard_value::TEXT ~ '^[0-9\.]+$' -- Ensure numeric value
LIMIT 100;

-- Vietnamese
-- Ch·ªçn 100 d√≤ng d·ªØ li·ªáu, ƒë·∫£m b·∫£o r·∫±ng standard_value l√† s·ªë
SELECT
    act.molregno,
    act.standard_value,
    act.standard_units,
    cmp.smiles
FROM
    activities act
JOIN
    molecule_dictionary cmp ON act.molregno = cmp.molregno
WHERE
    act.standard_type = 'IC50'  -- V√≠ d·ª•: L·ªçc theo gi√° tr·ªã IC50
    AND act.standard_relation = '='
    AND act.standard_value IS NOT NULL
    AND act.standard_value::TEXT ~ '^[0-9\.]+$' -- ƒê·∫£m b·∫£o gi√° tr·ªã l√† s·ªë
LIMIT 100;
```

**3.2 Python (Jupyter Notebook)**

```python
# English
import os
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Define base path
base_path = "../data"  # Adjust this path

# Load data from CSV
data_file = "chembl_ic50_data.csv"  # Replace with your CSV file name
data_path = os.path.join(base_path, data_file)
df = pd.read_csv(data_path)

# Function to calculate molecular descriptors using RDKit
def calculate_descriptors(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    descriptors = {}
    descriptors["MolWt"] = Descriptors.MolWt(mol)
    descriptors["LogP"] = Descriptors.MolLogP(mol)
    descriptors["HBD"] = Descriptors.NumHDonors(mol)
    descriptors["HBA"] = Descriptors.NumHAcceptors(mol)
    return descriptors

# Apply descriptor calculation to the DataFrame
df['descriptors'] = df['smiles'].apply(calculate_descriptors)
df = df.dropna(subset=['descriptors'])  # Drop rows with None descriptors

# Convert descriptors to columns
df = pd.concat([df.drop(['descriptors'], axis=1), df['descriptors'].apply(pd.Series)], axis=1)

# Prepare data for modeling
X = df[["MolWt", "LogP", "HBD", "HBA"]]  # Use calculated descriptors
y = df["standard_value"].astype(float)  # Ensure numeric type

# Remove infinite or NaN values
X = X[~np.isinf(X).any(axis=1)]
y = y[~np.isinf(y)]
X = X.dropna()
y = y.dropna()

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred) # No squared=False needed
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

# Vietnamese
# Nh·∫≠p c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
import os
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n g·ªëc
base_path = "../data"  # ƒêi·ªÅu ch·ªânh ƒë∆∞·ªùng d·∫´n n√†y

# T·∫£i d·ªØ li·ªáu t·ª´ file CSV
data_file = "chembl_ic50_data.csv"  # Thay th·∫ø b·∫±ng t√™n file CSV c·ªßa b·∫°n
data_path = os.path.join(base_path, data_file)
df = pd.read_csv(data_path)

# H√†m t√≠nh to√°n descriptor ph√¢n t·ª≠ b·∫±ng RDKit
def calculate_descriptors(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    descriptors = {}
    descriptors["MolWt"] = Descriptors.MolWt(mol)
    descriptors["LogP"] = Descriptors.MolLogP(mol)
    descriptors["HBD"] = Descriptors.NumHDonors(mol)
    descriptors["HBA"] = Descriptors.NumHAcceptors(mol)
    return descriptors

# √Åp d·ª•ng t√≠nh to√°n descriptor cho DataFrame
df['descriptors'] = df['smiles'].apply(calculate_descriptors)
df = df.dropna(subset=['descriptors'])  # Lo·∫°i b·ªè c√°c h√†ng c√≥ descriptor l√† None

# Chuy·ªÉn ƒë·ªïi descriptor th√†nh c√°c c·ªôt
df = pd.concat([df.drop(['descriptors'], axis=1), df['descriptors'].apply(pd.Series)], axis=1)

# Chu·∫©n b·ªã d·ªØ li·ªáu cho m√¥ h√¨nh h√≥a
X = df[["MolWt", "LogP", "HBD", "HBA"]]  # S·ª≠ d·ª•ng c√°c descriptor ƒë√£ t√≠nh
y = df["standard_value"].astype(float)  # ƒê·∫£m b·∫£o ki·ªÉu s·ªë

# Lo·∫°i b·ªè c√°c gi√° tr·ªã v√¥ c·ª±c ho·∫∑c NaN
X = X[~np.isinf(X).any(axis=1)]
y = y[~np.isinf(y)]
X = X.dropna()
y = y.dropna()

# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Hu·∫•n luy·ªán m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh
model = LinearRegression()
model.fit(X_train, y_train)

# D·ª± ƒëo√°n
y_pred = model.predict(X_test)

# ƒê√°nh gi√° m√¥ h√¨nh
mse = mean_squared_error(y_test, y_pred) # Kh√¥ng c·∫ßn squared=False
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

**4. NƒÉm v√≠ d·ª• code (Five code examples)**

**V√≠ d·ª• 1: T√≠nh s·ªë l∆∞·ª£ng v√≤ng (ring count)**

```sql
-- SQL
SELECT molregno, smiles, ring_count FROM molecule_dictionary LIMIT 5;
```

```python
# Python
from rdkit import Chem
from rdkit.Chem import rdMolDescriptors

def get_ring_count(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return rdMolDescriptors.CalcNumRings(mol)
    else:
        return None

df['ring_count'] = df['smiles'].apply(get_ring_count)
```

**V√≠ d·ª• 2: L·ªçc theo tr·ªçng l∆∞·ª£ng ph√¢n t·ª≠ (molecular weight)**

```sql
-- SQL
SELECT molregno, smiles, mol_weight FROM molecule_dictionary WHERE mol_weight > 500 LIMIT 5;
```

```python
# Python
df_filtered = df[df['MolWt'] > 500]
```

**V√≠ d·ª• 3: T√≠nh TPSA (Topological Polar Surface Area)**

```python
# Python
from rdkit.Chem import Descriptors3D

def calculate_tpsa(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors3D.TPSA(mol)
    else:
        return None

df['tpsa'] = df['smiles'].apply(calculate_tpsa)
```

**V√≠ d·ª• 4: Ph√¢n t√≠ch t·∫ßn su·∫•t c·ªßa c√°c ƒë∆°n v·ªã c·∫•u tr√∫c (frequent substructure analysis)**

```python
# Python
from rdkit.Chem import AllChem
from collections import defaultdict

def frequent_substructures(smiles_list, min_support=0.2):
    mols = [Chem.MolFromSmiles(s) for s in smiles_list]
    patterns = defaultdict(int)
    for mol in mols:
        if mol:
            info = {}
            fp = AllChem.GetMorganFingerprint(mol, 2, bitInfo=info)
            for bit, atom_radius in info.items():
                env = Chem.FindAtomEnvironmentOfRadiusN(mol, atom_radius[1], atom_radius[0])
                amap = {}
                submol = Chem.PathToSubmol(mol, env, atomMap=amap)
                 Smiles = Chem.MolToSmiles(submol)
                patterns[Smiles] += 1

    # Filter by minimum support
    filtered_patterns = {k: v for k, v in patterns.items() if v / len(smiles_list) >= min_support}
    return filtered_patterns

# Get a list of SMILES strings from your DataFrame
smiles_list = df['smiles'].tolist()

# Find frequent substructures
frequent_patterns = frequent_substructures(smiles_list)

print("Frequent Substructures:")
for pattern, count in frequent_patterns.items():
    print(f"Substructure: {pattern}, Support: {count / len(smiles_list):.2f}")
```

**V√≠ d·ª• 5: T√≠nh s·ªë l∆∞·ª£ng li√™n k·∫øt quay t·ª± do (number of rotatable bonds)**

```python
# Python
from rdkit.Chem import Descriptors

def calculate_rotatable_bonds(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.NumRotatableBonds(mol)
    else:
        return None

df['rotatable_bonds'] = df['smiles'].apply(calculate_rotatable_bonds)
```

**L∆∞u √Ω quan tr·ªçng:**

*   **ƒê∆∞·ªùng d·∫´n:** H√£y ch·∫Øc ch·∫Øn r·∫±ng ƒë∆∞·ªùng d·∫´n `base_path` trong code Python tr·ªè ƒë·∫øn ƒë√∫ng th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu c·ªßa b·∫°n.
*   **T√™n file:** Thay th·∫ø `"chembl_ic50_data.csv"` b·∫±ng t√™n file CSV th·ª±c t·∫ø c·ªßa b·∫°n.
*   **Ch·ªçn descriptor:**  L·ª±a ch·ªçn descriptor ph√¢n t·ª≠ ph√π h·ª£p ph·ª• thu·ªôc v√†o m·ª•c ti√™u c·ª• th·ªÉ c·ªßa b·∫°n. H√£y tham kh·∫£o c√°c t√†i li·ªáu v·ªÅ SAR/QSAR ƒë·ªÉ bi·∫øt th√™m th√¥ng tin.
*   **ƒêi·ªÅu ch·ªânh tham s·ªë:** C√°c tham s·ªë nh∆∞ `test_size` trong `train_test_split` v√† `min_support` trong `frequent_substructures` c√≥ th·ªÉ c·∫ßn ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh ƒë·ªÉ ph√π h·ª£p v·ªõi d·ªØ li·ªáu c·ªßa b·∫°n.
*   **X·ª≠ l√Ω l·ªói:** Lu√¥n ki·ªÉm tra v√† x·ª≠ l√Ω c√°c l·ªói ti·ªÅm ·∫©n (v√≠ d·ª•: ph√¢n t·ª≠ kh√¥ng h·ª£p l·ªá, gi√° tr·ªã thi·∫øu) ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh ·ªïn ƒë·ªãnh c·ªßa quy tr√¨nh ph√¢n t√≠ch.
*   **Phi√™n b·∫£n th∆∞ vi·ªán:** ƒê·∫£m b·∫£o r·∫±ng b·∫°n ƒë√£ c√†i ƒë·∫∑t c√°c phi√™n b·∫£n t∆∞∆°ng th√≠ch c·ªßa c√°c th∆∞ vi·ªán (RDKit, scikit-learn, pandas, numpy).

Ch√∫c b·∫°n th√†nh c√¥ng v·ªõi d·ª± √°n ph√¢n t√≠ch d·ªØ li·ªáu ChEMBL 35! N·∫øu b·∫°n c√≥ b·∫•t k·ª≥ c√¢u h·ªèi n√†o kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i h·ªèi.
