# PharmApp Suite
## üß† AI for Drug Discovery and Development üß™
| Copyright 2025 | Nghi√™n C·ª©u Thu·ªëc | www.nghiencuuthuoc.com | Zalo: +84888999311 |

üß© Topic: C·∫£nh b√°o an to√†n li√™n k·∫øt v·ªõi ho·∫°t t√≠nh sinh h·ªçc
---
Tuy·ªát v·ªùi! T√¥i r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n trong d·ª± √°n ph√¢n t√≠ch d·ªØ li·ªáu ChEMBL 35 k·∫øt h·ª£p RDKit ƒë·ªÉ ph·ª•c v·ª• nghi√™n c·ª©u v√† ph√°t tri·ªÉn thu·ªëc. V·ªõi vai tr√≤ l√† m·ªôt chuy√™n gia R&D d∆∞·ª£c h·ªçc, t√¥i s·∫Ω gi√∫p b·∫°n x√¢y d·ª±ng m·ªôt quy tr√¨nh l√†m vi·ªác hi·ªáu qu·∫£, gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t v√† ƒë∆∞a ra c√°c v√≠ d·ª• c·ª• th·ªÉ ƒë·ªÉ b·∫°n tham kh·∫£o.

D∆∞·ªõi ƒë√¢y l√† ph√¢n t√≠ch, h∆∞·ªõng d·∫´n chi ti·∫øt v√† c√°c v√≠ d·ª• code m·∫´u, ƒë∆∞·ª£c tr√¨nh b√†y song ng·ªØ (ti·∫øng Anh v√† ti·∫øng Vi·ªát) ƒë·ªÉ b·∫°n d·ªÖ d√†ng theo d√µi:

**1. Ph√¢n t√≠ch m√¥ h√¨nh ph√¢n t√≠ch (Analysis of the Analysis Model)**

M·ª•c ti√™u c·ªßa b·∫°n l√† khai th√°c d·ªØ li·ªáu t·ª´ ChEMBL 35, m·ªôt c∆° s·ªü d·ªØ li·ªáu l·ªõn ch·ª©a th√¥ng tin v·ªÅ c√°c ph√¢n t·ª≠ ho·∫°t t√≠nh sinh h·ªçc. S·ª≠ d·ª•ng RDKit, m·ªôt b·ªô c√¥ng c·ª• h√≥a tin h·ªçc m·∫°nh m·∫Ω, b·∫°n c√≥ th·ªÉ t√≠nh to√°n c√°c descriptor ph√¢n t·ª≠ (molecular descriptors) v√† fingerprints ƒë·ªÉ bi·ªÉu di·ªÖn c·∫•u tr√∫c h√≥a h·ªçc c·ªßa c√°c h·ª£p ch·∫•t. Sau ƒë√≥, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c m√¥ h√¨nh h·ªçc m√°y (machine learning models) ƒë·ªÉ x√¢y d·ª±ng c√°c m√¥ h√¨nh QSAR/QSPR (Quantitative Structure-Activity/Property Relationship) d·ª± ƒëo√°n ho·∫°t t√≠nh sinh h·ªçc ho·∫∑c t√≠nh ch·∫•t c·ªßa c√°c h·ª£p ch·∫•t m·ªõi.

**C√°c b∆∞·ªõc ch√≠nh trong quy tr√¨nh ph√¢n t√≠ch:**

1.  **Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ ChEMBL 35 (Data Extraction from ChEMBL 35):** S·ª≠ d·ª•ng SQL ƒë·ªÉ truy v·∫•n d·ªØ li·ªáu c·∫ßn thi·∫øt t·ª´ c∆° s·ªü d·ªØ li·ªáu ChEMBL 35. D·ªØ li·ªáu n√†y c√≥ th·ªÉ bao g·ªìm c·∫•u tr√∫c ph√¢n t·ª≠ (SMILES), ho·∫°t t√≠nh sinh h·ªçc (IC50, Ki, Kd, etc.), v√† c√°c th√¥ng tin li√™n quan kh√°c.
2.  **Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu (Data Preprocessing):** L√†m s·∫°ch d·ªØ li·ªáu, x·ª≠ l√Ω c√°c gi√° tr·ªã thi·∫øu, chu·∫©n h√≥a d·ªØ li·ªáu ho·∫°t t√≠nh sinh h·ªçc (v√≠ d·ª•: chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ v·ªÅ pIC50).
3.  **T√≠nh to√°n descriptor ph√¢n t·ª≠ (Molecular Descriptor Calculation):** S·ª≠ d·ª•ng RDKit ƒë·ªÉ t√≠nh to√°n c√°c descriptor ph√¢n t·ª≠ v√† fingerprints t·ª´ c·∫•u tr√∫c SMILES. C√°c descriptor n√†y c√≥ th·ªÉ bao g·ªìm c√°c t√≠nh ch·∫•t v·∫≠t l√Ω h√≥a h·ªçc, c√°c th√¥ng s·ªë h√¨nh h·ªçc, v√† c√°c fingerprints bi·ªÉu di·ªÖn c·∫•u tr√∫c ph√¢n t·ª≠.
4.  **L·ª±a ch·ªçn ƒë·∫∑c tr∆∞ng (Feature Selection):** Ch·ªçn c√°c descriptor quan tr·ªçng nh·∫•t ƒë·ªÉ ƒë∆∞a v√†o m√¥ h√¨nh h·ªçc m√°y. ƒêi·ªÅu n√†y c√≥ th·ªÉ ƒë∆∞·ª£c th·ª±c hi·ªán b·∫±ng c√°c ph∆∞∆°ng ph√°p th·ªëng k√™ ho·∫∑c c√°c thu·∫≠t to√°n l·ª±a ch·ªçn ƒë·∫∑c tr∆∞ng.
5.  **X√¢y d·ª±ng m√¥ h√¨nh h·ªçc m√°y (Machine Learning Model Building):** S·ª≠ d·ª•ng c√°c thu·∫≠t to√°n h·ªçc m√°y nh∆∞ h·ªìi quy tuy·∫øn t√≠nh, random forest, SVM, ho·∫∑c m·∫°ng n∆°-ron ƒë·ªÉ x√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n ho·∫°t t√≠nh sinh h·ªçc.
6.  **ƒê√°nh gi√° m√¥ h√¨nh (Model Evaluation):** ƒê√°nh gi√° hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh b·∫±ng c√°c ch·ªâ s·ªë ph√π h·ª£p nh∆∞ R-squared, RMSE, MAE, AUC, etc.
7.  **Gi·∫£i th√≠ch m√¥ h√¨nh (Model Interpretation):** Ph√¢n t√≠ch c√°c descriptor quan tr·ªçng nh·∫•t ·∫£nh h∆∞·ªüng ƒë·∫øn ho·∫°t t√≠nh sinh h·ªçc ƒë·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ m·ªëi quan h·ªá c·∫•u tr√∫c-ho·∫°t t√≠nh.

**2. H∆∞·ªõng d·∫´n song ng·ªØ (Bilingual Guide)**

**2.1. Code SQL (SQL Code)**

*   **M·ª•c ƒë√≠ch (Purpose):** Tr√≠ch xu·∫•t d·ªØ li·ªáu ho·∫°t t√≠nh sinh h·ªçc t·ª´ c∆° s·ªü d·ªØ li·ªáu ChEMBL 35 (Extract bioactivity data from ChEMBL 35 database).
*   **Gi·∫£i th√≠ch (Explanation):** Truy v·∫•n n√†y l·∫•y d·ªØ li·ªáu t·ª´ c√°c b·∫£ng `activities`, `activity_properties`, `assays`, `compound_structures`, v√† `target_dictionary` ƒë·ªÉ l·ªçc c√°c ho·∫°t t√≠nh d·ª±a tr√™n m·ª•c ti√™u c·ª• th·ªÉ v√† lo·∫°i ho·∫°t t√≠nh (This query retrieves data from the `activities`, `activity_properties`, `assays`, `compound_structures`, and `target_dictionary` tables to filter activities based on a specific target and activity type).
*   **L∆∞u √Ω (Note):** S·ª≠a ƒë·ªïi `target_chembl_id` v√† c√°c ƒëi·ªÅu ki·ªán kh√°c ƒë·ªÉ ph√π h·ª£p v·ªõi m·ª•c ti√™u nghi√™n c·ª©u c·ªßa b·∫°n (Modify `target_chembl_id` and other conditions to suit your research objectives).

```sql
-- English
-- Extract bioactivity data for a specific target, limiting to 100 rows
SELECT
    cs.canonical_smiles,
    act.standard_type,
    act.standard_value,
    act.standard_units
FROM
    activities act
JOIN
    activity_properties ap ON act.activity_id = ap.activity_id
JOIN
    assays ass ON act.assay_id = ass.assay_id
JOIN
    compound_structures cs ON act.molregno = cs.molregno
JOIN
    target_dictionary td ON ass.tid = td.tid
WHERE
    td.target_chembl_id = 'CHEMBL205'  -- Replace with your target of interest
    AND act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.standard_value IS NOT NULL
    AND act.standard_value > 0  -- Avoid zero values
    AND act.standard_value < 10000 -- Limit to reasonable values
    AND act.standard_value::text ~ '^[0-9\.]+$'  -- Ensure it's a number
LIMIT 100;

-- Vietnamese
-- Tr√≠ch xu·∫•t d·ªØ li·ªáu ho·∫°t t√≠nh sinh h·ªçc cho m·ªôt m·ª•c ti√™u c·ª• th·ªÉ, gi·ªõi h·∫°n 100 d√≤ng
SELECT
    cs.canonical_smiles,
    act.standard_type,
    act.standard_value,
    act.standard_units
FROM
    activities act
JOIN
    activity_properties ap ON act.activity_id = ap.activity_id
JOIN
    assays ass ON act.assay_id = ass.assay_id
JOIN
    compound_structures cs ON act.molregno = cs.molregno
JOIN
    target_dictionary td ON ass.tid = td.tid
WHERE
    td.target_chembl_id = 'CHEMBL205'  -- Thay th·∫ø b·∫±ng m·ª•c ti√™u b·∫°n quan t√¢m
    AND act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.standard_value IS NOT NULL
    AND act.standard_value > 0  -- Tr√°nh c√°c gi√° tr·ªã b·∫±ng kh√¥ng
    AND act.standard_value < 10000 -- Gi·ªõi h·∫°n trong kho·∫£ng gi√° tr·ªã h·ª£p l√Ω
    AND act.standard_value::text ~ '^[0-9\.]+$'  -- ƒê·∫£m b·∫£o l√† m·ªôt s·ªë
LIMIT 100;
```

**S·ª≠a l·ªói SQL (Fixing SQL Error):**

L·ªói `ERROR: operator does not exist: numeric ~ unknown LINE 12: AND act.standard_value ~ '^[0-9\.]+$'` x·∫£y ra do b·∫°n ƒëang c·ªë g·∫Øng s·ª≠ d·ª•ng to√°n t·ª≠ `~` (regular expression match) tr√™n m·ªôt c·ªôt ki·ªÉu s·ªë (numeric). ƒê·ªÉ kh·∫Øc ph·ª•c, b·∫°n c·∫ßn √©p ki·ªÉu c·ªôt `standard_value` sang ki·ªÉu text tr∆∞·ªõc khi so s√°nh:

```sql
AND act.standard_value::text ~ '^[0-9\.]+$'
```

**2.2. Code Python (Python Code)**

*   **M·ª•c ƒë√≠ch (Purpose):** ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV, t√≠nh to√°n descriptor ph√¢n t·ª≠ b·∫±ng RDKit v√† hi·ªÉn th·ªã m·ªôt v√†i d√≤ng ƒë·∫ßu (Read data from CSV file, calculate molecular descriptors using RDKit, and display the first few rows).
*   **Gi·∫£i th√≠ch (Explanation):** ƒêo·∫°n code n√†y s·ª≠ d·ª•ng th∆∞ vi·ªán `pandas` ƒë·ªÉ ƒë·ªçc d·ªØ li·ªáu t·ª´ file CSV. Sau ƒë√≥, n√≥ s·ª≠ d·ª•ng RDKit ƒë·ªÉ chuy·ªÉn ƒë·ªïi c·∫•u tr√∫c SMILES th√†nh ƒë·ªëi t∆∞·ª£ng ph√¢n t·ª≠ v√† t√≠nh to√°n descriptor `MolWt` (Molecular Weight). Cu·ªëi c√πng, n√≥ in ra 5 d√≤ng ƒë·∫ßu c·ªßa DataFrame (This code uses the `pandas` library to read data from a CSV file. Then, it uses RDKit to convert SMILES structures into molecule objects and calculates the `MolWt` descriptor (Molecular Weight). Finally, it prints the first 5 rows of the DataFrame).
*   **L∆∞u √Ω (Note):** ƒê·∫£m b·∫£o b·∫°n ƒë√£ c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán `pandas` v√† `rdkit` tr∆∞·ªõc khi ch·∫°y code (Make sure you have installed the `pandas` and `rdkit` libraries before running the code).

```python
# English
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import os

# Define base path
base_path = "../data"  # Adjust if your actual base path is different

# Construct the full file path
csv_file_path = os.path.join(base_path, "your_data.csv")  # Replace with your actual CSV file name

# Function to calculate molecular weight
def calculate_mol_weight(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.MolWt(mol)
    else:
        return None

# Read the CSV file into a pandas DataFrame
try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"Error: The file {csv_file_path} was not found.")
    exit()

# Apply the function to the 'canonical_smiles' column to create a new 'mol_weight' column
df['mol_weight'] = df['canonical_smiles'].apply(calculate_mol_weight)

# Print the first 5 rows of the DataFrame, including the new 'mol_weight' column
print(df.head())

# Vietnamese
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import os

# X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n g·ªëc
base_path = "../data"  # ƒêi·ªÅu ch·ªânh n·∫øu ƒë∆∞·ªùng d·∫´n g·ªëc th·ª±c t·∫ø c·ªßa b·∫°n kh√°c

# X√¢y d·ª±ng ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn file CSV
csv_file_path = os.path.join(base_path, "your_data.csv")  # Thay th·∫ø b·∫±ng t√™n file CSV th·ª±c t·∫ø c·ªßa b·∫°n

# H√†m t√≠nh to√°n kh·ªëi l∆∞·ª£ng ph√¢n t·ª≠
def calculate_mol_weight(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.MolWt(mol)
    else:
        return None

# ƒê·ªçc file CSV v√†o m·ªôt DataFrame c·ªßa pandas
try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {csv_file_path}.")
    exit()

# √Åp d·ª•ng h√†m cho c·ªôt 'canonical_smiles' ƒë·ªÉ t·∫°o c·ªôt m·ªõi 'mol_weight'
df['mol_weight'] = df['canonical_smiles'].apply(calculate_mol_weight)

# In 5 d√≤ng ƒë·∫ßu ti√™n c·ªßa DataFrame, bao g·ªìm c·ªôt 'mol_weight' m·ªõi
print(df.head())
```

**S·ª≠a l·ªói Python (Fixing Python Error):**

Th√¥ng b√°o l·ªói "phi√™n b·∫£n scikit-learn c≈© kh√¥ng h·ªó tr·ª£ tham s·ªë squared=False trong h√†m mean_squared_error" cho bi·∫øt r·∫±ng phi√™n b·∫£n scikit-learn b·∫°n ƒëang s·ª≠ d·ª•ng qu√° c≈© v√† kh√¥ng h·ªó tr·ª£ tham s·ªë `squared=False` trong h√†m `mean_squared_error`.  ƒê·ªÉ kh·∫Øc ph·ª•c, b·∫°n c√≥ hai l·ª±a ch·ªçn:

1.  **N√¢ng c·∫•p scikit-learn (Upgrade scikit-learn):**  ƒê√¢y l√† c√°ch t·ªët nh·∫•t.  S·ª≠ d·ª•ng pip ƒë·ªÉ n√¢ng c·∫•p l√™n phi√™n b·∫£n m·ªõi nh·∫•t:

    ```bash
    pip install --upgrade scikit-learn
    ```

2.  **T√≠nh RMSE th·ªß c√¥ng (Calculate RMSE manually):** N·∫øu b·∫°n kh√¥ng th·ªÉ n√¢ng c·∫•p scikit-learn, b·∫°n c√≥ th·ªÉ t√≠nh cƒÉn b·∫≠c hai c·ªßa MSE ƒë·ªÉ c√≥ ƒë∆∞·ª£c RMSE:

    ```python
    from sklearn.metrics import mean_squared_error
    import numpy as np

    # T√≠nh MSE
    mse = mean_squared_error(y_true, y_pred)

    # T√≠nh RMSE b·∫±ng c√°ch l·∫•y cƒÉn b·∫≠c hai c·ªßa MSE
    rmse = np.sqrt(mse)
    print(f"RMSE: {rmse}")
    ```

**3. V√≠ d·ª• code (Code Examples)**

D∆∞·ªõi ƒë√¢y l√† 5 v√≠ d·ª• code SQL v√† Python m·∫´u, minh h·ªça c√°c t√°c v·ª• kh√°c nhau trong quy tr√¨nh ph√¢n t√≠ch d·ªØ li·ªáu ChEMBL 35:

**V√≠ d·ª• 1: Tr√≠ch xu·∫•t d·ªØ li·ªáu v√† t√≠nh logP (Example 1: Data Extraction and logP Calculation)**

*   **SQL (English/Vietnamese):**

```sql
-- English
-- Extract SMILES and IC50 values for a specific target and calculate logP using RDKit in Python
SELECT
    cs.canonical_smiles,
    act.standard_value
FROM
    activities act
JOIN
    activity_properties ap ON act.activity_id = ap.activity_id
JOIN
    assays ass ON act.assay_id = ass.assay_id
JOIN
    compound_structures cs ON act.molregno = cs.molregno
JOIN
    target_dictionary td ON ass.tid = td.tid
WHERE
    td.target_chembl_id = 'CHEMBL205'
    AND act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.standard_value IS NOT NULL
LIMIT 100;

-- Vietnamese
-- Tr√≠ch xu·∫•t gi√° tr·ªã SMILES v√† IC50 cho m·ªôt m·ª•c ti√™u c·ª• th·ªÉ v√† t√≠nh logP b·∫±ng RDKit trong Python
SELECT
    cs.canonical_smiles,
    act.standard_value
FROM
    activities act
JOIN
    activity_properties ap ON act.activity_id = ap.activity_id
JOIN
    assays ass ON act.assay_id = ass.assay_id
JOIN
    compound_structures cs ON act.molregno = cs.molregno
JOIN
    target_dictionary td ON ass.tid = td.tid
WHERE
    td.target_chembl_id = 'CHEMBL205'
    AND act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.standard_value IS NOT NULL
LIMIT 100;
```

*   **Python (English/Vietnamese):**

```python
# English
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import os

# Define base path
base_path = "../data"  # Adjust if your actual base path is different

# Construct the full file path
csv_file_path = os.path.join(base_path, "your_data.csv")  # Replace with your actual CSV file name

# Function to calculate logP
def calculate_logp(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.MolLogP(mol)
    else:
        return None

# Read the CSV file into a pandas DataFrame
try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"Error: The file {csv_file_path} was not found.")
    exit()

# Apply the function to the 'canonical_smiles' column to create a new 'logp' column
df['logp'] = df['canonical_smiles'].apply(calculate_logp)

# Print the first 5 rows of the DataFrame, including the new 'logp' column
print(df.head())

# Vietnamese
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import os

# X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n g·ªëc
base_path = "../data"  # ƒêi·ªÅu ch·ªânh n·∫øu ƒë∆∞·ªùng d·∫´n g·ªëc th·ª±c t·∫ø c·ªßa b·∫°n kh√°c

# X√¢y d·ª±ng ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn file CSV
csv_file_path = os.path.join(base_path, "your_data.csv")  # Thay th·∫ø b·∫±ng t√™n file CSV th·ª±c t·∫ø c·ªßa b·∫°n

# H√†m t√≠nh to√°n logP
def calculate_logp(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.MolLogP(mol)
    else:
        return None

# ƒê·ªçc file CSV v√†o m·ªôt DataFrame c·ªßa pandas
try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {csv_file_path}.")
    exit()

# √Åp d·ª•ng h√†m cho c·ªôt 'canonical_smiles' ƒë·ªÉ t·∫°o c·ªôt m·ªõi 'logp'
df['logp'] = df['canonical_smiles'].apply(calculate_logp)

# In 5 d√≤ng ƒë·∫ßu ti√™n c·ªßa DataFrame, bao g·ªìm c·ªôt 'logp' m·ªõi
print(df.head())
```

**V√≠ d·ª• 2: T√≠nh to√°n fingerprints (Example 2: Fingerprint Calculation)**

*   **Python (English/Vietnamese):**

```python
# English
import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem
import os

# Define base path
base_path = "../data"  # Adjust if your actual base path is different

# Construct the full file path
csv_file_path = os.path.join(base_path, "your_data.csv")  # Replace with your actual CSV file name

# Function to calculate Morgan fingerprints
def calculate_morgan_fingerprint(smiles, radius=2, nBits=2048):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)
    else:
        return None

# Read the CSV file into a pandas DataFrame
try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"Error: The file {csv_file_path} was not found.")
    exit()

# Apply the function to the 'canonical_smiles' column to create a new 'morgan_fp' column
df['morgan_fp'] = df['canonical_smiles'].apply(calculate_morgan_fingerprint)

# Print the first 5 rows of the DataFrame, including the new 'morgan_fp' column
print(df.head())

# Vietnamese
import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem
import os

# X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n g·ªëc
base_path = "../data"  # ƒêi·ªÅu ch·ªânh n·∫øu ƒë∆∞·ªùng d·∫´n g·ªëc th·ª±c t·∫ø c·ªßa b·∫°n kh√°c

# X√¢y d·ª±ng ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn file CSV
csv_file_path = os.path.join(base_path, "your_data.csv")  # Thay th·∫ø b·∫±ng t√™n file CSV th·ª±c t·∫ø c·ªßa b·∫°n

# H√†m t√≠nh to√°n Morgan fingerprints
def calculate_morgan_fingerprint(smiles, radius=2, nBits=2048):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)
    else:
        return None

# ƒê·ªçc file CSV v√†o m·ªôt DataFrame c·ªßa pandas
try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {csv_file_path}.")
    exit()

# √Åp d·ª•ng h√†m cho c·ªôt 'canonical_smiles' ƒë·ªÉ t·∫°o c·ªôt m·ªõi 'morgan_fp'
df['morgan_fp'] = df['canonical_smiles'].apply(calculate_morgan_fingerprint)

# In 5 d√≤ng ƒë·∫ßu ti√™n c·ªßa DataFrame, bao g·ªìm c·ªôt 'morgan_fp' m·ªõi
print(df.head())
```

**V√≠ d·ª• 3: Chu·∫©n h√≥a d·ªØ li·ªáu ho·∫°t t√≠nh sinh h·ªçc (Example 3: Bioactivity Data Normalization)**

*   **Python (English/Vietnamese):**

```python
# English
import pandas as pd
import numpy as np
import os

# Define base path
base_path = "../data"  # Adjust if your actual base path is different

# Construct the full file path
csv_file_path = os.path.join(base_path, "your_data.csv")  # Replace with your actual CSV file name

# Function to convert IC50 to pIC50
def ic50_to_pic50(ic50):
    if ic50:
        try:
            ic50 = float(ic50)
            if ic50 > 0:
                pIC50 = -np.log10(ic50 * 1e-9)  # Convert nM to M and then to pIC50
                return pIC50
            else:
                return None
        except ValueError:
            return None
    else:
        return None

# Read the CSV file into a pandas DataFrame
try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"Error: The file {csv_file_path} was not found.")
    exit()

# Apply the function to the 'standard_value' column to create a new 'pIC50' column
df['pIC50'] = df['standard_value'].apply(ic50_to_pic50)

# Print the first 5 rows of the DataFrame, including the new 'pIC50' column
print(df.head())

# Vietnamese
import pandas as pd
import numpy as np
import os

# X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n g·ªëc
base_path = "../data"  # ƒêi·ªÅu ch·ªânh n·∫øu ƒë∆∞·ªùng d·∫´n g·ªëc th·ª±c t·∫ø c·ªßa b·∫°n kh√°c

# X√¢y d·ª±ng ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn file CSV
csv_file_path = os.path.join(base_path, "your_data.csv")  # Thay th·∫ø b·∫±ng t√™n file CSV th·ª±c t·∫ø c·ªßa b·∫°n

# H√†m chuy·ªÉn ƒë·ªïi IC50 sang pIC50
def ic50_to_pic50(ic50):
    if ic50:
        try:
            ic50 = float(ic50)
            if ic50 > 0:
                pIC50 = -np.log10(ic50 * 1e-9)  # Chuy·ªÉn ƒë·ªïi nM sang M v√† sau ƒë√≥ sang pIC50
                return pIC50
            else:
                return None
        except ValueError:
            return None
    else:
        return None

# ƒê·ªçc file CSV v√†o m·ªôt DataFrame c·ªßa pandas
try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {csv_file_path}.")
    exit()

# √Åp d·ª•ng h√†m cho c·ªôt 'standard_value' ƒë·ªÉ t·∫°o c·ªôt m·ªõi 'pIC50'
df['pIC50'] = df['standard_value'].apply(ic50_to_pic50)

# In 5 d√≤ng ƒë·∫ßu ti√™n c·ªßa DataFrame, bao g·ªìm c·ªôt 'pIC50' m·ªõi
print(df.head())
```

**V√≠ d·ª• 4: X√¢y d·ª±ng m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh (Example 4: Linear Regression Model Building)**

*   **Python (English/Vietnamese):**

```python
# English
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import numpy as np
import os

# Define base path
base_path = "../data"  # Adjust if your actual base path is different

# Construct the full file path
csv_file_path = os.path.join(base_path, "your_data.csv")  # Replace with your actual CSV file name

# Function to calculate molecular weight
def calculate_mol_weight(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.MolWt(mol)
    else:
        return None

# Read the CSV file into a pandas DataFrame
try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"Error: The file {csv_file_path} was not found.")
    exit()

# Calculate molecular weight
df['mol_weight'] = df['canonical_smiles'].apply(calculate_mol_weight)

# Data preprocessing: Drop rows with missing values
df = df.dropna(subset=['mol_weight', 'standard_value'])

# Prepare data for the model
X = df[['mol_weight']]  # Features
y = df['standard_value']  # Target variable

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)  # Calculate RMSE manually
print(f"Root Mean Squared Error: {rmse}")


# Vietnamese
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import numpy as np
import os

# X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n g·ªëc
base_path = "../data"  # ƒêi·ªÅu ch·ªânh n·∫øu ƒë∆∞·ªùng d·∫´n g·ªëc th·ª±c t·∫ø c·ªßa b·∫°n kh√°c

# X√¢y d·ª±ng ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn file CSV
csv_file_path = os.path.join(base_path, "your_data.csv")  # Thay th·∫ø b·∫±ng t√™n file CSV th·ª±c t·∫ø c·ªßa b·∫°n

# H√†m t√≠nh to√°n kh·ªëi l∆∞·ª£ng ph√¢n t·ª≠
def calculate_mol_weight(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.MolWt(mol)
    else:
        return None

# ƒê·ªçc file CSV v√†o m·ªôt DataFrame c·ªßa pandas
try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {csv_file_path}.")
    exit()

# T√≠nh to√°n kh·ªëi l∆∞·ª£ng ph√¢n t·ª≠
df['mol_weight'] = df['canonical_smiles'].apply(calculate_mol_weight)

# Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu: Lo·∫°i b·ªè c√°c h√†ng c√≥ gi√° tr·ªã b·ªã thi·∫øu
df = df.dropna(subset=['mol_weight', 'standard_value'])

# Chu·∫©n b·ªã d·ªØ li·ªáu cho m√¥ h√¨nh
X = df[['mol_weight']]  # C√°c ƒë·∫∑c tr∆∞ng
y = df['standard_value']  # Bi·∫øn m·ª•c ti√™u

# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# T·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh
model = LinearRegression()
model.fit(X_train, y_train)

# D·ª± ƒëo√°n tr√™n t·∫≠p ki·ªÉm tra
y_pred = model.predict(X_test)

# ƒê√°nh gi√° m√¥ h√¨nh
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)  # T√≠nh RMSE th·ªß c√¥ng
print(f"Sai s·ªë b√¨nh ph∆∞∆°ng g·ªëc trung b√¨nh: {rmse}")
```

**V√≠ d·ª• 5: S·ª≠ d·ª•ng Random Forest ƒë·ªÉ d·ª± ƒëo√°n ho·∫°t t√≠nh (Example 5: Using Random Forest for Activity Prediction)**

*   **Python (English/Vietnamese):**

```python
# English
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import numpy as np
import os

# Define base path
base_path = "../data"  # Adjust if your actual base path is different

# Construct the full file path
csv_file_path = os.path.join(base_path, "your_data.csv")  # Replace with your actual CSV file name

# Function to calculate molecular weight
def calculate_mol_weight(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.MolWt(mol)
    else:
        return None

# Read the CSV file into a pandas DataFrame
try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"Error: The file {csv_file_path} was not found.")
    exit()

# Calculate molecular weight
df['mol_weight'] = df['canonical_smiles'].apply(calculate_mol_weight)

# Data preprocessing: Drop rows with missing values
df = df.dropna(subset=['mol_weight', 'standard_value'])

# Prepare data for the model
X = df[['mol_weight']]  # Features
y = df['standard_value']  # Target variable

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train the Random Forest Regressor model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)  # Calculate RMSE manually
print(f"Root Mean Squared Error: {rmse}")

# Vietnamese
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import numpy as np
import os

# X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n g·ªëc
base_path = "../data"  # ƒêi·ªÅu ch·ªânh n·∫øu ƒë∆∞·ªùng d·∫´n g·ªëc th·ª±c t·∫ø c·ªßa b·∫°n kh√°c

# X√¢y d·ª±ng ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn file CSV
csv_file_path = os.path.join(base_path, "your_data.csv")  # Thay th·∫ø b·∫±ng t√™n file CSV th·ª±c t·∫ø c·ªßa b·∫°n

# H√†m t√≠nh to√°n kh·ªëi l∆∞·ª£ng ph√¢n t·ª≠
def calculate_mol_weight(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.MolWt(mol)
    else:
        return None

# ƒê·ªçc file CSV v√†o m·ªôt DataFrame c·ªßa pandas
try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {csv_file_path}.")
    exit()

# T√≠nh to√°n kh·ªëi l∆∞·ª£ng ph√¢n t·ª≠
df['mol_weight'] = df['canonical_smiles'].apply(calculate_mol_weight)

# Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu: Lo·∫°i b·ªè c√°c h√†ng c√≥ gi√° tr·ªã b·ªã thi·∫øu
df = df.dropna(subset=['mol_weight', 'standard_value'])

# Chu·∫©n b·ªã d·ªØ li·ªáu cho m√¥ h√¨nh
X = df[['mol_weight']]  # C√°c ƒë·∫∑c tr∆∞ng
y = df['standard_value']  # Bi·∫øn m·ª•c ti√™u

# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# T·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh Random Forest Regressor
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# D·ª± ƒëo√°n tr√™n t·∫≠p ki·ªÉm tra
y_pred = model.predict(X_test)

# ƒê√°nh gi√° m√¥ h√¨nh
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)  # T√≠nh RMSE th·ªß c√¥ng
print(f"Sai s·ªë b√¨nh ph∆∞∆°ng g·ªëc trung b√¨nh: {rmse}")
```

**L∆∞u √Ω quan tr·ªçng:**

*   **ƒê∆∞·ªùng d·∫´n file:**  H√£y ch·∫Øc ch·∫Øn r·∫±ng b·∫°n ƒë√£ thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n file CSV (`csv_file_path`) trong c√°c v√≠ d·ª• Python ƒë·ªÉ tr·ªè ƒë·∫øn v·ªã tr√≠ ch√≠nh x√°c c·ªßa file d·ªØ li·ªáu c·ªßa b·∫°n.
*   **Ch·ªçn descriptor:** Trong c√°c v√≠ d·ª• tr√™n, t√¥i ch·ªâ s·ª≠ d·ª•ng `MolWt` (kh·ªëi l∆∞·ª£ng ph√¢n t·ª≠) l√†m m·ªôt descriptor ƒë∆°n gi·∫£n.  Trong th·ª±c t·∫ø, b·∫°n n√™n t√≠nh to√°n v√† s·ª≠ d·ª•ng nhi·ªÅu descriptor kh√°c nhau ƒë·ªÉ m√¥ h√¨nh c√≥ th·ªÉ h·ªçc ƒë∆∞·ª£c c√°c m·ªëi quan h·ªá ph·ª©c t·∫°p h∆°n gi·ªØa c·∫•u tr√∫c v√† ho·∫°t t√≠nh.
*   **T·ªëi ∆∞u h√≥a m√¥ h√¨nh:** C√°c m√¥ h√¨nh h·ªçc m√°y trong c√°c v√≠ d·ª• tr√™n ch·ªâ l√† c√°c v√≠ d·ª• c∆° b·∫£n.  B·∫°n n√™n th·ª≠ nghi·ªám v·ªõi c√°c thu·∫≠t to√°n kh√°c nhau, ƒëi·ªÅu ch·ªânh c√°c si√™u tham s·ªë v√† s·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t nh∆∞ cross-validation ƒë·ªÉ t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh.
*   **ƒê·∫£m b·∫£o k·∫øt n·ªëi:** ƒê·∫£m b·∫£o r·∫±ng m√°y ch·ªß PostgreSQL c·ªßa b·∫°n ƒëang ch·∫°y v√† c√≥ th·ªÉ truy c·∫≠p ƒë∆∞·ª£c t·ª´ m√°y t√≠nh m√† b·∫°n ƒëang ch·∫°y Jupyter Notebook.
*   **AIMLOps:** Nh·ªõ tu√¢n th·ªß c·∫•u tr√∫c th∆∞ m·ª•c AIMLOps Template ƒë·ªÉ d·ª± √°n c·ªßa b·∫°n ƒë∆∞·ª£c t·ªï ch·ª©c m·ªôt c√°ch chuy√™n nghi·ªáp.

T√¥i hy v·ªçng nh·ªØng h∆∞·ªõng d·∫´n v√† v√≠ d·ª• n√†y s·∫Ω gi√∫p b·∫°n b·∫Øt ƒë·∫ßu d·ª± √°n ph√¢n t√≠ch d·ªØ li·ªáu ChEMBL 35 c·ªßa m√¨nh m·ªôt c√°ch hi·ªáu qu·∫£. N·∫øu b·∫°n c√≥ b·∫•t k·ª≥ c√¢u h·ªèi n√†o kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i h·ªèi! Ch√∫c b·∫°n th√†nh c√¥ng!
