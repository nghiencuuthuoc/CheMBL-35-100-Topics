# PharmApp Suite
## ğŸ§  AI for Drug Discovery and Development ğŸ§ª
| Copyright 2025 | NghiÃªn Cá»©u Thuá»‘c | www.nghiencuuthuoc.com | Zalo: +84888999311 |

ğŸ§© Topic: LiÃªn káº¿t ChEMBL vá»›i dá»¯ liá»‡u nhÃ£n FDA
---
Tuyá»‡t vá»i! TÃ´i ráº¥t vui Ä‘Æ°á»£c há»— trá»£ báº¡n trong dá»± Ã¡n phÃ¢n tÃ­ch dá»¯ liá»‡u ChEMBL 35 nÃ y. Vá»›i vai trÃ² lÃ  chuyÃªn gia nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn dÆ°á»£c há»c, tÃ´i sáº½ giÃºp báº¡n xÃ¢y dá»±ng quy trÃ¬nh phÃ¢n tÃ­ch hiá»‡u quáº£, giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» ká»¹ thuáº­t vÃ  cung cáº¥p cÃ¡c vÃ­ dá»¥ code Ä‘á»ƒ báº¡n tham kháº£o.

**Tá»•ng quan dá»± Ã¡n:**

Dá»± Ã¡n nÃ y táº­p trung vÃ o viá»‡c khai thÃ¡c dá»¯ liá»‡u tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u ChEMBL 35, má»™t nguá»“n thÃ´ng tin phong phÃº vá» cÃ¡c há»£p cháº¥t hÃ³a há»c vÃ  hoáº¡t tÃ­nh sinh há»c cá»§a chÃºng. Sá»­ dá»¥ng RDKit Ä‘á»ƒ xá»­ lÃ½ thÃ´ng tin hÃ³a há»c vÃ  Python Ä‘á»ƒ phÃ¢n tÃ­ch dá»¯ liá»‡u, báº¡n cÃ³ thá»ƒ khÃ¡m phÃ¡ cÃ¡c má»‘i quan há»‡ giá»¯a cáº¥u trÃºc phÃ¢n tá»­ vÃ  hoáº¡t tÃ­nh, tá»« Ä‘Ã³ há»— trá»£ quÃ¡ trÃ¬nh thiáº¿t káº¿ vÃ  phÃ¡t triá»ƒn thuá»‘c.

**PhÃ¢n tÃ­ch vÃ  HÆ°á»›ng dáº«n:**

ChÃºng ta sáº½ táº­p trung vÃ o chá»§ Ä‘á» `Topic_CheMBL_35_84`. Äá»ƒ báº¯t Ä‘áº§u, chÃºng ta cáº§n xÃ¡c Ä‘á»‹nh má»¥c tiÃªu cá»¥ thá»ƒ cá»§a chá»§ Ä‘á» nÃ y. VÃ­ dá»¥:

*   **Má»¥c tiÃªu:** XÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n hoáº¡t tÃ­nh á»©c cháº¿ enzyme (vÃ­ dá»¥: IC50) dá»±a trÃªn cáº¥u trÃºc phÃ¢n tá»­ cá»§a cÃ¡c há»£p cháº¥t.
*   **MÃ´ hÃ¬nh phÃ¢n tÃ­ch:**
    1.  **Chuáº©n bá»‹ dá»¯ liá»‡u:**
        *   Káº¿t ná»‘i Ä‘áº¿n cÆ¡ sá»Ÿ dá»¯ liá»‡u ChEMBL 35.
        *   Lá»c dá»¯ liá»‡u theo enzyme má»¥c tiÃªu (target).
        *   LÃ m sáº¡ch dá»¯ liá»‡u hoáº¡t tÃ­nh (activity data), loáº¡i bá» cÃ¡c giÃ¡ trá»‹ khÃ´ng há»£p lá»‡ hoáº·c khÃ´ng Ä‘áº§y Ä‘á»§.
        *   TÃ­nh toÃ¡n cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n tá»­ (molecular descriptors) báº±ng RDKit.
    2.  **XÃ¢y dá»±ng mÃ´ hÃ¬nh:**
        *   Chia dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n (training set) vÃ  táº­p kiá»ƒm tra (test set).
        *   Chá»n thuáº­t toÃ¡n há»c mÃ¡y phÃ¹ há»£p (vÃ­ dá»¥: Random Forest, Support Vector Machine).
        *   Huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn táº­p huáº¥n luyá»‡n.
        *   ÄÃ¡nh giÃ¡ hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh trÃªn táº­p kiá»ƒm tra.
    3.  **Diá»…n giáº£i káº¿t quáº£:**
        *   XÃ¡c Ä‘á»‹nh cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n tá»­ quan trá»ng áº£nh hÆ°á»Ÿng Ä‘áº¿n hoáº¡t tÃ­nh.
        *   Äá» xuáº¥t cÃ¡c cáº£i tiáº¿n cáº¥u trÃºc Ä‘á»ƒ tÄƒng cÆ°á»ng hoáº¡t tÃ­nh.

**HÆ°á»›ng dáº«n song ngá»¯:**

**1. Data Preparation (Chuáº©n bá»‹ dá»¯ liá»‡u):**

*   **SQL:** Extract relevant data from ChEMBL database.
*   **SQL:** TrÃ­ch xuáº¥t dá»¯ liá»‡u liÃªn quan tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u ChEMBL.
*   **Python:** Calculate molecular descriptors using RDKit.
*   **Python:** TÃ­nh toÃ¡n cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n tá»­ báº±ng RDKit.

**2. Model Building (XÃ¢y dá»±ng mÃ´ hÃ¬nh):**

*   **Python:** Train a machine learning model to predict activity.
*   **Python:** Huáº¥n luyá»‡n mÃ´ hÃ¬nh há»c mÃ¡y Ä‘á»ƒ dá»± Ä‘oÃ¡n hoáº¡t tÃ­nh.
*   **Python:** Evaluate model performance using appropriate metrics.
*   **Python:** ÄÃ¡nh giÃ¡ hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh báº±ng cÃ¡c Ä‘á»™ Ä‘o phÃ¹ há»£p.

**3. Interpretation (Diá»…n giáº£i):**

*   **Python:** Identify key molecular features influencing activity.
*   **Python:** XÃ¡c Ä‘á»‹nh cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n tá»­ quan trá»ng áº£nh hÆ°á»Ÿng Ä‘áº¿n hoáº¡t tÃ­nh.
*   **Based on the model, propose structural modifications to improve activity.
*   Dá»±a trÃªn mÃ´ hÃ¬nh, Ä‘á» xuáº¥t cÃ¡c cáº£i tiáº¿n cáº¥u trÃºc Ä‘á»ƒ tÄƒng cÆ°á»ng hoáº¡t tÃ­nh.

**Code SQL:**

```sql
-- Láº¥y 100 há»£p cháº¥t cÃ³ hoáº¡t tÃ­nh trÃªn má»™t má»¥c tiÃªu cá»¥ thá»ƒ (vÃ­ dá»¥: CHEMBL205)
SELECT DISTINCT mol.molregno,
                md.chembl_id,
                act.standard_value,
                act.standard_units
FROM molecule_dictionary mol
    JOIN activities act ON mol.molregno = act.molregno
    JOIN assay_xref ax ON act.assay_id = ax.assay_id
    JOIN target_dictionary td ON ax.tid = td.tid
    JOIN compound_structures cs ON mol.molregno = cs.molregno
WHERE td.chembl_id = 'CHEMBL205'
  AND act.standard_type = 'IC50'
  AND act.standard_relation = '='
  AND act.standard_value IS NOT NULL
LIMIT 100;

-- Sá»­a lá»—i liÃªn quan Ä‘áº¿n kiá»ƒu dá»¯ liá»‡u trong Ä‘iá»u kiá»‡n lá»c
-- Chuyá»ƒn Ä‘á»•i giÃ¡ trá»‹ standard_value sang kiá»ƒu numeric trÆ°á»›c khi so sÃ¡nh
SELECT DISTINCT mol.molregno,
                md.chembl_id,
                act.standard_value,
                act.standard_units
FROM molecule_dictionary mol
    JOIN activities act ON mol.molregno = act.molregno
    JOIN assay_xref ax ON act.assay_id = ax.assay_id
    JOIN target_dictionary td ON ax.tid = td.tid
    JOIN compound_structures cs ON mol.molregno = cs.molregno
WHERE td.chembl_id = 'CHEMBL205'
  AND act.standard_type = 'IC50'
  AND act.standard_relation = '='
  AND act.standard_value IS NOT NULL
  AND act.standard_value::TEXT ~ '^[0-9\.]+$' -- Kiá»ƒm tra xem giÃ¡ trá»‹ cÃ³ pháº£i lÃ  sá»‘
LIMIT 100;
```

**Code Python:**

```python
import os
import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem
from rdkit.Chem import Descriptors
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n
base_path = os.getcwd()  # ÄÆ°á»ng dáº«n thÆ° má»¥c gá»‘c cá»§a dá»± Ã¡n
data_path = os.path.join(base_path, 'data')
notebook_path = os.path.join(base_path, 'notebooks')

# Äá»c dá»¯ liá»‡u tá»« file CSV
data = pd.read_csv(os.path.join(data_path, 'chembl_data.csv'))

# HÃ m tÃ­nh toÃ¡n Ä‘áº·c trÆ°ng phÃ¢n tá»­
def calculate_descriptors(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    descriptors = {}
    descriptors['MolLogP'] = Descriptors.MolLogP(mol)
    descriptors['MolWt'] = Descriptors.MolWt(mol)
    descriptors['NumHAcceptors'] = Descriptors.NumHAcceptors(mol)
    descriptors['NumHDonors'] = Descriptors.NumHDonors(mol)
    return descriptors

# Ãp dá»¥ng hÃ m tÃ­nh toÃ¡n Ä‘áº·c trÆ°ng
data['descriptors'] = data['canonical_smiles'].apply(calculate_descriptors)
data = data.dropna(subset=['descriptors'])

# Chuyá»ƒn Ä‘á»•i Ä‘áº·c trÆ°ng thÃ nh DataFrame
descriptors_df = pd.DataFrame(data['descriptors'].tolist())
data = pd.concat([data, descriptors_df], axis=1)

# Chuáº©n bá»‹ dá»¯ liá»‡u cho mÃ´ hÃ¬nh
X = data[['MolLogP', 'MolWt', 'NumHAcceptors', 'NumHDonors']]
y = data['standard_value']

# Chia dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n vÃ  táº­p kiá»ƒm tra
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# XÃ¢y dá»±ng mÃ´ hÃ¬nh Random Forest
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R2 Score: {r2}')
```

**Giáº£i thÃ­ch code:**

1.  **Import thÆ° viá»‡n:** Nháº­p cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t nhÆ° `os`, `pandas`, `rdkit`, vÃ  `sklearn`.
2.  **Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n:** XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n Ä‘áº¿n cÃ¡c thÆ° má»¥c chá»©a dá»¯ liá»‡u vÃ  notebook.
3.  **Äá»c dá»¯ liá»‡u:** Äá»c dá»¯ liá»‡u tá»« file CSV vÃ o DataFrame.
4.  **TÃ­nh toÃ¡n Ä‘áº·c trÆ°ng phÃ¢n tá»­:**
    *   Äá»‹nh nghÄ©a hÃ m `calculate_descriptors` Ä‘á»ƒ tÃ­nh toÃ¡n cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n tá»­ tá»« SMILES.
    *   Ãp dá»¥ng hÃ m nÃ y cho cá»™t `canonical_smiles` trong DataFrame.
5.  **Chuáº©n bá»‹ dá»¯ liá»‡u:**
    *   Chá»n cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n tá»­ lÃ m biáº¿n Ä‘á»™c láº­p (X) vÃ  giÃ¡ trá»‹ hoáº¡t tÃ­nh (IC50) lÃ m biáº¿n phá»¥ thuá»™c (y).
    *   Chia dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n vÃ  táº­p kiá»ƒm tra.
6.  **XÃ¢y dá»±ng mÃ´ hÃ¬nh:**
    *   Khá»Ÿi táº¡o mÃ´ hÃ¬nh Random Forest.
    *   Huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn táº­p huáº¥n luyá»‡n.
7.  **ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh:**
    *   Dá»± Ä‘oÃ¡n giÃ¡ trá»‹ hoáº¡t tÃ­nh trÃªn táº­p kiá»ƒm tra.
    *   TÃ­nh toÃ¡n Mean Squared Error (MSE) vÃ  R2 Score Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh.

**VÃ­ dá»¥ code bá»• sung:**

**VÃ­ dá»¥ 1: Lá»c dá»¯ liá»‡u theo khoáº£ng giÃ¡ trá»‹ hoáº¡t tÃ­nh:**

```sql
-- Láº¥y cÃ¡c há»£p cháº¥t cÃ³ IC50 tá»« 100 nM Ä‘áº¿n 1000 nM
SELECT DISTINCT mol.molregno,
                md.chembl_id,
                act.standard_value,
                act.standard_units
FROM molecule_dictionary mol
    JOIN activities act ON mol.molregno = act.molregno
    JOIN assay_xref ax ON act.assay_id = ax.assay_id
    JOIN target_dictionary td ON ax.tid = td.tid
WHERE td.chembl_id = 'CHEMBL205'
  AND act.standard_type = 'IC50'
  AND act.standard_relation = '='
  AND act.standard_value BETWEEN 100 AND 1000
  AND act.standard_units = 'nM'
LIMIT 100;
```

```python
# Lá»c dá»¯ liá»‡u theo khoáº£ng giÃ¡ trá»‹ hoáº¡t tÃ­nh
data_filtered = data[(data['standard_value'] >= 100) & (data['standard_value'] <= 1000)]
```

**VÃ­ dá»¥ 2: TÃ­nh toÃ¡n TPSA báº±ng RDKit:**

```python
from rdkit.Chem import rdMolDescriptors

def calculate_tpsa(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    tpsa = rdMolDescriptors.CalcTPSA(mol)
    return tpsa

data['tpsa'] = data['canonical_smiles'].apply(calculate_tpsa)
```

**VÃ­ dá»¥ 3: Sá»­ dá»¥ng Support Vector Machine (SVM) cho mÃ´ hÃ¬nh hÃ³a:**

```python
from sklearn.svm import SVR

# Khá»Ÿi táº¡o mÃ´ hÃ¬nh SVM
model = SVR(kernel='rbf')
model.fit(X_train, y_train)

# Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R2 Score: {r2}')
```

**VÃ­ dá»¥ 4: LÆ°u trá»¯ káº¿t quáº£ vÃ o file CSV:**

```python
results = pd.DataFrame({'actual': y_test, 'predicted': y_pred})
results.to_csv(os.path.join(data_path, 'predictions.csv'), index=False)
```

**VÃ­ dá»¥ 5: Sá»­ dá»¥ng PCA Ä‘á»ƒ giáº£m chiá»u dá»¯ liá»‡u:**

```python
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Chuáº©n hÃ³a dá»¯ liá»‡u
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Giáº£m chiá»u dá»¯ liá»‡u xuá»‘ng 2 chiá»u
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# Táº¡o DataFrame tá»« dá»¯ liá»‡u PCA
X_pca_df = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])
```

**LÆ°u Ã½ vá» lá»—i:**

*   **Lá»—i SQL:** Lá»—i `operator does not exist: numeric ~ unknown` xáº£y ra do báº¡n Ä‘ang cá»‘ gáº¯ng so sÃ¡nh má»™t giÃ¡ trá»‹ sá»‘ (`act.standard_value`) vá»›i má»™t chuá»—i (`'^[0-9\.]+$'`). Äá»ƒ kháº¯c phá»¥c, báº¡n cáº§n Ä‘áº£m báº£o ráº±ng cáº£ hai váº¿ cá»§a phÃ©p so sÃ¡nh Ä‘á»u cÃ³ cÃ¹ng kiá»ƒu dá»¯ liá»‡u. Trong trÆ°á»ng há»£p nÃ y, báº¡n cÃ³ thá»ƒ chuyá»ƒn Ä‘á»•i `act.standard_value` sang kiá»ƒu chuá»—i báº±ng cÃ¡ch sá»­ dá»¥ng `act.standard_value::TEXT`.
*   **Lá»—i scikit-learn:** Náº¿u báº¡n gáº·p lá»—i `squared=False` khÃ´ng Ä‘Æ°á»£c há»— trá»£, hÃ£y nÃ¢ng cáº¥p phiÃªn báº£n scikit-learn cá»§a báº¡n lÃªn phiÃªn báº£n má»›i nháº¥t.

**Káº¿t luáº­n:**

Hy vá»ng nhá»¯ng hÆ°á»›ng dáº«n vÃ  vÃ­ dá»¥ nÃ y sáº½ giÃºp báº¡n báº¯t Ä‘áº§u dá»± Ã¡n phÃ¢n tÃ­ch dá»¯ liá»‡u ChEMBL 35 má»™t cÃ¡ch hiá»‡u quáº£. HÃ£y nhá»› ráº±ng, viá»‡c thá»­ nghiá»‡m vÃ  Ä‘iá»u chá»‰nh mÃ´ hÃ¬nh lÃ  ráº¥t quan trá»ng Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ tá»‘t nháº¥t. ChÃºc báº¡n thÃ nh cÃ´ng!