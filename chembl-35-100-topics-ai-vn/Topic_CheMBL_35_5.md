# PharmApp Suite
## ğŸ§  AI for Drug Discovery and Development ğŸ§ª
| Copyright 2025 | NghiÃªn Cá»©u Thuá»‘c | www.nghiencuuthuoc.com | Zalo: +84888999311 |

ğŸ§© Topic: PhÃ¢n tÃ­ch tÃ­nh giá»‘ng thuá»‘c báº±ng RDKit
---
Tuyá»‡t vá»i! TÃ´i ráº¥t vui Ä‘Æ°á»£c há»— trá»£ báº¡n trong dá»± Ã¡n phÃ¢n tÃ­ch dá»¯ liá»‡u ChEMBL 35 sá»­ dá»¥ng RDKit. Vá»›i vai trÃ² lÃ  má»™t chuyÃªn gia R&D DÆ°á»£c há»c, tÃ´i sáº½ cung cáº¥p cho báº¡n hÆ°á»›ng dáº«n chi tiáº¿t, code máº«u vÃ  giáº£i thÃ­ch Ä‘á»ƒ báº¡n cÃ³ thá»ƒ triá»ƒn khai dá»± Ã¡n má»™t cÃ¡ch hiá»‡u quáº£.

**Tá»•ng quan dá»± Ã¡n:**

Dá»± Ã¡n nÃ y táº­p trung vÃ o viá»‡c khai thÃ¡c dá»¯ liá»‡u tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u ChEMBL 35, káº¿t há»£p vá»›i cÃ¡c cÃ´ng cá»¥ tin sinh há»c nhÆ° RDKit, Ä‘á»ƒ há»— trá»£ quÃ¡ trÃ¬nh nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn thuá»‘c. Báº¡n sáº½ sá»­ dá»¥ng SQL Ä‘á»ƒ truy váº¥n vÃ  trÃ­ch xuáº¥t dá»¯ liá»‡u tá»« ChEMBL, sau Ä‘Ã³ sá»­ dá»¥ng Python (vá»›i RDKit vÃ  cÃ¡c thÆ° viá»‡n liÃªn quan) Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  mÃ´ hÃ¬nh hÃ³a dá»¯ liá»‡u.

**Cáº¥u trÃºc thÆ° má»¥c dá»± Ã¡n (tuÃ¢n theo AIMLOps Template):**

```
â”œâ”€â”€ data/
â”‚   â””â”€â”€ *.csv  # Dá»¯ liá»‡u trÃ­ch xuáº¥t tá»« SQL
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Topic_CheMBL_35_5_1_*.ipynb
â”‚   â””â”€â”€ Topic_CheMBL_35_5_2_*.ipynb
â”œâ”€â”€ src/
â”‚   â””â”€â”€ # (Optional) CÃ¡c module Python tÃ¹y chá»‰nh
â””â”€â”€ README.md
```

**1. PhÃ¢n tÃ­ch mÃ´ hÃ¬nh phÃ¢n tÃ­ch (Analysis Model):**

Chá»§ Ä‘á» `Topic_CheMBL_35_5` cÃ³ thá»ƒ táº­p trung vÃ o nhiá»u khÃ­a cáº¡nh khÃ¡c nhau cá»§a quÃ¡ trÃ¬nh phÃ¡t triá»ƒn thuá»‘c. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ mÃ´ hÃ¬nh phÃ¢n tÃ­ch tiá»m nÄƒng, cÃ¹ng vá»›i hÆ°á»›ng dáº«n vÃ  code máº«u:

*   **MÃ´ hÃ¬nh 1: PhÃ¢n tÃ­ch má»‘i tÆ°Æ¡ng quan giá»¯a cáº¥u trÃºc hÃ³a há»c vÃ  hoáº¡t tÃ­nh sinh há»c (SAR/QSAR):**
    *   **Má»¥c tiÃªu:** XÃ¡c Ä‘á»‹nh cÃ¡c nhÃ³m chá»©c hoáº·c Ä‘áº·c Ä‘iá»ƒm cáº¥u trÃºc nÃ o áº£nh hÆ°á»Ÿng Ä‘áº¿n hoáº¡t tÃ­nh cá»§a má»™t há»£p cháº¥t Ä‘á»‘i vá»›i má»™t má»¥c tiÃªu sinh há»c cá»¥ thá»ƒ.
    *   **PhÆ°Æ¡ng phÃ¡p:**
        1.  **TrÃ­ch xuáº¥t dá»¯ liá»‡u:** Láº¥y dá»¯ liá»‡u vá» cáº¥u trÃºc hÃ³a há»c (SMILES) vÃ  hoáº¡t tÃ­nh sinh há»c (vÃ­ dá»¥: IC50, Ki) cá»§a cÃ¡c há»£p cháº¥t tá»« ChEMBL.
        2.  **TÃ­nh toÃ¡n descriptor:** Sá»­ dá»¥ng RDKit Ä‘á»ƒ tÃ­nh toÃ¡n cÃ¡c descriptor phÃ¢n tá»­ (vÃ­ dá»¥: trá»ng lÆ°á»£ng phÃ¢n tá»­, logP, sá»‘ lÆ°á»£ng liÃªn káº¿t hydro, diá»‡n tÃ­ch bá» máº·t phÃ¢n cá»±c).
        3.  **PhÃ¢n tÃ­ch tÆ°Æ¡ng quan:** Sá»­ dá»¥ng cÃ¡c phÆ°Æ¡ng phÃ¡p thá»‘ng kÃª (vÃ­ dá»¥: há»“i quy tuyáº¿n tÃ­nh, random forest) Ä‘á»ƒ tÃ¬m má»‘i tÆ°Æ¡ng quan giá»¯a cÃ¡c descriptor vÃ  hoáº¡t tÃ­nh sinh há»c.
    *   **á»¨ng dá»¥ng:** Dá»± Ä‘oÃ¡n hoáº¡t tÃ­nh cá»§a cÃ¡c há»£p cháº¥t má»›i, tá»‘i Æ°u hÃ³a cáº¥u trÃºc há»£p cháº¥t Ä‘á»ƒ cáº£i thiá»‡n hoáº¡t tÃ­nh.
*   **MÃ´ hÃ¬nh 2: PhÃ¢n tÃ­ch Ä‘a dáº¡ng hÃ³a há»c (Chemical Diversity Analysis):**
    *   **Má»¥c tiÃªu:** ÄÃ¡nh giÃ¡ sá»± Ä‘a dáº¡ng cá»§a má»™t táº­p há»£p cÃ¡c há»£p cháº¥t, xÃ¡c Ä‘á»‹nh cÃ¡c há»£p cháº¥t Ä‘áº¡i diá»‡n cho cÃ¡c vÃ¹ng khÃ¡c nhau trong khÃ´ng gian hÃ³a há»c.
    *   **PhÆ°Æ¡ng phÃ¡p:**
        1.  **TÃ­nh toÃ¡n fingerprint:** Sá»­ dá»¥ng RDKit Ä‘á»ƒ táº¡o fingerprint cho cÃ¡c há»£p cháº¥t (vÃ­ dá»¥: Morgan fingerprint, MACCS keys).
        2.  **PhÃ¢n tÃ­ch thÃ nh pháº§n chÃ­nh (PCA) hoáº·c t-SNE:** Giáº£m chiá»u dá»¯ liá»‡u fingerprint Ä‘á»ƒ trá»±c quan hÃ³a khÃ´ng gian hÃ³a há»c.
        3.  **PhÃ¢n cá»¥m (clustering):** PhÃ¢n nhÃ³m cÃ¡c há»£p cháº¥t dá»±a trÃªn sá»± tÆ°Æ¡ng Ä‘á»“ng vá» cáº¥u trÃºc.
    *   **á»¨ng dá»¥ng:** Lá»±a chá»n cÃ¡c há»£p cháº¥t Ä‘áº¡i diá»‡n cho thá»­ nghiá»‡m sÃ ng lá»c, thiáº¿t káº¿ thÆ° viá»‡n há»£p cháº¥t Ä‘a dáº¡ng.
*   **MÃ´ hÃ¬nh 3: Dá»± Ä‘oÃ¡n tÃ­nh cháº¥t háº¥p thá»¥, phÃ¢n bá»‘, chuyá»ƒn hÃ³a, tháº£i trá»« (ADMET):**
    *   **Má»¥c tiÃªu:** Dá»± Ä‘oÃ¡n cÃ¡c tÃ­nh cháº¥t dÆ°á»£c Ä‘á»™ng há»c cá»§a má»™t há»£p cháº¥t, giÃºp Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng trá»Ÿ thÃ nh thuá»‘c tiá»m nÄƒng.
    *   **PhÆ°Æ¡ng phÃ¡p:**
        1.  **TÃ­nh toÃ¡n descriptor:** Sá»­ dá»¥ng RDKit Ä‘á»ƒ tÃ­nh toÃ¡n cÃ¡c descriptor phÃ¢n tá»­ liÃªn quan Ä‘áº¿n ADMET (vÃ­ dá»¥: logP, diá»‡n tÃ­ch bá» máº·t phÃ¢n cá»±c).
        2.  **Sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n:** Ãp dá»¥ng cÃ¡c mÃ´ hÃ¬nh mÃ¡y há»c (vÃ­ dá»¥: random forest, SVM) hoáº·c cÃ¡c quy táº¯c dá»±a trÃªn cáº¥u trÃºc Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¡c tÃ­nh cháº¥t ADMET (vÃ­ dá»¥: kháº£ nÄƒng háº¥p thá»¥ qua Ä‘Æ°á»ng uá»‘ng, kháº£ nÄƒng xÃ¢m nháº­p hÃ ng rÃ o mÃ¡u nÃ£o).
    *   **á»¨ng dá»¥ng:** Lá»c bá» cÃ¡c há»£p cháº¥t cÃ³ tÃ­nh cháº¥t ADMET khÃ´ng phÃ¹ há»£p, tá»‘i Æ°u hÃ³a cáº¥u trÃºc há»£p cháº¥t Ä‘á»ƒ cáº£i thiá»‡n tÃ­nh cháº¥t ADMET.

**2. HÆ°á»›ng dáº«n song ngá»¯ (Bilingual Instructions):**

*   **(English)**: This project focuses on analyzing ChEMBL 35 data using RDKit to support drug discovery and development. You will use SQL to query and extract data, then use Python (with RDKit) to analyze and model the data.
*   **(Tiáº¿ng Viá»‡t)**: Dá»± Ã¡n nÃ y táº­p trung vÃ o phÃ¢n tÃ­ch dá»¯ liá»‡u ChEMBL 35 sá»­ dá»¥ng RDKit Ä‘á»ƒ há»— trá»£ nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn thuá»‘c. Báº¡n sáº½ sá»­ dá»¥ng SQL Ä‘á»ƒ truy váº¥n vÃ  trÃ­ch xuáº¥t dá»¯ liá»‡u, sau Ä‘Ã³ sá»­ dá»¥ng Python (vá»›i RDKit) Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  mÃ´ hÃ¬nh hÃ³a dá»¯ liá»‡u.

**3. Code SQL vÃ  Python máº«u (SQL and Python Code Examples):**

**SQL (vÃ­ dá»¥ 1): Láº¥y 100 há»£p cháº¥t á»©c cháº¿ enzyme cÃ³ IC50 < 100 nM**

```sql
-- English
SELECT
    m.chembl_id,
    cs.canonical_smiles,
    act.standard_value,
    act.standard_units
FROM
    activities act
JOIN
    molecule_dictionary m ON act.molregno = m.molregno
JOIN
    compound_structures cs ON m.molregno = cs.molregno
JOIN
    target_dictionary td ON act.tid = td.tid
WHERE
    td.target_type = 'SINGLE PROTEIN'
    AND act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.standard_value IS NOT NULL
    AND act.standard_value > 0  -- Ensure positive values
    AND act.standard_value <= 100
LIMIT 100;

--Tiáº¿ng Viá»‡t
--Láº¥y 100 há»£p cháº¥t á»©c cháº¿ enzyme cÃ³ IC50 < 100 nM
SELECT
    m.chembl_id,
    cs.canonical_smiles,
    act.standard_value,
    act.standard_units
FROM
    activities act
JOIN
    molecule_dictionary m ON act.molregno = m.molregno
JOIN
    compound_structures cs ON m.molregno = cs.molregno
JOIN
    target_dictionary td ON act.tid = td.tid
WHERE
    td.target_type = 'SINGLE PROTEIN'
    AND act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.standard_value IS NOT NULL
    AND act.standard_value > 0  -- Äáº£m báº£o giÃ¡ trá»‹ dÆ°Æ¡ng
    AND act.standard_value <= 100
LIMIT 100;
```

**Python (vÃ­ dá»¥ 1): TÃ­nh toÃ¡n descriptor phÃ¢n tá»­ vÃ  váº½ biá»ƒu Ä‘á»“**

```python
# English
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import matplotlib.pyplot as plt

# Load data from CSV file
base_path = "." # Thay Ä‘á»•i náº¿u cáº§n
data_path = os.path.join(base_path, "data", "your_data.csv")  # Replace "your_data.csv"
df = pd.read_csv(data_path)

# Function to calculate molecular weight
def calculate_mw(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.MolWt(mol)
    else:
        return None

# Apply the function to the SMILES column
df['molecular_weight'] = df['canonical_smiles'].apply(calculate_mw)

# Remove rows with NaN values in 'molecular_weight'
df = df.dropna(subset=['molecular_weight'])

# Plotting the distribution of molecular weights
plt.figure(figsize=(10, 6))
plt.hist(df['molecular_weight'], bins=50, color='skyblue', edgecolor='black')
plt.title('Distribution of Molecular Weights')
plt.xlabel('Molecular Weight (Da)')
plt.ylabel('Frequency')
plt.grid(True)
plt.show()


#Tiáº¿ng Viá»‡t
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import matplotlib.pyplot as plt

# Táº£i dá»¯ liá»‡u tá»« file CSV
base_path = "." # Thay Ä‘á»•i náº¿u cáº§n
data_path = os.path.join(base_path, "data", "your_data.csv")  # Thay tháº¿ "your_data.csv"
df = pd.read_csv(data_path)

# HÃ m tÃ­nh toÃ¡n trá»ng lÆ°á»£ng phÃ¢n tá»­
def calculate_mw(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.MolWt(mol)
    else:
        return None

# Ãp dá»¥ng hÃ m cho cá»™t SMILES
df['molecular_weight'] = df['canonical_smiles'].apply(calculate_mw)

# Loáº¡i bá» cÃ¡c hÃ ng cÃ³ giÃ¡ trá»‹ NaN trong cá»™t 'molecular_weight'
df = df.dropna(subset=['molecular_weight'])


# Váº½ biá»ƒu Ä‘á»“ phÃ¢n bá»‘ trá»ng lÆ°á»£ng phÃ¢n tá»­
plt.figure(figsize=(10, 6))
plt.hist(df['molecular_weight'], bins=50, color='skyblue', edgecolor='black')
plt.title('PhÃ¢n bá»‘ trá»ng lÆ°á»£ng phÃ¢n tá»­')
plt.xlabel('Trá»ng lÆ°á»£ng phÃ¢n tá»­ (Da)')
plt.ylabel('Táº§n sá»‘')
plt.grid(True)
plt.show()
```

**4. VÃ­ dá»¥ code SQL vÃ  Python máº«u (SQL and Python Code Examples):**

**SQL (vÃ­ dá»¥ 2): Láº¥y sá»‘ lÆ°á»£ng há»£p cháº¥t cho má»—i loáº¡i má»¥c tiÃªu (target type)**

```sql
-- English
SELECT td.target_type, COUNT(DISTINCT m.molregno) AS num_compounds
FROM target_dictionary td
JOIN activities act ON td.tid = act.tid
JOIN molecule_dictionary m ON act.molregno = m.molregno
GROUP BY td.target_type
ORDER BY num_compounds DESC
LIMIT 10;

-- Tiáº¿ng Viá»‡t
-- Láº¥y sá»‘ lÆ°á»£ng há»£p cháº¥t cho má»—i loáº¡i má»¥c tiÃªu (target type)
SELECT td.target_type, COUNT(DISTINCT m.molregno) AS num_compounds
FROM target_dictionary td
JOIN activities act ON td.tid = act.tid
JOIN molecule_dictionary m ON act.molregno = m.molregno
GROUP BY td.target_type
ORDER BY num_compounds DESC
LIMIT 10;
```

**Python (vÃ­ dá»¥ 2): TÃ­nh toÃ¡n LogP vÃ  váº½ scatter plot vá»›i IC50**

```python
# English
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import matplotlib.pyplot as plt
import numpy as np

# Load data from CSV (replace 'your_data.csv' with your actual file)
base_path = "." # Thay Ä‘á»•i náº¿u cáº§n
data_path = os.path.join(base_path, "data", "your_data.csv")  # Replace "your_data.csv"
df = pd.read_csv(data_path)

# Convert IC50 to numeric, handling potential errors
df['standard_value'] = pd.to_numeric(df['standard_value'], errors='coerce')
df = df.dropna(subset=['standard_value'])

# Function to calculate LogP
def calculate_logp(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.MolLogP(mol)
    else:
        return None

# Apply the function to the SMILES column
df['logp'] = df['canonical_smiles'].apply(calculate_logp)

# Remove rows with NaN values in 'logp'
df = df.dropna(subset=['logp'])

# Ensure standard_value is numeric and convert to pIC50
df['pIC50'] = -np.log10(df['standard_value'] * 1e-9)  # Convert nM to M and then to pIC50

# Create the scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(df['logp'], df['pIC50'], alpha=0.5)
plt.xlabel('LogP')
plt.ylabel('pIC50')
plt.title('LogP vs pIC50')
plt.grid(True)
plt.show()


# Tiáº¿ng Viá»‡t
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import matplotlib.pyplot as plt
import numpy as np

# Táº£i dá»¯ liá»‡u tá»« file CSV (thay 'your_data.csv' báº±ng tÃªn file cá»§a báº¡n)
base_path = "." # Thay Ä‘á»•i náº¿u cáº§n
data_path = os.path.join(base_path, "data", "your_data.csv")  # Thay tháº¿ "your_data.csv"
df = pd.read_csv(data_path)

# Chuyá»ƒn Ä‘á»•i IC50 sang dáº¡ng sá»‘, xá»­ lÃ½ cÃ¡c lá»—i cÃ³ thá»ƒ xáº£y ra
df['standard_value'] = pd.to_numeric(df['standard_value'], errors='coerce')
df = df.dropna(subset=['standard_value'])

# HÃ m tÃ­nh toÃ¡n LogP
def calculate_logp(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return Descriptors.MolLogP(mol)
    else:
        return None

# Ãp dá»¥ng hÃ m cho cá»™t SMILES
df['logp'] = df['canonical_smiles'].apply(calculate_logp)

# Loáº¡i bá» cÃ¡c hÃ ng cÃ³ giÃ¡ trá»‹ NaN trong cá»™t 'logp'
df = df.dropna(subset=['logp'])

# Äáº£m báº£o standard_value lÃ  sá»‘ vÃ  chuyá»ƒn Ä‘á»•i sang pIC50
df['pIC50'] = -np.log10(df['standard_value'] * 1e-9)  # Chuyá»ƒn Ä‘á»•i nM sang M vÃ  sau Ä‘Ã³ sang pIC50

# Táº¡o biá»ƒu Ä‘á»“ phÃ¢n tÃ¡n
plt.figure(figsize=(10, 6))
plt.scatter(df['logp'], df['pIC50'], alpha=0.5)
plt.xlabel('LogP')
plt.ylabel('pIC50')
plt.title('LogP so vá»›i pIC50')
plt.grid(True)
plt.show()
```

**SQL (vÃ­ dá»¥ 3): Láº¥y cÃ¡c há»£p cháº¥t cÃ³ trá»ng lÆ°á»£ng phÃ¢n tá»­ náº±m trong khoáº£ng 200-500 Da**

```sql
-- English
SELECT
    m.chembl_id,
    cs.canonical_smiles
FROM
    molecule_dictionary m
JOIN
    compound_structures cs ON m.molregno = cs.molregno
WHERE m.molregno IN (SELECT molregno FROM molecule_properties WHERE mw_freebase BETWEEN 200 AND 500)
LIMIT 100;

-- Tiáº¿ng Viá»‡t
-- Láº¥y cÃ¡c há»£p cháº¥t cÃ³ trá»ng lÆ°á»£ng phÃ¢n tá»­ náº±m trong khoáº£ng 200-500 Da
SELECT
    m.chembl_id,
    cs.canonical_smiles
FROM
    molecule_dictionary m
JOIN
    compound_structures cs ON m.molregno = m.molregno
WHERE m.molregno IN (SELECT molregno FROM molecule_properties WHERE mw_freebase BETWEEN 200 AND 500)
LIMIT 100;
```

**Python (vÃ­ dá»¥ 3): TÃ­nh toÃ¡n fingerprint Morgan vÃ  phÃ¢n tÃ­ch PCA**

```python
# English
import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np

# Load data (replace 'your_data.csv' with your actual file)
base_path = "." # Thay Ä‘á»•i náº¿u cáº§n
data_path = os.path.join(base_path, "data", "your_data.csv")  # Replace "your_data.csv"
df = pd.read_csv(data_path)

# Function to generate Morgan Fingerprint
def generate_morgan_fingerprint(smiles, radius=2, nBits=2048):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)
    else:
        return None

# Apply the function to the SMILES column
df['morgan_fp'] = df['canonical_smiles'].apply(generate_morgan_fingerprint)

# Remove rows where fingerprint generation failed
df = df.dropna(subset=['morgan_fp'])

# Convert fingerprints to a numpy array
fingerprint_array = np.array([list(fp) for fp in df['morgan_fp']])

# Apply PCA
pca = PCA(n_components=2)
pca_result = pca.fit_transform(fingerprint_array)

# Create a scatter plot of the PCA results
plt.figure(figsize=(10, 8))
plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.5)
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA of Morgan Fingerprints')
plt.grid(True)
plt.show()

# Tiáº¿ng Viá»‡t
import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np

# Táº£i dá»¯ liá»‡u (thay 'your_data.csv' báº±ng tÃªn file cá»§a báº¡n)
base_path = "." # Thay Ä‘á»•i náº¿u cáº§n
data_path = os.path.join(base_path, "data", "your_data.csv")  # Thay tháº¿ "your_data.csv"
df = pd.read_csv(data_path)

# HÃ m táº¡o Morgan Fingerprint
def generate_morgan_fingerprint(smiles, radius=2, nBits=2048):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        return AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)
    else:
        return None

# Ãp dá»¥ng hÃ m cho cá»™t SMILES
df['morgan_fp'] = df['canonical_smiles'].apply(generate_morgan_fingerprint)

# Loáº¡i bá» cÃ¡c hÃ ng mÃ  quÃ¡ trÃ¬nh táº¡o fingerprint bá»‹ lá»—i
df = df.dropna(subset=['morgan_fp'])

# Chuyá»ƒn Ä‘á»•i fingerprint thÃ nh má»™t máº£ng numpy
fingerprint_array = np.array([list(fp) for fp in df['morgan_fp']])

# Ãp dá»¥ng PCA
pca = PCA(n_components=2)
pca_result = pca.fit_transform(fingerprint_array)

# Táº¡o biá»ƒu Ä‘á»“ phÃ¢n tÃ¡n cá»§a káº¿t quáº£ PCA
plt.figure(figsize=(10, 8))
plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.5)
plt.xlabel('ThÃ nh pháº§n chÃ­nh 1')
plt.ylabel('ThÃ nh pháº§n chÃ­nh 2')
plt.title('PCA cá»§a Morgan Fingerprints')
plt.grid(True)
plt.show()
```

**SQL (vÃ­ dá»¥ 4): TÃ¬m cÃ¡c há»£p cháº¥t tÆ°Æ¡ng tá»± vá»›i má»™t há»£p cháº¥t cá»¥ thá»ƒ (dá»±a trÃªn SubstructureKeys)**

```sql
-- English
SELECT m.chembl_id, cs.canonical_smiles
FROM molecule_dictionary m
JOIN compound_structures cs ON m.molregno = cs.molregno
WHERE m.molregno IN (
    SELECT molregno
    FROM substructure_sets
    WHERE substructure IN (
        SELECT substructure FROM substructure_sets WHERE molregno = (SELECT molregno FROM molecule_dictionary WHERE chembl_id = 'CHEMBL121')
    )
    AND molregno != (SELECT molregno FROM molecule_dictionary WHERE chembl_id = 'CHEMBL121')
)
LIMIT 100;

-- Tiáº¿ng Viá»‡t
-- TÃ¬m cÃ¡c há»£p cháº¥t tÆ°Æ¡ng tá»± vá»›i má»™t há»£p cháº¥t cá»¥ thá»ƒ (dá»±a trÃªn SubstructureKeys)
SELECT m.chembl_id, cs.canonical_smiles
FROM molecule_dictionary m
JOIN compound_structures cs ON m.molregno = cs.molregno
WHERE m.molregno IN (
    SELECT molregno
    FROM substructure_sets
    WHERE substructure IN (
        SELECT substructure FROM substructure_sets WHERE molregno = (SELECT molregno FROM molecule_dictionary WHERE chembl_id = 'CHEMBL121')
    )
    AND molregno != (SELECT molregno FROM molecule_dictionary WHERE chembl_id = 'CHEMBL121')
)
LIMIT 100;
```

**Python (vÃ­ dá»¥ 4): TÃ­nh Tanimoto similarity giá»¯a cÃ¡c fingerprint**

```python
# English
import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem
from rdkit import DataStructs

# Load data (replace 'your_data.csv' with your actual file)
base_path = "." # Thay Ä‘á»•i náº¿u cáº§n
data_path = os.path.join(base_path, "data", "your_data.csv")  # Replace "your_data.csv"
df = pd.read_csv(data_path)

# Compound to compare against (replace with a valid CHEMBL_ID from your data)
reference_smiles = df['canonical_smiles'].iloc[0] # láº¥y smiles Ä‘áº§u tiÃªn lÃ m chuáº©n, báº¡n cÃ³ thá»ƒ thay Ä‘á»•i
reference_mol = Chem.MolFromSmiles(reference_smiles)
reference_fp = AllChem.GetMorganFingerprintAsBitVect(reference_mol, 2, nBits=2048)

# Function to calculate Tanimoto similarity
def calculate_tanimoto_similarity(smiles, reference_fp):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)
        return DataStructs.TanimotoSimilarity(reference_fp, fp)
    else:
        return None

# Apply the function to the SMILES column
df['tanimoto_similarity'] = df['canonical_smiles'].apply(lambda x: calculate_tanimoto_similarity(x, reference_fp))

# Show the results
print(df[['chembl_id', 'tanimoto_similarity']].head())

# Tiáº¿ng Viá»‡t
import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem
from rdkit import DataStructs

# Táº£i dá»¯ liá»‡u (thay 'your_data.csv' báº±ng tÃªn file cá»§a báº¡n)
base_path = "." # Thay Ä‘á»•i náº¿u cáº§n
data_path = os.path.join(base_path, "data", "your_data.csv")  # Thay tháº¿ "your_data.csv"
df = pd.read_csv(data_path)

# Há»£p cháº¥t Ä‘á»ƒ so sÃ¡nh (thay báº±ng má»™t CHEMBL_ID há»£p lá»‡ tá»« dá»¯ liá»‡u cá»§a báº¡n)
reference_smiles = df['canonical_smiles'].iloc[0] # láº¥y smiles Ä‘áº§u tiÃªn lÃ m chuáº©n, báº¡n cÃ³ thá»ƒ thay Ä‘á»•i
reference_mol = Chem.MolFromSmiles(reference_smiles)
reference_fp = AllChem.GetMorganFingerprintAsBitVect(reference_mol, 2, nBits=2048)

# HÃ m tÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng Tanimoto
def calculate_tanimoto_similarity(smiles, reference_fp):
    mol = Chem.MolFromSmiles(smiles)
    if mol:
        fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)
        return DataStructs.TanimotoSimilarity(reference_fp, fp)
    else:
        return None

# Ãp dá»¥ng hÃ m cho cá»™t SMILES
df['tanimoto_similarity'] = df['canonical_smiles'].apply(lambda x: calculate_tanimoto_similarity(x, reference_fp))

# Hiá»ƒn thá»‹ káº¿t quáº£
print(df[['chembl_id', 'tanimoto_similarity']].head())
```

**SQL (vÃ­ dá»¥ 5): Láº¥y thÃ´ng tin vá» cÃ¡c má»¥c tiÃªu (targets) liÃªn quan Ä‘áº¿n má»™t bá»‡nh cá»¥ thá»ƒ (vÃ­ dá»¥: ung thÆ°)**

```sql
-- English
SELECT td.chembl_id, td.pref_name, td.target_type
FROM target_dictionary td
JOIN target_components tc ON td.tid = tc.tid
JOIN component_sequences cs ON tc.component_id = cs.component_id
WHERE cs.description LIKE '%cancer%'
LIMIT 100;

-- Tiáº¿ng Viá»‡t
-- Láº¥y thÃ´ng tin vá» cÃ¡c má»¥c tiÃªu (targets) liÃªn quan Ä‘áº¿n má»™t bá»‡nh cá»¥ thá»ƒ (vÃ­ dá»¥: ung thÆ°)
SELECT td.chembl_id, td.pref_name, td.target_type
FROM target_dictionary td
JOIN target_components tc ON td.tid = tc.tid
JOIN component_sequences cs ON tc.component_id = cs.component_id
WHERE cs.description LIKE '%cancer%'
LIMIT 100;
```

**Python (vÃ­ dá»¥ 5): Sá»­ dá»¥ng RDKit Ä‘á»ƒ chuáº©n hÃ³a SMILES**

```python
# English
import pandas as pd
from rdkit import Chem
from rdkit.Chem import MolStandardize

# Load data (replace 'your_data.csv' with your actual file)
base_path = "." # Thay Ä‘á»•i náº¿u cáº§n
data_path = os.path.join(base_path, "data", "your_data.csv")  # Replace "your_data.csv"
df = pd.read_csv(data_path)

def standardize_smiles(smiles):
    try:
        mol = Chem.MolFromSmiles(smiles)
        if mol is not None:
            # Initialize the standardization object
            std = MolStandardize.Standardizer()
            mol = std.charge_parent(mol)  # Get the parent molecule
            mol = std.normalize(mol)  # Apply normalization
            mol = std.reionize(mol)  # Reionize the molecule
            return Chem.MolToSmiles(mol)  # Convert back to SMILES
        else:
            return None
    except Exception as e:
        print(f"Error processing SMILES: {smiles} - {e}")
        return None

# Apply the standardization function
df['standardized_smiles'] = df['canonical_smiles'].apply(standardize_smiles)

# Display the standardized SMILES
print(df[['canonical_smiles', 'standardized_smiles']].head())


# Tiáº¿ng Viá»‡t
import pandas as pd
from rdkit import Chem
from rdkit.Chem import MolStandardize

# Táº£i dá»¯ liá»‡u (thay 'your_data.csv' báº±ng tÃªn file cá»§a báº¡n)
base_path = "." # Thay Ä‘á»•i náº¿u cáº§n
data_path = os.path.join(base_path, "data", "your_data.csv")  # Thay tháº¿ "your_data.csv"
df = pd.read_csv(data_path)

def standardize_smiles(smiles):
    try:
        mol = Chem.MolFromSmiles(smiles)
        if mol is not None:
            # Khá»Ÿi táº¡o Ä‘á»‘i tÆ°á»£ng chuáº©n hÃ³a
            std = MolStandardize.Standardizer()
            mol = std.charge_parent(mol)  # Láº¥y phÃ¢n tá»­ gá»‘c
            mol = std.normalize(mol)  # Ãp dá»¥ng chuáº©n hÃ³a
            mol = std.reionize(mol)  # TÃ¡i ion hÃ³a phÃ¢n tá»­
            return Chem.MolToSmiles(mol)  # Chuyá»ƒn Ä‘á»•i láº¡i thÃ nh SMILES
        else:
            return None
    except Exception as e:
        print(f"Lá»—i xá»­ lÃ½ SMILES: {smiles} - {e}")
        return None

# Ãp dá»¥ng hÃ m chuáº©n hÃ³a
df['standardized_smiles'] = df['canonical_smiles'].apply(standardize_smiles)

# Hiá»ƒn thá»‹ SMILES Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a
print(df[['canonical_smiles', 'standardized_smiles']].head())
```

**5. Giáº£i quyáº¿t cÃ¡c lá»—i thÆ°á»ng gáº·p (Addressing Common Errors):**

*   **Lá»—i SQL: `ERROR: operator does not exist: numeric ~ unknown`**

    *   **(English)**: This error occurs because you're trying to use a regular expression operator (`~`) on a numeric column.  To fix this, ensure that the `standard_value` column contains only numeric data *before* applying the regular expression. You can use `TRY_CAST` to safely convert the column to numeric.
    *   **(Tiáº¿ng Viá»‡t)**: Lá»—i nÃ y xáº£y ra vÃ¬ báº¡n Ä‘ang cá»‘ gáº¯ng sá»­ dá»¥ng toÃ¡n tá»­ biá»ƒu thá»©c chÃ­nh quy (`~`) trÃªn má»™t cá»™t sá»‘. Äá»ƒ kháº¯c phá»¥c, hÃ£y Ä‘áº£m báº£o ráº±ng cá»™t `standard_value` chá»‰ chá»©a dá»¯ liá»‡u sá»‘ *trÆ°á»›c khi* Ã¡p dá»¥ng biá»ƒu thá»©c chÃ­nh quy. Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng `TRY_CAST` Ä‘á»ƒ chuyá»ƒn Ä‘á»•i an toÃ n cá»™t nÃ y sang kiá»ƒu sá»‘.

    ```sql
    -- English
    SELECT
        m.chembl_id,
        cs.canonical_smiles,
        act.standard_value,
        act.standard_units
    FROM
        activities act
    JOIN
        molecule_dictionary m ON act.molregno = m.molregno
    JOIN
        compound_structures cs ON m.molregno = cs.molregno
    WHERE
        act.standard_type = 'IC50'
        AND act.standard_units = 'nM'
        AND act.standard_value IS NOT NULL
        -- Try to cast to numeric *before* filtering by regex
        AND TRY_CAST(act.standard_value AS NUMERIC) IS NOT NULL
        -- Now that we *know* it's numeric, we can compare it as such
        AND TRY_CAST(act.standard_value AS NUMERIC) > 0
        AND TRY_CAST(act.standard_value AS NUMERIC) <= 100
    LIMIT 100;

    -- Tiáº¿ng Viá»‡t
    SELECT
        m.chembl_id,
        cs.canonical_smiles,
        act.standard_value,
        act.standard_units
    FROM
        activities act
    JOIN
        molecule_dictionary m ON act.molregno = m.molregno
    JOIN
        compound_structures cs ON m.molregno = cs.molregno
    WHERE
        act.standard_type = 'IC50'
        AND act.standard_units = 'nM'
        AND act.standard_value IS NOT NULL
        -- Thá»­ chuyá»ƒn Ä‘á»•i sang kiá»ƒu sá»‘ *trÆ°á»›c khi* lá»c báº±ng regex
        AND TRY_CAST(act.standard_value AS NUMERIC) IS NOT NULL
        -- BÃ¢y giá» *chÃºng ta biáº¿t* nÃ³ lÃ  sá»‘, chÃºng ta cÃ³ thá»ƒ so sÃ¡nh nÃ³ nhÆ° váº­y
        AND TRY_CAST(act.standard_value AS NUMERIC) > 0
        AND TRY_CAST(act.standard_value AS NUMERIC) <= 100
    LIMIT 100;
    ```

*   **Lá»—i Python: `TypeError: mean_squared_error() got an unexpected keyword argument 'squared'`**

    *   **(English)**: This error indicates that your version of scikit-learn is outdated. The `squared=False` parameter was introduced in a later version.  You have two options:
        1.  **Upgrade scikit-learn:**  `pip install scikit-learn --upgrade`
        2.  **Remove `squared=False`:** If you can't upgrade, remove the `squared=False` argument and take the square root of the result to get the RMSE (Root Mean Squared Error).
    *   **(Tiáº¿ng Viá»‡t)**: Lá»—i nÃ y chá»‰ ra ráº±ng phiÃªn báº£n scikit-learn cá»§a báº¡n Ä‘Ã£ cÅ©. Tham sá»‘ `squared=False` Ä‘Æ°á»£c giá»›i thiá»‡u trong má»™t phiÃªn báº£n sau nÃ y. Báº¡n cÃ³ hai lá»±a chá»n:
        1.  **NÃ¢ng cáº¥p scikit-learn:** `pip install scikit-learn --upgrade`
        2.  **XÃ³a `squared=False`:** Náº¿u báº¡n khÃ´ng thá»ƒ nÃ¢ng cáº¥p, hÃ£y xÃ³a Ä‘á»‘i sá»‘ `squared=False` vÃ  láº¥y cÄƒn báº­c hai cá»§a káº¿t quáº£ Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c RMSE (Root Mean Squared Error).

    ```python
    # VÃ­ dá»¥:
    from sklearn.metrics import mean_squared_error
    import numpy as np

    y_true = [3, -0.5, 2, 7]
    y_predicted = [2.5, 0.0, 2, 8]

    # Náº¿u báº¡n khÃ´ng thá»ƒ nÃ¢ng cáº¥p scikit-learn:
    mse = mean_squared_error(y_true, y_predicted)
    rmse = np.sqrt(mse)
    print(f"RMSE: {rmse}")

    # Náº¿u báº¡n Ä‘Ã£ nÃ¢ng cáº¥p scikit-learn:
    rmse = mean_squared_error(y_true, y_predicted, squared=False)
    print(f"RMSE: {rmse}")
    ```

**LÆ°u Ã½ quan trá»ng:**

*   HÃ£y thay tháº¿ `"your_data.csv"` báº±ng tÃªn file CSV thá»±c táº¿ cá»§a báº¡n.
*   Äiá»u chá»‰nh cÃ¡c tham sá»‘ vÃ  truy váº¥n SQL cho phÃ¹ há»£p vá»›i má»¥c tiÃªu nghiÃªn cá»©u cá»¥ thá»ƒ cá»§a báº¡n.
*   Sá»­ dá»¥ng `os.path.join(base_path, "data", "your_data.csv")` Ä‘á»ƒ Ä‘áº£m báº£o code cá»§a báº¡n hoáº¡t Ä‘á»™ng trÃªn cÃ¡c há»‡ Ä‘iá»u hÃ nh khÃ¡c nhau.
*   HÃ£y nhá»› cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t: `pip install pandas rdkit scikit-learn matplotlib`

TÃ´i hy vá»ng hÆ°á»›ng dáº«n nÃ y sáº½ giÃºp báº¡n báº¯t Ä‘áº§u dá»± Ã¡n cá»§a mÃ¬nh má»™t cÃ¡ch suÃ´n sáº». Náº¿u báº¡n cÃ³ báº¥t ká»³ cÃ¢u há»i nÃ o khÃ¡c, Ä‘á»«ng ngáº§n ngáº¡i há»i!
