# PharmApp Suite
## üß† AI for Drug Discovery and Development üß™
| Copyright 2025 | Nghi√™n C·ª©u Thu·ªëc | www.nghiencuuthuoc.com | Zalo: +84888999311 |

üß© Topic: Li√™n k·∫øt d·ªØ li·ªáu thu·ªëc v·ªõi c√°c pha l√¢m s√†ng
---
Tuy·ªát v·ªùi! T√¥i r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n trong d·ª± √°n ph√¢n t√≠ch d·ªØ li·ªáu ChEMBL 35 s·ª≠ d·ª•ng RDKit. V·ªõi vai tr√≤ l√† m·ªôt chuy√™n gia nghi√™n c·ª©u v√† ph√°t tri·ªÉn d∆∞·ª£c h·ªçc, t√¥i hi·ªÉu r√µ t·∫ßm quan tr·ªçng c·ªßa vi·ªác khai th√°c d·ªØ li·ªáu ChEMBL ƒë·ªÉ t√¨m ki·∫øm c√°c h·ª£p ch·∫•t ti·ªÅm nƒÉng.

D∆∞·ªõi ƒë√¢y l√† ph√¢n t√≠ch chi ti·∫øt, h∆∞·ªõng d·∫´n song ng·ªØ, code SQL v√† Python m·∫´u, c√πng v·ªõi c√°c v√≠ d·ª• ƒë·ªÉ gi√∫p b·∫°n b·∫Øt ƒë·∫ßu d·ª± √°n c·ªßa m√¨nh.

**1. Ph√¢n t√≠ch v√† M√¥ h√¨nh Ph√¢n t√≠ch (Analysis and Analysis Model)**

*   **M·ª•c ti√™u:**
    *   X√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n ho·∫°t t√≠nh c·ªßa c√°c h·ª£p ch·∫•t d·ª±a tr√™n c·∫•u tr√∫c h√≥a h·ªçc c·ªßa ch√∫ng.
    *   X√°c ƒë·ªãnh c√°c ƒë·∫∑c t√≠nh h√≥a h·ªçc quan tr·ªçng ·∫£nh h∆∞·ªüng ƒë·∫øn ho·∫°t t√≠nh.
    *   T√¨m ki·∫øm c√°c h·ª£p ch·∫•t ti·ªÅm nƒÉng c√≥ ho·∫°t t√≠nh mong mu·ªën.

*   **D·ªØ li·ªáu:**
    *   D·ªØ li·ªáu t·ª´ ChEMBL 35, bao g·ªìm th√¥ng tin v·ªÅ c·∫•u tr√∫c h√≥a h·ªçc (SMILES), ho·∫°t t√≠nh sinh h·ªçc (IC50, Ki, EC50, v.v.), v√† c√°c thu·ªôc t√≠nh kh√°c.
    *   S·ª≠ d·ª•ng RDKit ƒë·ªÉ t√≠nh to√°n c√°c descriptor ph√¢n t·ª≠ t·ª´ c·∫•u tr√∫c SMILES.

*   **M√¥ h√¨nh:**
    *   **H·ªìi quy (Regression):** D·ª± ƒëo√°n gi√° tr·ªã ho·∫°t t√≠nh li√™n t·ª•c (v√≠ d·ª•: pIC50).
        *   **V√≠ d·ª•:** H·ªìi quy tuy·∫øn t√≠nh (Linear Regression), H·ªìi quy Ridge (Ridge Regression), H·ªìi quy Lasso (Lasso Regression), M√°y vector h·ªó tr·ª£ h·ªìi quy (Support Vector Regression - SVR), R·ª´ng ng·∫´u nhi√™n (Random Forest), Gradient Boosting.
    *   **Ph√¢n lo·∫°i (Classification):** D·ª± ƒëo√°n m·ªôt h·ª£p ch·∫•t c√≥ ho·∫°t t√≠nh hay kh√¥ng (v√≠ d·ª•: ho·∫°t t√≠nh > ng∆∞·ª°ng).
        *   **V√≠ d·ª•:** H·ªìi quy Logistic (Logistic Regression), M√°y vector h·ªó tr·ª£ ph√¢n lo·∫°i (Support Vector Classification - SVC), C√¢y quy·∫øt ƒë·ªãnh (Decision Tree), R·ª´ng ng·∫´u nhi√™n (Random Forest), Gradient Boosting.

*   **Quy tr√¨nh:**

    1.  **Thu th·∫≠p d·ªØ li·ªáu (Data Acquisition):** Truy v·∫•n c∆° s·ªü d·ªØ li·ªáu ChEMBL ƒë·ªÉ l·∫•y d·ªØ li·ªáu c·∫ßn thi·∫øt.
    2.  **Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu (Data Preprocessing):**
        *   L√†m s·∫°ch d·ªØ li·ªáu (x·ª≠ l√Ω gi√° tr·ªã thi·∫øu, lo·∫°i b·ªè d·ªØ li·ªáu tr√πng l·∫∑p).
        *   Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu (v√≠ d·ª•: chuy·ªÉn IC50 sang pIC50).
    3.  **T√≠nh to√°n descriptor ph√¢n t·ª≠ (Molecular Descriptor Calculation):** S·ª≠ d·ª•ng RDKit ƒë·ªÉ t√≠nh to√°n c√°c descriptor ph√¢n t·ª≠ t·ª´ c·∫•u tr√∫c SMILES.
    4.  **L·ª±a ch·ªçn ƒë·∫∑c tr∆∞ng (Feature Selection):** Ch·ªçn c√°c descriptor quan tr·ªçng nh·∫•t ƒë·ªÉ ƒë∆∞a v√†o m√¥ h√¨nh.
    5.  **X√¢y d·ª±ng m√¥ h√¨nh (Model Building):** Ch·ªçn v√† hu·∫•n luy·ªán m√¥ h√¨nh ph√π h·ª£p.
    6.  **ƒê√°nh gi√° m√¥ h√¨nh (Model Evaluation):** ƒê√°nh gi√° hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh b·∫±ng c√°c ƒë·ªô ƒëo ph√π h·ª£p (v√≠ d·ª•: R-squared, RMSE, AUC).
    7.  **D·ª± ƒëo√°n v√† ph√¢n t√≠ch (Prediction and Analysis):** S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ d·ª± ƒëo√°n ho·∫°t t√≠nh c·ªßa c√°c h·ª£p ch·∫•t m·ªõi v√† ph√¢n t√≠ch c√°c ƒë·∫∑c t√≠nh quan tr·ªçng.

**2. H∆∞·ªõng d·∫´n Song ng·ªØ (Bilingual Guide)**

| B∆∞·ªõc                                   | Ti·∫øng Anh                                                                                                                                                                                                                            | Ti·∫øng Vi·ªát                                                                                                                                                                                                                            |
| ------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| 1. Thu th·∫≠p d·ªØ li·ªáu                    | Data Acquisition: Query the ChEMBL database to retrieve the necessary data.                                                                                                                                                            | Thu th·∫≠p d·ªØ li·ªáu: Truy v·∫•n c∆° s·ªü d·ªØ li·ªáu ChEMBL ƒë·ªÉ l·∫•y d·ªØ li·ªáu c·∫ßn thi·∫øt.                                                                                                                                                            |
| 2. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu                  | Data Preprocessing: Clean the data (handle missing values, remove duplicates). Transform the data (e.g., convert IC50 to pIC50).                                                                                                   | Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu: L√†m s·∫°ch d·ªØ li·ªáu (x·ª≠ l√Ω gi√° tr·ªã thi·∫øu, lo·∫°i b·ªè d·ªØ li·ªáu tr√πng l·∫∑p). Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu (v√≠ d·ª•: chuy·ªÉn IC50 sang pIC50).                                                                                             |
| 3. T√≠nh to√°n descriptor ph√¢n t·ª≠           | Molecular Descriptor Calculation: Use RDKit to calculate molecular descriptors from SMILES structures.                                                                                                                             | T√≠nh to√°n descriptor ph√¢n t·ª≠: S·ª≠ d·ª•ng RDKit ƒë·ªÉ t√≠nh to√°n c√°c descriptor ph√¢n t·ª≠ t·ª´ c·∫•u tr√∫c SMILES.                                                                                                                             |
| 4. L·ª±a ch·ªçn ƒë·∫∑c tr∆∞ng                   | Feature Selection: Select the most important descriptors to include in the model.                                                                                                                                                   | L·ª±a ch·ªçn ƒë·∫∑c tr∆∞ng: Ch·ªçn c√°c descriptor quan tr·ªçng nh·∫•t ƒë·ªÉ ƒë∆∞a v√†o m√¥ h√¨nh.                                                                                                                                                   |
| 5. X√¢y d·ª±ng m√¥ h√¨nh                   | Model Building: Select and train an appropriate model.                                                                                                                                                                             | X√¢y d·ª±ng m√¥ h√¨nh: Ch·ªçn v√† hu·∫•n luy·ªán m√¥ h√¨nh ph√π h·ª£p.                                                                                                                                                                             |
| 6. ƒê√°nh gi√° m√¥ h√¨nh                   | Model Evaluation: Evaluate the model's performance using appropriate metrics (e.g., R-squared, RMSE, AUC).                                                                                                                          | ƒê√°nh gi√° m√¥ h√¨nh: ƒê√°nh gi√° hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh b·∫±ng c√°c ƒë·ªô ƒëo ph√π h·ª£p (v√≠ d·ª•: R-squared, RMSE, AUC).                                                                                                                          |
| 7. D·ª± ƒëo√°n v√† ph√¢n t√≠ch                | Prediction and Analysis: Use the model to predict the activity of new compounds and analyze important characteristics.                                                                                                                | D·ª± ƒëo√°n v√† ph√¢n t√≠ch: S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ d·ª± ƒëo√°n ho·∫°t t√≠nh c·ªßa c√°c h·ª£p ch·∫•t m·ªõi v√† ph√¢n t√≠ch c√°c ƒë·∫∑c t√≠nh quan tr·ªçng.                                                                                                                |
| **L·ªói th∆∞·ªùng g·∫∑p (Common Errors)** | ERROR: operator does not exist: numeric ~ unknown: This error occurs because you're trying to use the `~` operator (regular expression matching) on a numeric column. You need to cast the column to text first. | L·ªói: operator does not exist: numeric ~ unknown: L·ªói n√†y x·∫£y ra khi b·∫°n c·ªë g·∫Øng s·ª≠ d·ª•ng to√°n t·ª≠ `~` (so kh·ªõp bi·ªÉu th·ª©c ch√≠nh quy) tr√™n m·ªôt c·ªôt s·ªë. B·∫°n c·∫ßn chuy·ªÉn ƒë·ªïi c·ªôt th√†nh vƒÉn b·∫£n tr∆∞·ªõc. |
| Scikit-learn version issue             |  Older scikit-learn versions may not support `squared=False` in `mean_squared_error`.  Update your scikit-learn version or remove the argument.                                                                                    | Phi√™n b·∫£n Scikit-learn c≈© c√≥ th·ªÉ kh√¥ng h·ªó tr·ª£ `squared=False` trong `mean_squared_error`. H√£y c·∫≠p nh·∫≠t phi√™n b·∫£n Scikit-learn c·ªßa b·∫°n ho·∫∑c x√≥a ƒë·ªëi s·ªë n√†y.                                                                    |

**3. Code SQL v√† Python (SQL and Python Code)**

**SQL (V√≠ d·ª•: L·∫•y d·ªØ li·ªáu t·ª´ ChEMBL cho m·ªôt target c·ª• th·ªÉ):**

```sql
-- Get data for a specific target (e.g., target_chembl_id = 'CHEMBL205')
SELECT
    cmp.chembl_id,
    cmp.canonical_smiles,
    act.standard_type,
    act.standard_value,
    act.standard_units
FROM
    compound_structures cmp
JOIN
    activities act ON cmp.molregno = act.molregno
JOIN
    target_dictionary td ON act.tid = td.tid
WHERE
    td.target_chembl_id = 'CHEMBL205'
    AND act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.standard_value IS NOT NULL
    AND act.standard_value::text ~ '^[0-9\.]+$'  -- Corrected line: Casting to text for regex
LIMIT 100;

--Gi·∫£i th√≠ch:
-- L·∫•y th√¥ng tin v·ªÅ h·ª£p ch·∫•t, c·∫•u tr√∫c, lo·∫°i ho·∫°t t√≠nh, gi√° tr·ªã, v√† ƒë∆°n v·ªã
-- T·ª´ b·∫£ng c·∫•u tr√∫c h·ª£p ch·∫•t, ho·∫°t ƒë·ªông, v√† t·ª´ ƒëi·ªÉn m·ª•c ti√™u
-- L·ªçc theo target_chembl_id c·ª• th·ªÉ (v√≠ d·ª•: CHEMBL205), lo·∫°i ho·∫°t t√≠nh l√† IC50, ƒë∆°n v·ªã l√† nM, gi√° tr·ªã kh√¥ng null, v√† gi√° tr·ªã ch·ªâ ch·ª©a s·ªë v√† d·∫•u ch·∫•m (ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh h·ª£p l·ªá)
-- Gi·ªõi h·∫°n k·∫øt qu·∫£ 100 d√≤ng

-- Explanation:
-- Get compound information, structure, activity type, value, and units
-- From the compound structure, activities, and target dictionary tables
-- Filter by specific target_chembl_id (e.g., CHEMBL205), activity type is IC50, units are nM, value is not null, and value contains only numbers and dots (to ensure validity)
-- Limit the result to 100 rows
```

**Python (V√≠ d·ª•: T√≠nh to√°n descriptor ph√¢n t·ª≠ v√† x√¢y d·ª±ng m√¥ h√¨nh):**

```python
import os
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# ƒê∆∞·ªùng d·∫´n c∆° s·ªü (Base path)
base_path = "../data"

# T√™n file CSV (CSV file name)
csv_file = "chembl_205_ic50_100.csv"  # Replace with your actual file name
file_path = os.path.join(base_path, csv_file)

# ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV (Read data from CSV file)
try:
    df = pd.read_csv(file_path)
except FileNotFoundError:
    print(f"Error: File not found at {file_path}")
    exit()

# In ra th√¥ng tin c∆° b·∫£n c·ªßa DataFrame (Print basic DataFrame info)
print("DataFrame Info:")
print(df.info())

# H√†m t√≠nh to√°n descriptor ph√¢n t·ª≠ (Function to calculate molecular descriptors)
def calculate_descriptors(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    descriptors = {}
    for name, func in Descriptors.descList:
        try:
            descriptors[name] = func(mol)
        except:
            descriptors[name] = np.nan  # Handle potential errors
    return descriptors

# √Åp d·ª•ng h√†m t√≠nh to√°n descriptor (Apply descriptor calculation function)
df['descriptors'] = df['canonical_smiles'].apply(calculate_descriptors)

# Lo·∫°i b·ªè c√°c d√≤ng c√≥ l·ªói (Remove rows with errors)
df = df.dropna(subset=['descriptors'])

# Chuy·ªÉn ƒë·ªïi descriptor th√†nh DataFrame (Convert descriptors to DataFrame)
descriptors_df = pd.DataFrame(df['descriptors'].tolist())

# G·ªôp DataFrame descriptor v·ªõi DataFrame ch√≠nh (Merge descriptor DataFrame with main DataFrame)
df = pd.concat([df, descriptors_df], axis=1)

# Chuy·ªÉn ƒë·ªïi IC50 th√†nh pIC50 (Convert IC50 to pIC50)
df['pIC50'] = -np.log10(df['standard_value'] * 1e-9)  # Convert nM to M

# Ch·ªçn c√°c ƒë·∫∑c tr∆∞ng v√† bi·∫øn m·ª•c ti√™u (Select features and target variable)
features = descriptors_df.columns
target = 'pIC50'

# Lo·∫°i b·ªè c√°c gi√° tr·ªã v√¥ c·ª±c v√† NaN (Remove infinite and NaN values)
df = df[np.isfinite(df[target])]
df = df.dropna(axis=1, how='any')

# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra (Split data into training and test sets)
X_train, X_test, y_train, y_test = train_test_split(df[features].fillna(0), df[target], test_size=0.2, random_state=42)

# Chu·∫©n h√≥a d·ªØ li·ªáu v√† x√¢y d·ª±ng m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh (Standardize data and build linear regression model)
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', LinearRegression())
])

# Hu·∫•n luy·ªán m√¥ h√¨nh (Train the model)
pipeline.fit(X_train, y_train)

# D·ª± ƒëo√°n tr√™n t·∫≠p ki·ªÉm tra (Predict on the test set)
y_pred = pipeline.predict(X_test)

# ƒê√°nh gi√° m√¥ h√¨nh (Evaluate the model)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')

# In ra 10 d√≤ng ƒë·∫ßu c·ªßa DataFrame (Print the first 10 rows of the DataFrame)
print("First 10 rows of DataFrame:")
print(df.head(10))
```

**Gi·∫£i th√≠ch:**

1.  **Import th∆∞ vi·ªán:** Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt (pandas, RDKit, scikit-learn).
2.  **ƒê·ªçc d·ªØ li·ªáu:** ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV.
3.  **T√≠nh to√°n descriptor:** T√≠nh to√°n descriptor ph√¢n t·ª≠ b·∫±ng RDKit.
4.  **Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu:** X·ª≠ l√Ω gi√° tr·ªã thi·∫øu, chuy·ªÉn ƒë·ªïi IC50 sang pIC50.
5.  **Chia d·ªØ li·ªáu:** Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra.
6.  **X√¢y d·ª±ng m√¥ h√¨nh:** X√¢y d·ª±ng m√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh.
7.  **ƒê√°nh gi√° m√¥ h√¨nh:** ƒê√°nh gi√° hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh.

**Explanation:**

1.  **Import libraries:** Import necessary libraries (pandas, RDKit, scikit-learn).
2.  **Read data:** Read data from CSV file.
3.  **Calculate descriptors:** Calculate molecular descriptors using RDKit.
4.  **Data preprocessing:** Handle missing values, convert IC50 to pIC50.
5.  **Split data:** Split data into training and test sets.
6.  **Build model:** Build a linear regression model.
7.  **Evaluate model:** Evaluate the model's performance.

**4. V√≠ d·ª• Code SQL v√† Python (SQL and Python Code Examples)**

**V√≠ d·ª• 1: L·ªçc c√°c h·ª£p ch·∫•t c√≥ ho·∫°t t√≠nh IC50 d∆∞·ªõi 100 nM (SQL)**

```sql
SELECT
    cmp.chembl_id,
    cmp.canonical_smiles,
    act.standard_value
FROM
    compound_structures cmp
JOIN
    activities act ON cmp.molregno = act.molregno
JOIN
    target_dictionary td ON act.tid = td.tid
WHERE
    td.target_chembl_id = 'CHEMBL205'
    AND act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.standard_value <= 100
LIMIT 100;
```

**V√≠ d·ª• 1: T√≠nh to√°n logP v√† MW (Python)**

```python
from rdkit import Chem
from rdkit.Chem import Descriptors

def calculate_logp_mw(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None, None
    logp = Descriptors.MolLogP(mol)
    mw = Descriptors.MolWt(mol)
    return logp, mw

smiles = 'CC(=O)Oc1ccccc1C(=O)O'
logp, mw = calculate_logp_mw(smiles)
print(f'LogP: {logp}, MW: {mw}')
```

**V√≠ d·ª• 2: L·∫•y c√°c h·ª£p ch·∫•t t√°c ƒë·ªông l√™n m·ªôt protein c·ª• th·ªÉ (SQL)**

```sql
SELECT
    cmp.chembl_id,
    cmp.canonical_smiles
FROM
    compound_structures cmp
JOIN
    activities act ON cmp.molregno = act.molregno
JOIN
    target_dictionary td ON act.tid = td.tid
WHERE
    td.target_chembl_id = 'CHEMBL301' -- Replace with desired target
LIMIT 100;
```

**V√≠ d·ª• 2: T√≠nh to√°n TPSA (Python)**

```python
from rdkit import Chem
from rdkit.Chem import rdMolDescriptors

def calculate_tpsa(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    tpsa = rdMolDescriptors.CalcTPSA(mol)
    return tpsa

smiles = 'c1ccccc1O'
tpsa = calculate_tpsa(smiles)
print(f'TPSA: {tpsa}')
```

**V√≠ d·ª• 3: T√¨m c√°c h·ª£p ch·∫•t c√≥ Ki < 10 nM (SQL)**

```sql
SELECT
    cmp.chembl_id,
    cmp.canonical_smiles,
    act.standard_value
FROM
    compound_structures cmp
JOIN
    activities act ON cmp.molregno = act.molregno
JOIN
    target_dictionary td ON act.tid = td.tid
WHERE
    td.target_chembl_id = 'CHEMBL205'
    AND act.standard_type = 'Ki'
    AND act.standard_units = 'nM'
    AND act.standard_value < 10
LIMIT 100;
```

**V√≠ d·ª• 3: T√≠nh to√°n s·ªë l∆∞·ª£ng v√≤ng (Python)**

```python
from rdkit import Chem
from rdkit.Chem import Descriptors

def calculate_ring_count(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    ring_count = Descriptors.RingCount(mol)
    return ring_count

smiles = 'c1ccccc1Cc2ccccc2'
ring_count = calculate_ring_count(smiles)
print(f'Ring Count: {ring_count}')
```

**V√≠ d·ª• 4: L·∫•y c√°c h·ª£p ch·∫•t c√≥ ho·∫°t t√≠nh tr√™n m·ªôt ƒë∆∞·ªùng d·∫´n sinh h·ªçc c·ª• th·ªÉ (SQL)**

```sql
SELECT
    cmp.chembl_id,
    cmp.canonical_smiles
FROM
    compound_structures cmp
JOIN
    activities act ON cmp.molregno = act.molregno
JOIN
    target_dictionary td ON act.tid = td.tid
JOIN
    target_components tc ON td.tid = tc.tid
JOIN
    component_sequences cs ON tc.component_id = cs.component_id
WHERE
    cs.accession = 'P00533'  -- Example: EGFR
LIMIT 100;
```

**V√≠ d·ª• 4: Scale d·ªØ li·ªáu s·ª≠ d·ª•ng StandardScaler (Python)**

```python
from sklearn.preprocessing import StandardScaler
import numpy as np

# V√≠ d·ª• d·ªØ li·ªáu
data = np.array([[1.0], [2.0], [3.0], [4.0], [5.0]])

# Kh·ªüi t·∫°o StandardScaler
scaler = StandardScaler()

# Fit v√† transform d·ªØ li·ªáu
scaled_data = scaler.fit_transform(data)

print("Original data:\n", data)
print("Scaled data:\n", scaled_data)
```

**V√≠ d·ª• 5: L·∫•y d·ªØ li·ªáu pIC50 t·ª´ ChEMBL (SQL)**

```sql
SELECT
    cmp.chembl_id,
    cmp.canonical_smiles,
    -LOG10(act.standard_value * POW(10, -9)) AS pIC50 -- Calculate pIC50
FROM
    compound_structures cmp
JOIN
    activities act ON cmp.molregno = act.molregno
JOIN
    target_dictionary td ON act.tid = td.tid
WHERE
    td.target_chembl_id = 'CHEMBL205'
    AND act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.standard_value IS NOT NULL
    AND act.standard_value::text ~ '^[0-9\.]+$' -- Ensure the value is numeric
LIMIT 100;
```

**V√≠ d·ª• 5: S·ª≠ d·ª•ng Random Forest Regressor (Python)**

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
import numpy as np

# T·∫°o d·ªØ li·ªáu v√≠ d·ª•
data = {'feature1': np.random.rand(100),
        'feature2': np.random.rand(100),
        'target': 2 * np.random.rand(100)}
df = pd.DataFrame(data)

# Chia d·ªØ li·ªáu th√†nh features (X) v√† target (y)
X = df[['feature1', 'feature2']]
y = df['target']

# Chia d·ªØ li·ªáu th√†nh training set v√† test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Kh·ªüi t·∫°o Random Forest Regressor
rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)

# Hu·∫•n luy·ªán m√¥ h√¨nh
rf_regressor.fit(X_train, y_train)

# D·ª± ƒëo√°n tr√™n test set
y_pred = rf_regressor.predict(X_test)

# ƒê√°nh gi√° m√¥ h√¨nh
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse)
print("R-squared:", r2)
```

**L∆∞u √Ω quan tr·ªçng:**

*   **Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n:** Thay ƒë·ªïi `base_path` v√† `csv_file` cho ph√π h·ª£p v·ªõi c·∫•u tr√∫c th∆∞ m·ª•c v√† t√™n file c·ªßa b·∫°n.
*   **X·ª≠ l√Ω l·ªói:** C√°c ƒëo·∫°n code tr√™n ch·ªâ l√† v√≠ d·ª•, b·∫°n c·∫ßn th√™m c√°c x·ª≠ l√Ω l·ªói ƒë·ªÉ ƒë·∫£m b·∫£o ch∆∞∆°ng tr√¨nh ch·∫°y ·ªïn ƒë·ªãnh.
*   **L·ª±a ch·ªçn m√¥ h√¨nh:** L·ª±a ch·ªçn m√¥ h√¨nh ph√π h·ª£p v·ªõi d·ªØ li·ªáu v√† m·ª•c ti√™u c·ªßa b·∫°n.
*   **T·ªëi ∆∞u h√≥a m√¥ h√¨nh:** T·ªëi ∆∞u h√≥a c√°c tham s·ªë c·ªßa m√¥ h√¨nh ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c hi·ªáu su·∫•t t·ªët nh·∫•t.
*   **Phi√™n b·∫£n scikit-learn:** H√£y ƒë·∫£m b·∫£o b·∫°n ƒëang s·ª≠ d·ª•ng phi√™n b·∫£n scikit-learn t∆∞∆°ng th√≠ch. N·∫øu b·∫°n g·∫∑p l·ªói v·ªõi tham s·ªë `squared=False` trong `mean_squared_error`, h√£y c·∫≠p nh·∫≠t scikit-learn ho·∫∑c b·ªè tham s·ªë ƒë√≥.
*   **Ki·ªÉm tra ki·ªÉu d·ªØ li·ªáu:** ƒê·∫£m b·∫£o ki·ªÉu d·ªØ li·ªáu c·ªßa c√°c c·ªôt ph√π h·ª£p v·ªõi c√°c ph√©p to√°n v√† h√†m b·∫°n s·ª≠ d·ª•ng.

Hy v·ªçng nh·ªØng h∆∞·ªõng d·∫´n v√† v√≠ d·ª• n√†y s·∫Ω gi√∫p b·∫°n b·∫Øt ƒë·∫ßu d·ª± √°n ph√¢n t√≠ch d·ªØ li·ªáu ChEMBL 35 c·ªßa m√¨nh m·ªôt c√°ch hi·ªáu qu·∫£. N·∫øu b·∫°n c√≥ b·∫•t k·ª≥ c√¢u h·ªèi n√†o, ƒë·ª´ng ng·∫ßn ng·∫°i h·ªèi!
