# PharmApp Suite
## ðŸ§  AI for Drug Discovery and Development ðŸ§ª
| Copyright 2025 | NghiÃªn Cá»©u Thuá»‘c | www.nghiencuuthuoc.com | Zalo: +84888999311 |

ðŸ§© Topic: Lá»c cÃ¡c phÃ¢n tá»­ tuÃ¢n thá»§ quy táº¯c Lipinski
---
Tuyá»‡t vá»i! TÃ´i ráº¥t vui Ä‘Æ°á»£c há»— trá»£ báº¡n trong dá»± Ã¡n phÃ¢n tÃ­ch dá»¯ liá»‡u ChEMBL 35 sá»­ dá»¥ng RDKit. Vá»›i vai trÃ² lÃ  má»™t chuyÃªn gia R&D dÆ°á»£c há»c, tÃ´i hiá»ƒu rÃµ táº§m quan trá»ng cá»§a viá»‡c khai thÃ¡c dá»¯ liá»‡u ChEMBL Ä‘á»ƒ tÃ¬m kiáº¿m cÃ¡c á»©ng cá»­ viÃªn thuá»‘c tiá»m nÄƒng. ChÃºng ta sáº½ cÃ¹ng nhau xÃ¢y dá»±ng quy trÃ¬nh lÃ m viá»‡c hiá»‡u quáº£, tuÃ¢n thá»§ theo chuáº©n AIMLOps Template mÃ  báº¡n Ä‘Ã£ Ä‘á» ra.

**Tá»•ng quan vá» dá»± Ã¡n**

Dá»± Ã¡n nÃ y táº­p trung vÃ o viá»‡c phÃ¢n tÃ­ch dá»¯ liá»‡u tá»« ChEMBL 35, má»™t cÆ¡ sá»Ÿ dá»¯ liá»‡u lá»›n chá»©a thÃ´ng tin vá» cÃ¡c phÃ¢n tá»­ hoáº¡t tÃ­nh sinh há»c. ChÃºng ta sáº½ sá»­ dá»¥ng PostgreSQL Ä‘á»ƒ truy váº¥n dá»¯ liá»‡u, RDKit Ä‘á»ƒ xá»­ lÃ½ vÃ  tÃ­nh toÃ¡n cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n tá»­, vÃ  Jupyter Notebook Ä‘á»ƒ viáº¿t code phÃ¢n tÃ­ch vÃ  trá»±c quan hÃ³a káº¿t quáº£.

**CÃ¡c bÆ°á»›c thá»±c hiá»‡n**

1.  **Truy váº¥n dá»¯ liá»‡u tá»« ChEMBL 35 báº±ng SQL vÃ  lÆ°u vÃ o file CSV:** Sá»­ dá»¥ng pgAdmin Ä‘á»ƒ káº¿t ná»‘i Ä‘áº¿n cÆ¡ sá»Ÿ dá»¯ liá»‡u ChEMBL 35 vÃ  viáº¿t cÃ¡c cÃ¢u lá»‡nh SQL Ä‘á»ƒ trÃ­ch xuáº¥t dá»¯ liá»‡u cáº§n thiáº¿t. LÆ°u káº¿t quáº£ vÃ o cÃ¡c file CSV trong thÆ° má»¥c `../data/`.
2.  **Xá»­ lÃ½ dá»¯ liá»‡u vÃ  tÃ­nh toÃ¡n Ä‘áº·c trÆ°ng phÃ¢n tá»­ báº±ng RDKit:** Sá»­ dá»¥ng Jupyter Notebook Ä‘á»ƒ Ä‘á»c dá»¯ liá»‡u tá»« cÃ¡c file CSV, tiá»n xá»­ lÃ½ dá»¯ liá»‡u, tÃ­nh toÃ¡n cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n tá»­ báº±ng RDKit, vÃ  lÆ°u káº¿t quáº£ vÃ o cÃ¡c file má»›i.
3.  **PhÃ¢n tÃ­ch dá»¯ liá»‡u vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh:** Sá»­ dá»¥ng cÃ¡c thÆ° viá»‡n Python nhÆ° scikit-learn Ä‘á»ƒ phÃ¢n tÃ­ch dá»¯ liá»‡u, xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n hoáº¡t tÃ­nh sinh há»c, vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh.
4.  **Trá»±c quan hÃ³a káº¿t quáº£:** Sá»­ dá»¥ng cÃ¡c thÆ° viá»‡n Python nhÆ° matplotlib vÃ  seaborn Ä‘á»ƒ trá»±c quan hÃ³a káº¿t quáº£ phÃ¢n tÃ­ch, giÃºp chÃºng ta hiá»ƒu rÃµ hÆ¡n vá» dá»¯ liá»‡u vÃ  mÃ´ hÃ¬nh.

**1. PhÃ¢n tÃ­ch mÃ´ hÃ¬nh phÃ¢n tÃ­ch (Analysis of the analysis model)**

Chá»§ Ä‘á» "Topic\_CheMBL\_35\_4" cÃ³ thá»ƒ táº­p trung vÃ o má»™t sá»‘ khÃ­a cáº¡nh sau cá»§a dá»¯ liá»‡u ChEMBL 35:

*   **PhÃ¢n tÃ­ch má»‘i quan há»‡ cáº¥u trÃºc-hoáº¡t tÃ­nh (SAR):** TÃ¬m kiáº¿m má»‘i liÃªn há»‡ giá»¯a cáº¥u trÃºc hÃ³a há»c cá»§a cÃ¡c phÃ¢n tá»­ vÃ  hoáº¡t tÃ­nh sinh há»c cá»§a chÃºng. Äiá»u nÃ y cÃ³ thá»ƒ giÃºp chÃºng ta xÃ¡c Ä‘á»‹nh cÃ¡c nhÃ³m chá»©c quan trá»ng cho hoáº¡t tÃ­nh, vÃ  tá»« Ä‘Ã³ thiáº¿t káº¿ cÃ¡c phÃ¢n tá»­ má»›i cÃ³ hoáº¡t tÃ­nh tá»‘t hÆ¡n.
*   **XÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n hoáº¡t tÃ­nh (Predictive modeling):** Sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n há»c mÃ¡y Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n hoáº¡t tÃ­nh sinh há»c cá»§a cÃ¡c phÃ¢n tá»­ dá»±a trÃªn cáº¥u trÃºc cá»§a chÃºng. MÃ´ hÃ¬nh nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ sÃ ng lá»c áº£o cÃ¡c thÆ° viá»‡n phÃ¢n tá»­ lá»›n, giÃºp chÃºng ta tÃ¬m kiáº¿m cÃ¡c á»©ng cá»­ viÃªn thuá»‘c tiá»m nÄƒng má»™t cÃ¡ch nhanh chÃ³ng vÃ  hiá»‡u quáº£.
*   **PhÃ¢n tÃ­ch Ä‘a dáº¡ng hÃ³a há»c (Chemical diversity analysis):** ÄÃ¡nh giÃ¡ sá»± Ä‘a dáº¡ng cá»§a cÃ¡c phÃ¢n tá»­ trong má»™t táº­p dá»¯ liá»‡u. Äiá»u nÃ y cÃ³ thá»ƒ giÃºp chÃºng ta Ä‘áº£m báº£o ráº±ng chÃºng ta Ä‘ang khÃ¡m phÃ¡ khÃ´ng gian hÃ³a há»c má»™t cÃ¡ch toÃ n diá»‡n, vÃ  khÃ´ng bá» lá»¡ cÃ¡c á»©ng cá»­ viÃªn thuá»‘c tiá»m nÄƒng.

**2. HÆ°á»›ng dáº«n song ngá»¯ (Bilingual Instructions)**

DÆ°á»›i Ä‘Ã¢y lÃ  hÆ°á»›ng dáº«n song ngá»¯ cho cÃ¡c bÆ°á»›c thá»±c hiá»‡n chÃ­nh:

**BÆ°á»›c 1: Truy váº¥n dá»¯ liá»‡u tá»« ChEMBL 35 báº±ng SQL**

*   **English:** Connect to the ChEMBL 35 database using pgAdmin and write SQL queries to extract the necessary data. Save the results to CSV files in the `../data/` directory.
*   **Tiáº¿ng Viá»‡t:** Káº¿t ná»‘i Ä‘áº¿n cÆ¡ sá»Ÿ dá»¯ liá»‡u ChEMBL 35 báº±ng pgAdmin vÃ  viáº¿t cÃ¡c cÃ¢u lá»‡nh SQL Ä‘á»ƒ trÃ­ch xuáº¥t dá»¯ liá»‡u cáº§n thiáº¿t. LÆ°u káº¿t quáº£ vÃ o cÃ¡c file CSV trong thÆ° má»¥c `../data/`.

**BÆ°á»›c 2: Xá»­ lÃ½ dá»¯ liá»‡u vÃ  tÃ­nh toÃ¡n Ä‘áº·c trÆ°ng phÃ¢n tá»­ báº±ng RDKit**

*   **English:** Use Jupyter Notebook to read data from CSV files, preprocess data, calculate molecular features using RDKit, and save the results to new files.
*   **Tiáº¿ng Viá»‡t:** Sá»­ dá»¥ng Jupyter Notebook Ä‘á»ƒ Ä‘á»c dá»¯ liá»‡u tá»« cÃ¡c file CSV, tiá»n xá»­ lÃ½ dá»¯ liá»‡u, tÃ­nh toÃ¡n cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n tá»­ báº±ng RDKit, vÃ  lÆ°u káº¿t quáº£ vÃ o cÃ¡c file má»›i.

**BÆ°á»›c 3: PhÃ¢n tÃ­ch dá»¯ liá»‡u vÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh**

*   **English:** Use Python libraries like scikit-learn to analyze data, build predictive models for biological activity, and evaluate model performance.
*   **Tiáº¿ng Viá»‡t:** Sá»­ dá»¥ng cÃ¡c thÆ° viá»‡n Python nhÆ° scikit-learn Ä‘á»ƒ phÃ¢n tÃ­ch dá»¯ liá»‡u, xÃ¢y dá»±ng mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n hoáº¡t tÃ­nh sinh há»c, vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u nÄƒng cá»§a mÃ´ hÃ¬nh.

**BÆ°á»›c 4: Trá»±c quan hÃ³a káº¿t quáº£**

*   **English:** Use Python libraries like matplotlib and seaborn to visualize the analysis results, helping us better understand the data and models.
*   **Tiáº¿ng Viá»‡t:** Sá»­ dá»¥ng cÃ¡c thÆ° viá»‡n Python nhÆ° matplotlib vÃ  seaborn Ä‘á»ƒ trá»±c quan hÃ³a káº¿t quáº£ phÃ¢n tÃ­ch, giÃºp chÃºng ta hiá»ƒu rÃµ hÆ¡n vá» dá»¯ liá»‡u vÃ  mÃ´ hÃ¬nh.

**3. Code SQL, Python (English)**

**3.1. SQL Code Example**

```sql
-- SQL query to extract data for compounds with IC50 values against a specific target
-- This example targets CHEMBL205 (Dopamine D4 receptor)
SELECT
    md.chembl_id,
    cs.canonical_smiles,
    act.standard_value,
    act.standard_units
FROM
    molecule_dictionary md
JOIN
    compound_structures cs ON md.molregno = cs.molregno
JOIN
    activities act ON md.molregno = act.molregno
JOIN
    target_dictionary td ON act.tid = td.tid
WHERE
    td.chembl_id = 'CHEMBL205'  -- Dopamine D4 receptor
    AND act.standard_type = 'IC50'
    AND act.standard_units = 'nM'
    AND act.standard_value IS NOT NULL
    AND act.standard_value > 0  -- Avoid zero values
    AND act.standard_value < 10000 -- Limit to 10000 nM for activity
LIMIT 100; -- Limit to 100 rows
```

**LÆ°u Ã½ vá» lá»—i SQL (Note about SQL error):**

Lá»—i `ERROR: operator does not exist: numeric ~ unknown, LINE 12: AND act.standard_value ~ '^[0-9\.]+$'` xáº£y ra do báº¡n Ä‘ang cá»‘ gáº¯ng sá»­ dá»¥ng toÃ¡n tá»­ `~` (regular expression match) trÃªn má»™t cá»™t kiá»ƒu sá»‘ (numeric). Äá»ƒ kháº¯c phá»¥c, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng hÃ m `CAST` Ä‘á»ƒ chuyá»ƒn Ä‘á»•i cá»™t `standard_value` sang kiá»ƒu text trÆ°á»›c khi so sÃ¡nh vá»›i regular expression, hoáº·c bá» Ä‘iá»u kiá»‡n nÃ y náº¿u khÃ´ng cáº§n thiáº¿t.

VÃ­ dá»¥:

```sql
-- Remove the line causing the error:
-- AND act.standard_value ~ '^[0-9\.]+$'

-- Or cast the numeric value to text:
-- AND CAST(act.standard_value AS TEXT) ~ '^[0-9\.]+$'
```

**3.2. Python Code Example**

```python
import os
import pandas as pd
from rdkit import Chem
from rdkit.Chem import Descriptors
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# Define the base path
base_path = ".."  # Assuming the notebook is in a subdirectory

# Define the path to the CSV file
csv_file_path = os.path.join(base_path, "data", "chembl_205_ic50.csv")  # Replace with your actual filename

# Load the data from the CSV file
try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"Error: File not found at {csv_file_path}")
    exit()

# Handle missing values: Remove rows with missing values in 'standard_value'
df = df.dropna(subset=['standard_value', 'canonical_smiles'])
df = df.head(100)


# RDKit function to calculate molecular descriptors
def calculate_descriptors(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None  # Handle invalid SMILES strings
    descriptors = {}
    descriptors['MolWt'] = Descriptors.MolWt(mol)
    descriptors['LogP'] = Descriptors.MolLogP(mol)
    descriptors['HBD'] = Descriptors.NumHDonors(mol)
    descriptors['HBA'] = Descriptors.NumHAcceptors(mol)
    return descriptors

# Apply descriptor calculation to each molecule
df['descriptors'] = df['canonical_smiles'].apply(calculate_descriptors)

# Filter out rows where descriptor calculation failed (invalid SMILES)
df = df[df['descriptors'].notna()]

# Convert descriptor dictionaries to columns
df = pd.concat([df.drop(['descriptors'], axis=1), df['descriptors'].apply(pd.Series)], axis=1)

# Prepare data for machine learning
X = df[['MolWt', 'LogP', 'HBD', 'HBA']]  # Feature matrix
y = -np.log10(df['standard_value'])  # Target variable (transformed IC50)

# Data scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train a linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

**LÆ°u Ã½ vá» lá»—i Python (Note about Python error):**

Náº¿u báº¡n gáº·p lá»—i vá» `squared=False` trong hÃ m `mean_squared_error`, hÃ£y kiá»ƒm tra phiÃªn báº£n scikit-learn cá»§a báº¡n. Náº¿u phiÃªn báº£n cÅ©, hÃ£y nÃ¢ng cáº¥p lÃªn phiÃªn báº£n má»›i nháº¥t báº±ng lá»‡nh:

```bash
pip install -U scikit-learn
```

Náº¿u báº¡n khÃ´ng muá»‘n nÃ¢ng cáº¥p, báº¡n cÃ³ thá»ƒ tÃ­nh cÄƒn báº­c hai cá»§a MSE Ä‘á»ƒ cÃ³ RMSE (Root Mean Squared Error), tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i MSE khi `squared=False`.

**4. VÃ­ dá»¥ (Examples)**

DÆ°á»›i Ä‘Ã¢y lÃ  5 vÃ­ dá»¥ vá» cÃ¡c cÃ¢u lá»‡nh SQL vÃ  Python mÃ  báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng trong dá»± Ã¡n cá»§a mÃ¬nh:

**4.1. VÃ­ dá»¥ 1: TrÃ­ch xuáº¥t dá»¯ liá»‡u cÆ¡ báº£n (Basic data extraction)**

*   **SQL:**

```sql
SELECT chembl_id, pref_name FROM molecule_dictionary LIMIT 10;
```

*   **Python:**

```python
import pandas as pd
# Assuming you have a CSV file named 'molecule_dictionary.csv'
df = pd.read_csv('../data/molecule_dictionary.csv', nrows=10)
print(df.head())
```

**4.2. VÃ­ dá»¥ 2: TÃ­nh toÃ¡n Ä‘áº·c trÆ°ng phÃ¢n tá»­ Ä‘Æ¡n giáº£n (Simple descriptor calculation)**

*   **Python:**

```python
from rdkit import Chem
from rdkit.Chem import Descriptors

smiles = 'CC(=O)Oc1ccccc1C(=O)O' # Aspirin
mol = Chem.MolFromSmiles(smiles)
mol_wt = Descriptors.MolWt(mol)
print(f"Molecular weight of Aspirin: {mol_wt}")
```

**4.3. VÃ­ dá»¥ 3: Lá»c dá»¯ liá»‡u theo hoáº¡t tÃ­nh (Filtering data by activity)**

*   **SQL:**

```sql
SELECT md.chembl_id, act.standard_value
FROM molecule_dictionary md
JOIN activities act ON md.molregno = act.molregno
WHERE act.standard_type = 'IC50' AND act.standard_value < 100;
```

*   **Python:**

```python
# Assuming you have a DataFrame named 'activities_df'
activities_df = pd.read_csv('../data/activities.csv')
filtered_df = activities_df[(activities_df['standard_type'] == 'IC50') & (activities_df['standard_value'] < 100)]
print(filtered_df.head())
```

**4.4. VÃ­ dá»¥ 4: Gom nhÃ³m dá»¯ liá»‡u (Grouping data)**

*   **SQL:**

```sql
SELECT target_dictionary.chembl_id, COUNT(*)
FROM activities
JOIN target_dictionary ON activities.tid = target_dictionary.tid
GROUP BY target_dictionary.chembl_id
ORDER BY COUNT(*) DESC
LIMIT 10;
```

*   **Python:**

```python
# Assuming you have a DataFrame named 'activities_df' and 'target_dictionary_df'
activities_df = pd.read_csv('../data/activities.csv')
target_dictionary_df = pd.read_csv('../data/target_dictionary.csv')

merged_df = pd.merge(activities_df, target_dictionary_df, on='tid')
grouped_df = merged_df.groupby('chembl_id')['molregno'].count().sort_values(ascending=False).head(10)
print(grouped_df)
```

**4.5. VÃ­ dá»¥ 5: XÃ¢y dá»±ng mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n (Simple model building)**

*   **Python:**

```python
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
import numpy as np

# Assuming you have features X and target variable y
X = np.random.rand(100, 5)
y = np.random.rand(100)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = LinearRegression()
model.fit(X_train, y_train)

score = model.score(X_test, y_test)
print(f"Model R^2 score: {score}")
```

**LÆ°u Ã½ quan trá»ng:**

*   HÃ£y thay Ä‘á»•i Ä‘Æ°á»ng dáº«n file CSV vÃ  cÃ¡c tham sá»‘ khÃ¡c cho phÃ¹ há»£p vá»›i dá»± Ã¡n cá»§a báº¡n.
*   Äáº£m báº£o ráº±ng báº¡n Ä‘Ã£ cÃ i Ä‘áº·t táº¥t cáº£ cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t (RDKit, pandas, scikit-learn, matplotlib, seaborn).
*   HÃ£y chia nhá» cÃ¡c bÆ°á»›c phÃ¢n tÃ­ch vÃ  kiá»ƒm tra káº¿t quáº£ thÆ°á»ng xuyÃªn Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng má»i thá»© hoáº¡t Ä‘á»™ng chÃ­nh xÃ¡c.

TÃ´i hy vá»ng nhá»¯ng hÆ°á»›ng dáº«n vÃ  vÃ­ dá»¥ nÃ y sáº½ giÃºp báº¡n báº¯t Ä‘áº§u dá»± Ã¡n phÃ¢n tÃ­ch dá»¯ liá»‡u ChEMBL 35 má»™t cÃ¡ch hiá»‡u quáº£. Náº¿u báº¡n cÃ³ báº¥t ká»³ cÃ¢u há»i nÃ o, Ä‘á»«ng ngáº§n ngáº¡i há»i! ChÃºc báº¡n thÃ nh cÃ´ng!
