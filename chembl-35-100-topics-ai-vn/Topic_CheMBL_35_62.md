# PharmApp Suite
## üß† AI for Drug Discovery and Development üß™
| Copyright 2025 | Nghi√™n C·ª©u Thu·ªëc | www.nghiencuuthuoc.com | Zalo: +84888999311 |

üß© Topic: M√¥ h√¨nh h·ªçc s√¢u ƒë·ªÉ d·ª± ƒëo√°n ho·∫°t t√≠nh
---
Tuy·ªát v·ªùi! V·ªõi vai tr√≤ l√† m·ªôt chuy√™n gia R&D d∆∞·ª£c h·ªçc, t√¥i r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n trong d·ª± √°n ph√¢n t√≠ch d·ªØ li·ªáu ChEMBL 35 k·∫øt h·ª£p RDKit n√†y. D·ª±a tr√™n th√¥ng tin b·∫°n cung c·∫•p, t√¥i s·∫Ω gi√∫p b·∫°n ph√¢n t√≠ch, h∆∞·ªõng d·∫´n, cung c·∫•p code m·∫´u SQL v√† Python ƒë·ªÉ b·∫°n c√≥ th·ªÉ b·∫Øt ƒë·∫ßu d·ª± √°n m·ªôt c√°ch hi·ªáu qu·∫£.

**1. Ph√¢n t√≠ch m√¥ h√¨nh ph√¢n t√≠ch (Analysis of the analysis model):**

Ch√∫ng ta s·∫Ω t·∫≠p trung v√†o vi·ªác tr√≠ch xu·∫•t v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ c∆° s·ªü d·ªØ li·ªáu ChEMBL 35, sau ƒë√≥ s·ª≠ d·ª•ng RDKit ƒë·ªÉ t√≠nh to√°n c√°c ƒë·∫∑c tr∆∞ng ph√¢n t·ª≠ (molecular descriptors) v√† cu·ªëi c√πng x√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n ho·∫°t t√≠nh sinh h·ªçc. M√¥ h√¨nh ph√¢n t√≠ch s·∫Ω bao g·ªìm c√°c b∆∞·ªõc sau:

*   **Tr√≠ch xu·∫•t d·ªØ li·ªáu (Data Extraction):** S·ª≠ d·ª•ng SQL ƒë·ªÉ l·∫•y th√¥ng tin v·ªÅ c√°c h·ª£p ch·∫•t v√† ho·∫°t t√≠nh c·ªßa ch√∫ng t·ª´ c∆° s·ªü d·ªØ li·ªáu ChEMBL 35.
*   **Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu (Data Preprocessing):** L√†m s·∫°ch d·ªØ li·ªáu, lo·∫°i b·ªè c√°c gi√° tr·ªã kh√¥ng h·ª£p l·ªá ho·∫∑c thi·∫øu, v√† chu·∫©n h√≥a d·ªØ li·ªáu (v√≠ d·ª•: chuy·ªÉn ƒë·ªïi IC50 th√†nh pIC50).
*   **T√≠nh to√°n ƒë·∫∑c tr∆∞ng ph√¢n t·ª≠ (Molecular Descriptor Calculation):** S·ª≠ d·ª•ng RDKit ƒë·ªÉ t√≠nh to√°n c√°c ƒë·∫∑c tr∆∞ng ph√¢n t·ª≠ nh∆∞ tr·ªçng l∆∞·ª£ng ph√¢n t·ª≠, h·ªá s·ªë ph√¢n v√πng octanol-n∆∞·ªõc (LogP), di·ªán t√≠ch b·ªÅ m·∫∑t ph√¢n c·ª±c (TPSA), v√† c√°c ƒë·∫∑c tr∆∞ng h√¨nh th√°i kh√°c.
*   **Ph√¢n t√≠ch d·ªØ li·ªáu (Data Analysis):** S·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t th·ªëng k√™ v√† h·ªçc m√°y ƒë·ªÉ ph√¢n t√≠ch d·ªØ li·ªáu v√† x√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n ho·∫°t t√≠nh sinh h·ªçc.
*   **ƒê√°nh gi√° m√¥ h√¨nh (Model Evaluation):** ƒê√°nh gi√° hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh b·∫±ng c√°ch s·ª≠ d·ª•ng c√°c ch·ªâ s·ªë nh∆∞ R-squared, RMSE, MAE, v√† AUC.

**2. H∆∞·ªõng d·∫´n song ng·ªØ (Bilingual Instructions):**

**English:**

This project aims to analyze ChEMBL 35 data using RDKit to support drug discovery and development. We will extract data from the ChEMBL 35 database, preprocess it, calculate molecular descriptors using RDKit, and build a predictive model for biological activity.

**Ti·∫øng Vi·ªát:**

D·ª± √°n n√†y nh·∫±m m·ª•c ƒë√≠ch ph√¢n t√≠ch d·ªØ li·ªáu ChEMBL 35 b·∫±ng RDKit ƒë·ªÉ h·ªó tr·ª£ nghi√™n c·ª©u v√† ph√°t tri·ªÉn thu·ªëc. Ch√∫ng ta s·∫Ω tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ c∆° s·ªü d·ªØ li·ªáu ChEMBL 35, ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu, t√≠nh to√°n c√°c ƒë·∫∑c tr∆∞ng ph√¢n t·ª≠ b·∫±ng RDKit v√† x√¢y d·ª±ng m√¥ h√¨nh d·ª± ƒëo√°n ho·∫°t t√≠nh sinh h·ªçc.

**3. Code SQL v√† Python (SQL and Python Code):**

**3.1 SQL Code (for data extraction):**

```sql
-- English: Extracting 100 compounds and their activity data from ChEMBL 35
-- Ti·∫øng Vi·ªát: Tr√≠ch xu·∫•t 100 h·ª£p ch·∫•t v√† d·ªØ li·ªáu ho·∫°t t√≠nh c·ªßa ch√∫ng t·ª´ ChEMBL 35
SELECT DISTINCT
    md.molregno,
    cs.canonical_smiles,
    act.standard_type,
    act.standard_value,
    act.standard_units
FROM
    molecule_dictionary md
JOIN
    compound_structures cs ON md.molregno = cs.molregno
JOIN
    activities act ON md.molregno = act.molregno
WHERE act.standard_type = 'IC50'
  AND act.standard_units = 'nM'
  AND act.standard_value IS NOT NULL
LIMIT 100;
```

**L∆∞u √Ω v·ªÅ l·ªói SQL:**

L·ªói `ERROR: operator does not exist: numeric ~ unknown, LINE 12: AND act.standard_value ~ '^[0-9\.]+$'` x·∫£y ra do b·∫°n ƒëang c·ªë g·∫Øng s·ª≠ d·ª•ng to√°n t·ª≠ `~` (regular expression match) tr√™n m·ªôt c·ªôt ki·ªÉu s·ªë (numeric). ƒê·ªÉ kh·∫Øc ph·ª•c, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng h√†m `CAST` ƒë·ªÉ chuy·ªÉn ƒë·ªïi c·ªôt `standard_value` th√†nh ki·ªÉu text tr∆∞·ªõc khi so s√°nh:

```sql
-- English: Corrected SQL query to handle numeric data type
-- Ti·∫øng Vi·ªát: S·ª≠a truy v·∫•n SQL ƒë·ªÉ x·ª≠ l√Ω ki·ªÉu d·ªØ li·ªáu s·ªë
SELECT DISTINCT
    md.molregno,
    cs.canonical_smiles,
    act.standard_type,
    act.standard_value,
    act.standard_units
FROM
    molecule_dictionary md
JOIN
    compound_structures cs ON md.molregno = cs.molregno
JOIN
    activities act ON md.molregno = act.molregno
WHERE act.standard_type = 'IC50'
  AND act.standard_units = 'nM'
  AND act.standard_value IS NOT NULL
  AND CAST(act.standard_value AS TEXT) SIMILAR TO '[0-9.]+'
LIMIT 100;
```

**3.2 Python Code (for data processing and analysis):**

```python
# English: Python code for data processing and analysis
# Ti·∫øng Vi·ªát: M√£ Python ƒë·ªÉ x·ª≠ l√Ω v√† ph√¢n t√≠ch d·ªØ li·ªáu

import pandas as pd
import numpy as np
from rdkit import Chem
from rdkit.Chem import Descriptors
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import os

# Define base path
base_path = "."  # Assuming the notebook is in the root of the project

# Construct the data path
data_path = os.path.join(base_path, "data", "chembl_data.csv") # Assuming your data file is named chembl_data.csv

# Load data from CSV file
try:
    df = pd.read_csv(data_path)
    print("Data loaded successfully!")
except FileNotFoundError:
    print(f"Error: File not found at {data_path}. Please make sure the file exists.")
    exit()
except Exception as e:
    print(f"Error loading data: {e}")
    exit()


# Function to calculate molecular descriptors using RDKit
def calculate_descriptors(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    descriptors = {}
    descriptors['MolWt'] = Descriptors.MolWt(mol)
    descriptors['LogP'] = Descriptors.MolLogP(mol)
    descriptors['HBD'] = Descriptors.NumHDonors(mol)
    descriptors['HBA'] = Descriptors.NumHAcceptors(mol)
    descriptors['TPSA'] = Descriptors.TPSA(mol)
    return descriptors

# Apply the function to calculate descriptors
df['descriptors'] = df['canonical_smiles'].apply(calculate_descriptors)

# Handle missing descriptors
df = df.dropna(subset=['descriptors'])

# Convert descriptors to DataFrame columns
df = pd.concat([df, df['descriptors'].apply(pd.Series)], axis=1)

# Convert IC50 to pIC50
df['pIC50'] = -np.log10(df['standard_value'].astype(float) / 1e9)

# Select features and target
features = ['MolWt', 'LogP', 'HBD', 'HBA', 'TPSA']
target = 'pIC50'

# Prepare data for modeling
X = df[features]
y = df[target]

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train a linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

**L∆∞u √Ω v·ªÅ l·ªói Python:**

L·ªói "phi√™n b·∫£n scikit-learn c≈© kh√¥ng h·ªó tr·ª£ tham s·ªë squared=False trong h√†m mean_squared_error" kh√¥ng c√≤n l√† v·∫•n ƒë·ªÅ v√¨ b·∫°n kh√¥ng s·ª≠ d·ª•ng tham s·ªë `squared=False` trong code.

**4. V√≠ d·ª• code SQL v√† Python (SQL and Python Code Examples):**

D∆∞·ªõi ƒë√¢y l√† 5 v√≠ d·ª• v·ªÅ c√°c truy v·∫•n SQL v√† code Python kh√°c nhau m√† b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng trong d·ª± √°n c·ªßa m√¨nh:

**V√≠ d·ª• 1: T√¨m ki·∫øm c√°c h·ª£p ch·∫•t c√≥ ho·∫°t t√≠nh cao nh·∫•t (Finding the most active compounds):**

**SQL:**

```sql
-- English: Find the top 10 most active compounds based on IC50 values
-- Ti·∫øng Vi·ªát: T√¨m 10 h·ª£p ch·∫•t c√≥ ho·∫°t t√≠nh cao nh·∫•t d·ª±a tr√™n gi√° tr·ªã IC50
SELECT md.molregno, cs.canonical_smiles, act.standard_value
FROM molecule_dictionary md
JOIN compound_structures cs ON md.molregno = cs.molregno
JOIN activities act ON md.molregno = act.molregno
WHERE act.standard_type = 'IC50'
  AND act.standard_units = 'nM'
ORDER BY act.standard_value ASC
LIMIT 10;
```

**Python:**

```python
# English: Calculate and display the correlation matrix of the descriptors
# Ti·∫øng Vi·ªát: T√≠nh to√°n v√† hi·ªÉn th·ªã ma tr·∫≠n t∆∞∆°ng quan c·ªßa c√°c descriptors
import seaborn as sns
import matplotlib.pyplot as plt

# Calculate the correlation matrix
correlation_matrix = df[features].corr()

# Plot the correlation matrix
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm")
plt.title("Correlation Matrix of Molecular Descriptors")
plt.show()
```

**V√≠ d·ª• 2: T√≠nh to√°n ph√¢n b·ªë c·ªßa LogP (Calculating LogP distribution):**

**SQL:**

```sql
-- English: Calculate the average LogP value for compounds in ChEMBL 35
-- Ti·∫øng Vi·ªát: T√≠nh gi√° tr·ªã LogP trung b√¨nh cho c√°c h·ª£p ch·∫•t trong ChEMBL 35
-- This requires you to have LogP values stored in the database.
-- ƒêi·ªÅu n√†y y√™u c·∫ßu b·∫°n ph·∫£i c√≥ gi√° tr·ªã LogP ƒë∆∞·ª£c l∆∞u tr·ªØ trong c∆° s·ªü d·ªØ li·ªáu.

-- Assuming you have a table with LogP values, adapt this query accordingly.
-- Gi·∫£ s·ª≠ b·∫°n c√≥ m·ªôt b·∫£ng v·ªõi gi√° tr·ªã LogP, h√£y ƒëi·ªÅu ch·ªânh truy v·∫•n n√†y cho ph√π h·ª£p.
-- Example:
-- V√≠ d·ª•:
-- SELECT AVG(logp_value) FROM compounds;
```

**Python:**

```python
# English: Plot the distribution of pIC50 values
# Ti·∫øng Vi·ªát: V·∫Ω bi·ªÉu ƒë·ªì ph√¢n b·ªë gi√° tr·ªã pIC50
plt.figure(figsize=(8, 6))
sns.histplot(df['pIC50'], kde=True)
plt.title("Distribution of pIC50 Values")
plt.xlabel("pIC50")
plt.ylabel("Frequency")
plt.show()
```

**V√≠ d·ª• 3: L·ªçc c√°c h·ª£p ch·∫•t theo tr·ªçng l∆∞·ª£ng ph√¢n t·ª≠ (Filtering compounds by molecular weight):**

**SQL:**

```sql
-- English: Find compounds with molecular weight between 200 and 400
-- Ti·∫øng Vi·ªát: T√¨m c√°c h·ª£p ch·∫•t c√≥ tr·ªçng l∆∞·ª£ng ph√¢n t·ª≠ t·ª´ 200 ƒë·∫øn 400
-- This requires you to have molecular weight values stored in the database.
-- ƒêi·ªÅu n√†y y√™u c·∫ßu b·∫°n ph·∫£i c√≥ gi√° tr·ªã tr·ªçng l∆∞·ª£ng ph√¢n t·ª≠ ƒë∆∞·ª£c l∆∞u tr·ªØ trong c∆° s·ªü d·ªØ li·ªáu.

-- Assuming you have a table with molecular weight values, adapt this query accordingly.
-- Gi·∫£ s·ª≠ b·∫°n c√≥ m·ªôt b·∫£ng v·ªõi gi√° tr·ªã tr·ªçng l∆∞·ª£ng ph√¢n t·ª≠, h√£y ƒëi·ªÅu ch·ªânh truy v·∫•n n√†y cho ph√π h·ª£p.
-- Example:
-- V√≠ d·ª•:
-- SELECT molregno, canonical_smiles FROM compounds WHERE mol_weight BETWEEN 200 AND 400;
```

**Python:**

```python
# English: Train a Random Forest Regressor model
# Ti·∫øng Vi·ªát: Hu·∫•n luy·ªán m√¥ h√¨nh Random Forest Regressor
from sklearn.ensemble import RandomForestRegressor

# Create and train a Random Forest Regressor model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions
y_pred_rf = rf_model.predict(X_test)

# Evaluate the model
mse_rf = mean_squared_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)

print(f"Random Forest Mean Squared Error: {mse_rf}")
print(f"Random Forest R-squared: {r2_rf}")
```

**V√≠ d·ª• 4: T√¨m ki·∫øm c√°c h·ª£p ch·∫•t c√≥ m·ªôt khung c·∫•u tr√∫c nh·∫•t ƒë·ªãnh (Searching for compounds with a specific scaffold):**

**SQL:**

```sql
-- English: Find compounds containing a specific substructure (e.g., benzene ring)
-- Ti·∫øng Vi·ªát: T√¨m c√°c h·ª£p ch·∫•t ch·ª©a m·ªôt c·∫•u tr√∫c con c·ª• th·ªÉ (v√≠ d·ª•: v√≤ng benzen)
-- This requires you to have a way to search for substructures in the database.
-- ƒêi·ªÅu n√†y y√™u c·∫ßu b·∫°n ph·∫£i c√≥ m·ªôt c√°ch ƒë·ªÉ t√¨m ki·∫øm c√°c c·∫•u tr√∫c con trong c∆° s·ªü d·ªØ li·ªáu.

-- Assuming you have a function or table for substructure search, adapt this query accordingly.
-- Gi·∫£ s·ª≠ b·∫°n c√≥ m·ªôt h√†m ho·∫∑c b·∫£ng ƒë·ªÉ t√¨m ki·∫øm c·∫•u tr√∫c con, h√£y ƒëi·ªÅu ch·ªânh truy v·∫•n n√†y cho ph√π h·ª£p.
-- Example:
-- V√≠ d·ª•:
-- SELECT molregno, canonical_smiles FROM compounds WHERE contains_substructure(canonical_smiles, 'c1ccccc1');
```

**Python:**

```python
# English: Calculate and display feature importance from the Random Forest model
# Ti·∫øng Vi·ªát: T√≠nh to√°n v√† hi·ªÉn th·ªã t·∫ßm quan tr·ªçng c·ªßa c√°c ƒë·∫∑c tr∆∞ng t·ª´ m√¥ h√¨nh Random Forest
feature_importances = rf_model.feature_importances_

# Create a DataFrame to store feature importances
feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})

# Sort the DataFrame by importance
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Print the feature importances
print("Feature Importances:")
print(feature_importance_df)

# Plot the feature importances
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df)
plt.title("Feature Importances in Random Forest Model")
plt.show()
```

**V√≠ d·ª• 5: Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu ƒë·ªÉ chu·∫©n b·ªã cho m√¥ h√¨nh h√≥a (Data preprocessing for modeling):**

**SQL:**

```sql
-- English: Extract data and convert IC50 to pIC50 within the SQL query
-- Ti·∫øng Vi·ªát: Tr√≠ch xu·∫•t d·ªØ li·ªáu v√† chuy·ªÉn ƒë·ªïi IC50 th√†nh pIC50 trong truy v·∫•n SQL
SELECT
    md.molregno,
    cs.canonical_smiles,
    act.standard_value,
    -LOG(act.standard_value * 1e-9) AS pIC50  -- Convert IC50 (nM) to pIC50
FROM
    molecule_dictionary md
JOIN
    compound_structures cs ON md.molregno = cs.molregno
JOIN
    activities act ON md.molregno = act.molregno
WHERE act.standard_type = 'IC50'
  AND act.standard_units = 'nM'
  AND act.standard_value IS NOT NULL
LIMIT 100;
```

**Python:**

```python
# English: Standardize features using StandardScaler
# Ti·∫øng Vi·ªát: Chu·∫©n h√≥a c√°c ƒë·∫∑c tr∆∞ng b·∫±ng StandardScaler
from sklearn.preprocessing import StandardScaler

# Create a StandardScaler object
scaler = StandardScaler()

# Fit the scaler on the training data and transform both training and testing data
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Now use the scaled data for modeling
model = LinearRegression()
model.fit(X_train_scaled, y_train)

# Make predictions
y_pred = model.predict(X_test_scaled)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")
```

**L∆∞u √Ω quan tr·ªçng:**

*   H√£y nh·ªõ ƒëi·ªÅu ch·ªânh c√°c truy v·∫•n SQL v√† code Python cho ph√π h·ª£p v·ªõi c·∫•u tr√∫c v√† n·ªôi dung c·ª• th·ªÉ c·ªßa c∆° s·ªü d·ªØ li·ªáu ChEMBL 35 c·ªßa b·∫°n.
*   ƒê·∫£m b·∫£o r·∫±ng b·∫°n ƒë√£ c√†i ƒë·∫∑t t·∫•t c·∫£ c√°c th∆∞ vi·ªán Python c·∫ßn thi·∫øt (v√≠ d·ª•: pandas, RDKit, scikit-learn). B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng pip ƒë·ªÉ c√†i ƒë·∫∑t ch√∫ng: `pip install pandas rdkit scikit-learn seaborn matplotlib`.
*   Khi l√†m vi·ªác v·ªõi d·ªØ li·ªáu l·ªõn, h√£y c√¢n nh·∫Øc s·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t t·ªëi ∆∞u h√≥a ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω.

Ch√∫c b·∫°n th√†nh c√¥ng v·ªõi d·ª± √°n c·ªßa m√¨nh! N·∫øu b·∫°n c√≥ b·∫•t k·ª≥ c√¢u h·ªèi n√†o kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i h·ªèi.
