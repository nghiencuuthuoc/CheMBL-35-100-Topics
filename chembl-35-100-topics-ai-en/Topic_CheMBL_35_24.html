
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <title>Topic_CheMBL_35_24</title>
            <style>
                body {
                    font-family: "Georgia", serif;
                    max-width: 800px;
                    margin: 40px auto;
                    padding: 20px;
                    line-height: 1.6;
                    background-color: #ffffff;
                    color: #333;
                }
                h1, h2, h3 {
                    color: #1a1a1a;
                }
                code {
                    background-color: #f5f5f5;
                    padding: 2px 4px;
                    border-radius: 4px;
                }
                pre {
                    background-color: #f5f5f5;
                    padding: 10px;
                    overflow-x: auto;
                    border-radius: 6px;
                }
            </style>
        </head>
        <body>
        <h1>PharmApp Suite</h1>
<h2>üß† AI for Drug Discovery and Development üß™</h2>
<p>| Copyright 2025 | RnD Pharma Plus | www.nghiencuuthuoc.comlus | Zalo: +84888999311 |</p>
<h1>üß© Topic: Target class distribution in ChEMBL</h1>
<hr />
<p>Okay, I understand. You're working with Chembl 35 data, using PostgreSQL with rdkit in a Jupyter Notebook environment following an AIMLops template. You've encountered SQL and Python errors and need guidance with corrected code, analysis, and examples.</p>
<p>Here‚Äôs a breakdown of the analysis, SQL, Python code (including error fixes), and examples.  I'll provide explanations in both English and Vietnamese.</p>
<p><strong>1. Analysis Model (Ph√¢n t√≠ch M√¥ h√¨nh)</strong></p>
<ul>
<li><strong>Objective (M·ª•c ti√™u):</strong>  To extract and analyze activity data from Chembl 35 for a specific target or compound class.  We'll filter the data to ensure it contains relevant and valid activity measurements (IC50, Ki, etc.) and then perform some basic analysis. This will involve filtering for activity values that are numeric and then exploring the distribution of these values.</li>
<li><strong>Data Source (Ngu·ªìn D·ªØ li·ªáu):</strong> Chembl 35 database, specifically activity data related to compounds.</li>
<li><strong>Key Tables (B·∫£ng ch√≠nh):</strong><ul>
<li><code>activities</code>: Contains activity measurements (IC50, Ki, etc.).</li>
<li><code>activity_properties</code>: Details about the activity, like the standard type (e.g., IC50).</li>
<li><code>assays</code>:  Information about the assay used to measure the activity.</li>
<li><code>target_dictionary</code>: Details about the target the compound is acting on.</li>
<li><code>molecule_dictionary</code>:  Information about the molecule (SMILES, etc.).</li>
</ul>
</li>
<li><strong>Data Preprocessing (X·ª≠ l√Ω d·ªØ li·ªáu):</strong><ul>
<li>Filtering for specific activity types (e.g., IC50).</li>
<li>Filtering for numeric activity values (addresses SQL error).</li>
<li>Converting activity values to a logarithmic scale (optional, often useful for potency).</li>
</ul>
</li>
<li><strong>Analysis (Ph√¢n t√≠ch):</strong><ul>
<li>Descriptive statistics (mean, median, standard deviation) of activity values.</li>
<li>Visualization of activity distributions (histograms, boxplots).</li>
<li>Potential correlation analysis with molecular properties (e.g., molecular weight, LogP).  This would require RDKit to calculate the molecular properties.</li>
</ul>
</li>
</ul>
<p><strong>2. SQL Code (M√£ SQL)</strong></p>
<p>Here's the SQL code, addressing the error you encountered and limiting the results to 100 rows.</p>
<p>```sql
-- Topic_CheMBL_35_24 - Extracting Activity Data</p>
<p>-- Ensure the rdkit extension is installed
CREATE EXTENSION IF NOT EXISTS rdkit;</p>
<p>-- Limit the results to 100 rows using LIMIT
SELECT
    md.chembl_id AS compound_chembl_id,
    ad.standard_type,
    ad.standard_value,
    ad.standard_units,
    td.chembl_id AS target_chembl_id,
    td.target_type,
    assays.description AS assay_description
FROM
    activities ad
JOIN
    activity_properties ap ON ad.activity_id = ap.activity_id
JOIN
    assays ON ad.assay_id = assays.assay_id
JOIN
    target_dictionary td ON assays.tid = td.tid
JOIN
    molecule_dictionary md ON ad.molregno = md.molregno
WHERE
    ad.standard_type IN ('IC50', 'Ki', 'EC50') -- Filter for common activity types
    AND ad.standard_relation = '=' -- Filter for direct relationships
    AND ad.standard_value IS NOT NULL -- Ensure value is not null
    AND ad.standard_value::text ~ '^[0-9.]+$'  -- Corrected: Filter for numeric values using explicit casting to text
    AND ad.standard_units = 'nM'  -- Filter for consistent units (nanomolar)
    AND td.target_type = 'SINGLE PROTEIN' -- Filter for single protein targets
LIMIT 100;</p>
<p>-- Save the results to a CSV file (using pgAdmin's export functionality or psql's \copy command)
```</p>
<p><strong>Explanation (Gi·∫£i th√≠ch):</strong></p>
<ul>
<li><code>CREATE EXTENSION IF NOT EXISTS rdkit;</code>: Enables the RDKit extension. Important for cheminformatics functionality.</li>
<li><code>WHERE ad.standard_value::text ~ '^[0-9\.]+$'</code>:  <strong>Corrected the error.</strong>  The original error occurred because PostgreSQL couldn't directly compare a numeric type to a regular expression.  The <code>::text</code> casts the <code>standard_value</code> to text, allowing the regular expression <code>'^[0-9\.]+$'</code> to check if it contains only numbers and dots (allowing for decimal values).</li>
<li><code>LIMIT 100</code>: Restricts the output to the first 100 rows.</li>
<li>The query joins multiple tables to retrieve compound IDs, activity data, target information, and assay details.</li>
<li>Filters are applied to select specific activity types (IC50, Ki, EC50), a direct relationship (=), non-null values, numeric values, nM units, and single protein targets.</li>
</ul>
<p><strong>Vietnamese Explanation (Gi·∫£i th√≠ch ti·∫øng Vi·ªát):</strong></p>
<ul>
<li><code>CREATE EXTENSION IF NOT EXISTS rdkit;</code>: K√≠ch ho·∫°t ti·ªán √≠ch RDKit. Quan tr·ªçng cho c√°c ch·ª©c nƒÉng tin sinh h·ªçc h√≥a h·ªçc.</li>
<li><code>WHERE ad.standard_value::text ~ '^[0-9\.]+$'</code>: <strong>ƒê√£ s·ª≠a l·ªói.</strong> L·ªói ban ƒë·∫ßu x·∫£y ra v√¨ PostgreSQL kh√¥ng th·ªÉ so s√°nh tr·ª±c ti·∫øp ki·ªÉu s·ªë v·ªõi bi·ªÉu th·ª©c ch√≠nh quy. <code>::text</code> chuy·ªÉn <code>standard_value</code> th√†nh vƒÉn b·∫£n, cho ph√©p bi·ªÉu th·ª©c ch√≠nh quy <code>'^[0-9\.]+$'</code> ki·ªÉm tra xem n√≥ ch·ªâ ch·ª©a s·ªë v√† d·∫•u ch·∫•m (cho ph√©p gi√° tr·ªã th·∫≠p ph√¢n).</li>
<li><code>LIMIT 100</code>: Gi·ªõi h·∫°n ƒë·∫ßu ra th√†nh 100 h√†ng ƒë·∫ßu ti√™n.</li>
<li>Truy v·∫•n n√†y k·∫øt h·ª£p nhi·ªÅu b·∫£ng ƒë·ªÉ l·∫•y ID h·ª£p ch·∫•t, d·ªØ li·ªáu ho·∫°t ƒë·ªông, th√¥ng tin m·ª•c ti√™u v√† chi ti·∫øt th·ª≠ nghi·ªám.</li>
<li>B·ªô l·ªçc ƒë∆∞·ª£c √°p d·ª•ng ƒë·ªÉ ch·ªçn c√°c lo·∫°i ho·∫°t ƒë·ªông c·ª• th·ªÉ (IC50, Ki, EC50), m·ªëi quan h·ªá tr·ª±c ti·∫øp (=), gi√° tr·ªã kh√¥ng r·ªóng, gi√° tr·ªã s·ªë, ƒë∆°n v·ªã nM v√† m·ª•c ti√™u protein ƒë∆°n l·∫ª.</li>
</ul>
<p><strong>To Save to CSV (ƒê·ªÉ L∆∞u v√†o CSV):</strong></p>
<ol>
<li><strong>pgAdmin:</strong> After running the query in pgAdmin, use the "Export" functionality (usually found in the query result window) to save the results as a CSV file to your <code>../data/</code> directory.</li>
<li>
<p><strong>psql:</strong>  Alternatively, from the command line using <code>psql</code>:</p>
<p><code>bash
psql -h 192.168.206.136 -U rd -d chembl_35 -c "COPY (SELECT ... your SQL query here ...) TO '/path/to/your/data/chembl_data.csv' WITH (FORMAT CSV, HEADER);"</code></p>
<p>Replace <code>/path/to/your/data/</code> with the actual path.  You might need to adjust permissions to allow the <code>postgres</code> user to write to that directory.</p>
</li>
</ol>
<p><strong>3. Python Code (M√£ Python)</strong></p>
<p>```python</p>
<h1>-<em>- coding: utf-8 -</em>-</h1>
<p>import pandas as pd
import numpy as np
import os
from rdkit import Chem
from rdkit.Chem import Descriptors
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt</p>
<h1>Define the base path according to AIMLops template</h1>
<p>base_path = "../data"  # Adjust if your base path is different
csv_file_path = os.path.join(base_path, "chembl_data.csv")  # Assuming you saved the SQL results as chembl_data.csv</p>
<h1>Load the data</h1>
<p>try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"Error: File not found at {csv_file_path}. Make sure you've saved the CSV file from your SQL query.")
    exit()</p>
<h1>Data Cleaning and Preprocessing</h1>
<p>df = df.dropna(subset=['standard_value'])  # Remove rows with missing standard_value
df = df[pd.to_numeric(df['standard_value'], errors='coerce').notna()] # Ensure standard_value is numeric after reading from csv</p>
<h1>Convert standard_value to numeric</h1>
<p>df['standard_value'] = pd.to_numeric(df['standard_value'])</p>
<h1>Filter for IC50 values only, you can adjust this based on your needs</h1>
<p>df = df[df['standard_type'] == 'IC50']</p>
<h1>Convert IC50 to pIC50 (optional but common)</h1>
<p>df['pIC50'] = -np.log10(df['standard_value'] * 1e-9) # Convert nM to M and then to pIC50</p>
<h1>RDKit - Calculate Molecular Descriptors (example)</h1>
<p>def calculate_descriptors(smiles):
    try:
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return None
        descriptors = {desc[0]: desc<a href="mol">1</a> for desc in Descriptors.descList}
        return descriptors
    except:
        return None</p>
<h1>Fetch canonical smiles from molecule_dictionary.</h1>
<h1>You will need another query to fetch smiles and merge it into the dataframe</h1>
<h1>For the example, let's assume you have a 'smiles' column in your df</h1>
<h1>Example only - Generating random SMILES (replace with your actual smiles data)</h1>
<p>import random
df['smiles'] = [Chem.MolToSmiles(Chem.MolFromSmiles('C' * random.randint(1, 10))) for _ in range(len(df))]</p>
<p>df['descriptors'] = df['smiles'].apply(calculate_descriptors)</p>
<h1>Handle cases where descriptor calculation failed</h1>
<p>df = df.dropna(subset=['descriptors'])</p>
<h1>Convert the 'descriptors' column to a DataFrame</h1>
<p>descriptors_df = pd.DataFrame(df['descriptors'].tolist())</p>
<h1>Remove columns with NaN values (if any)</h1>
<p>descriptors_df = descriptors_df.dropna(axis=1, how='any')</p>
<h1>Merge descriptors with main dataframe</h1>
<p>df = pd.concat([df, descriptors_df], axis=1)</p>
<h1>Drop the original 'descriptors' and 'smiles' column</h1>
<p>df = df.drop(columns=['descriptors', 'smiles'])</p>
<h1>Prepare data for modeling</h1>
<p>X = df.select_dtypes(include=np.number).drop(columns=['standard_value', 'pIC50'])  # Select numerical features, remove target
y = df['pIC50'] # Target variable</p>
<h1>Handle missing values by imputation</h1>
<p>from sklearn.impute import SimpleImputer</p>
<p>imputer = SimpleImputer(strategy='mean')  # Replace missing values with the mean
X = imputer.fit_transform(X)</p>
<h1>Split data into training and testing sets</h1>
<p>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</p>
<h1>Train a Linear Regression model</h1>
<p>model = LinearRegression()
model.fit(X_train, y_train)</p>
<h1>Make predictions</h1>
<p>y_pred = model.predict(X_test)</p>
<h1>Evaluate the model</h1>
<p>mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)</p>
<p>print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")</p>
<h1>Visualization (example)</h1>
<p>plt.scatter(y_test, y_pred)
plt.xlabel("Actual pIC50")
plt.ylabel("Predicted pIC50")
plt.title("Actual vs. Predicted pIC50 Values")
plt.show()
```</p>
<p><strong>Explanation (Gi·∫£i th√≠ch):</strong></p>
<ul>
<li><strong>Imports:</strong> Imports necessary libraries (pandas, numpy, rdkit, sklearn).</li>
<li><strong>File Loading:</strong> Loads the CSV file you created from the SQL query.  Handles potential <code>FileNotFoundError</code>.</li>
<li><strong>Data Cleaning:</strong>  Removes rows with missing or non-numeric <code>standard_value</code>.  Specifically handles cases where <code>standard_value</code> is read as object after loading csv and needs to be converted to numeric and removes rows where this conversion fails.</li>
<li><strong>Unit Conversion (Optional):</strong> Converts <code>IC50</code> values to <code>pIC50</code> (a common transformation).</li>
<li><strong>RDKit Integration:</strong><ul>
<li>The <code>calculate_descriptors</code> function calculates molecular descriptors using RDKit, converting SMILES strings into molecular objects and extracting relevant properties.</li>
<li>It handles potential errors during SMILES parsing.</li>
</ul>
</li>
<li><strong>Feature Engineering:</strong> Converts calculated descriptors to columns and concatenates to the main dataframe</li>
<li><strong>Data Preparation:</strong><ul>
<li>Selects numerical features from the DataFrame to use as input for the model (X).</li>
<li>Defines the target variable (y) as the 'pIC50' column.</li>
<li>Handles missing values using <code>SimpleImputer</code>.</li>
</ul>
</li>
<li><strong>Model Training:</strong> Trains a Linear Regression model using the training data.</li>
<li><strong>Model Evaluation:</strong> Evaluates the model using Mean Squared Error (MSE) and R-squared (R2).</li>
<li><strong>Visualization:</strong> Creates a scatter plot of actual vs. predicted pIC50 values.</li>
</ul>
<p><strong>Vietnamese Explanation (Gi·∫£i th√≠ch ti·∫øng Vi·ªát):</strong></p>
<ul>
<li><strong>Nh·∫≠p th∆∞ vi·ªán:</strong> Nh·∫≠p c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt (pandas, numpy, rdkit, sklearn).</li>
<li><strong>T·∫£i t·ªáp:</strong> T·∫£i t·ªáp CSV b·∫°n ƒë√£ t·∫°o t·ª´ truy v·∫•n SQL. X·ª≠ l√Ω <code>FileNotFoundError</code> ti·ªÅm nƒÉng.</li>
<li><strong>L√†m s·∫°ch d·ªØ li·ªáu:</strong> Lo·∫°i b·ªè c√°c h√†ng c√≥ <code>standard_value</code> b·ªã thi·∫øu ho·∫∑c kh√¥ng ph·∫£i l√† s·ªë.</li>
<li><strong>Chuy·ªÉn ƒë·ªïi ƒë∆°n v·ªã (T√πy ch·ªçn):</strong> Chuy·ªÉn ƒë·ªïi c√°c gi√° tr·ªã <code>IC50</code> th√†nh <code>pIC50</code> (m·ªôt bi·∫øn ƒë·ªïi ph·ªï bi·∫øn).</li>
<li><strong>T√≠ch h·ª£p RDKit:</strong><ul>
<li>H√†m <code>calculate_descriptors</code> t√≠nh to√°n c√°c m√¥ t·∫£ ph√¢n t·ª≠ b·∫±ng RDKit, chuy·ªÉn ƒë·ªïi chu·ªói SMILES th√†nh c√°c ƒë·ªëi t∆∞·ª£ng ph√¢n t·ª≠ v√† tr√≠ch xu·∫•t c√°c thu·ªôc t√≠nh c√≥ li√™n quan.</li>
<li>N√≥ x·ª≠ l√Ω c√°c l·ªói ti·ªÅm ·∫©n trong qu√° tr√¨nh ph√¢n t√≠ch c√∫ ph√°p SMILES.</li>
</ul>
</li>
<li><strong>Chu·∫©n b·ªã d·ªØ li·ªáu:</strong><ul>
<li>Ch·ªçn c√°c t√≠nh nƒÉng s·ªë t·ª´ DataFrame ƒë·ªÉ s·ª≠ d·ª•ng l√†m ƒë·∫ßu v√†o cho m√¥ h√¨nh (X).</li>
<li>X√°c ƒë·ªãnh bi·∫øn m·ª•c ti√™u (y) l√† c·ªôt 'pIC50'.</li>
</ul>
</li>
<li><strong>Hu·∫•n luy·ªán m√¥ h√¨nh:</strong> Hu·∫•n luy·ªán m·ªôt m√¥ h√¨nh H·ªìi quy tuy·∫øn t√≠nh b·∫±ng d·ªØ li·ªáu hu·∫•n luy·ªán.</li>
<li><strong>ƒê√°nh gi√° m√¥ h√¨nh:</strong> ƒê√°nh gi√° m√¥ h√¨nh b·∫±ng L·ªói b√¨nh ph∆∞∆°ng trung b√¨nh (MSE) v√† R-squared (R2).</li>
<li><strong>Tr·ª±c quan h√≥a:</strong> T·∫°o m·ªôt bi·ªÉu ƒë·ªì ph√¢n t√°n c·ªßa c√°c gi√° tr·ªã pIC50 th·ª±c t·∫ø so v·ªõi gi√° tr·ªã d·ª± ƒëo√°n.</li>
</ul>
<p><strong>4. Error Correction (S·ª≠a L·ªói)</strong></p>
<ul>
<li><strong>SQL Error:</strong> The SQL error <code>ERROR: operator does not exist: numeric ~ unknown</code> was fixed by explicitly casting the <code>standard_value</code> to text: <code>ad.standard_value::text ~ '^[0-9\.]+$'</code>.</li>
<li><strong>Old scikit-learn version:</strong>  You mentioned an issue with <code>squared=False</code> in <code>mean_squared_error</code>.  This parameter was added in a later version of scikit-learn.  The standard MSE calculation <em>is</em> squared, so if you're using an older version, just omit the <code>squared=False</code> argument.</li>
<li><strong>Ensure standard_value is numeric after reading from csv.</strong> After loading the csv, <code>standard_value</code> may be of <code>object</code> type, so the conversion and filtering are performed to avoid any type errors.</li>
<li><strong>Handle missing values</strong>: Missing values from the imported data will cause errors in the prediction process, so they should be handled with imputation.</li>
</ul>
<p><strong>5. Examples (V√≠ d·ª•)</strong></p>
<p>Here are five examples of how you can use this code, focusing on different aspects of the analysis. Each example builds on the previous code blocks.  These assume you've run the SQL query, saved the data to <code>chembl_data.csv</code>, and have the necessary libraries installed.</p>
<p><strong>Example 1: Basic Data Loading and Inspection (V√≠ d·ª• 1: T·∫£i v√† Ki·ªÉm tra D·ªØ li·ªáu C∆° b·∫£n)</strong></p>
<p>```python
import pandas as pd
import os</p>
<p>base_path = "../data"
csv_file_path = os.path.join(base_path, "chembl_data.csv")</p>
<p>try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"Error: File not found at {csv_file_path}.")
    exit()</p>
<p>print(df.head())  # Display the first few rows
print(df.info())  # Get information about the DataFrame (data types, missing values)
```</p>
<p><strong>Explanation:</strong> This example simply loads the data and prints the first few rows and information about the DataFrame. This is useful for quickly verifying that the data has been loaded correctly.</p>
<p><strong>Vietnamese:</strong> V√≠ d·ª• n√†y ch·ªâ ƒë∆°n gi·∫£n l√† t·∫£i d·ªØ li·ªáu v√† in ra m·ªôt v√†i h√†ng ƒë·∫ßu ti√™n v√† th√¥ng tin v·ªÅ DataFrame. ƒêi·ªÅu n√†y h·ªØu √≠ch ƒë·ªÉ nhanh ch√≥ng x√°c minh r·∫±ng d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i ch√≠nh x√°c.</p>
<p><strong>Example 2: Filtering and Descriptive Statistics (V√≠ d·ª• 2: L·ªçc v√† Th·ªëng k√™ M√¥ t·∫£)</strong></p>
<p>```python
import pandas as pd
import os</p>
<p>base_path = "../data"
csv_file_path = os.path.join(base_path, "chembl_data.csv")</p>
<p>try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"Error: File not found at {csv_file_path}.")
    exit()</p>
<p>df = df.dropna(subset=['standard_value']) # Drop rows with missing standard values
df = df[pd.to_numeric(df['standard_value'], errors='coerce').notna()] # Ensure standard_value is numeric after reading from csv
df['standard_value'] = pd.to_numeric(df['standard_value'])</p>
<p>df = df[df['standard_type'] == 'IC50'] # Filter for IC50 values
print(df['standard_value'].describe())  # Calculate and print descriptive statistics for IC50 values
```</p>
<p><strong>Explanation:</strong> This example filters the data to include only IC50 values and then calculates descriptive statistics (mean, standard deviation, min, max, etc.) for the <code>standard_value</code> column.</p>
<p><strong>Vietnamese:</strong> V√≠ d·ª• n√†y l·ªçc d·ªØ li·ªáu ƒë·ªÉ ch·ªâ bao g·ªìm c√°c gi√° tr·ªã IC50, sau ƒë√≥ t√≠nh to√°n th·ªëng k√™ m√¥ t·∫£ (gi√° tr·ªã trung b√¨nh, ƒë·ªô l·ªách chu·∫©n, min, max, v.v.) cho c·ªôt <code>standard_value</code>.</p>
<p><strong>Example 3: pIC50 Conversion and Visualization (V√≠ d·ª• 3: Chuy·ªÉn ƒë·ªïi pIC50 v√† Tr·ª±c quan h√≥a)</strong></p>
<p>```python
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt</p>
<p>base_path = "../data"
csv_file_path = os.path.join(base_path, "chembl_data.csv")</p>
<p>try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"Error: File not found at {csv_file_path}.")
    exit()</p>
<p>df = df.dropna(subset=['standard_value']) # Drop rows with missing standard values
df = df[pd.to_numeric(df['standard_value'], errors='coerce').notna()] # Ensure standard_value is numeric after reading from csv
df['standard_value'] = pd.to_numeric(df['standard_value'])
df = df[df['standard_type'] == 'IC50']
df['pIC50'] = -np.log10(df['standard_value'] * 1e-9)  # Convert IC50 to pIC50</p>
<p>plt.hist(df['pIC50'], bins=20) # Create a histogram of pIC50 values
plt.xlabel("pIC50")
plt.ylabel("Frequency")
plt.title("Distribution of pIC50 Values")
plt.show()
```</p>
<p><strong>Explanation:</strong>  This example converts IC50 values to pIC50 and then creates a histogram to visualize the distribution of pIC50 values.</p>
<p><strong>Vietnamese:</strong> V√≠ d·ª• n√†y chuy·ªÉn ƒë·ªïi c√°c gi√° tr·ªã IC50 th√†nh pIC50 v√† sau ƒë√≥ t·∫°o m·ªôt bi·ªÉu ƒë·ªì ƒë·ªÉ tr·ª±c quan h√≥a s·ª± ph√¢n ph·ªëi c·ªßa c√°c gi√° tr·ªã pIC50.</p>
<p><strong>Example 4: Calculating a Single Molecular Descriptor (V√≠ d·ª• 4: T√≠nh to√°n M√¥ t·∫£ Ph√¢n t·ª≠ ƒê∆°n)</strong></p>
<p>```python
import pandas as pd
import numpy as np
import os
from rdkit import Chem
from rdkit.Chem import Descriptors</p>
<p>base_path = "../data"
csv_file_path = os.path.join(base_path, "chembl_data.csv")</p>
<p>try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"Error: File not found at {csv_file_path}.")
    exit()</p>
<p>df = df.dropna(subset=['standard_value']) # Drop rows with missing standard values
df = df[pd.to_numeric(df['standard_value'], errors='coerce').notna()] # Ensure standard_value is numeric after reading from csv
df['standard_value'] = pd.to_numeric(df['standard_value'])
df = df[df['standard_type'] == 'IC50']
df['pIC50'] = -np.log10(df['standard_value'] * 1e-9)</p>
<h1>Fetch canonical smiles from molecule_dictionary.</h1>
<h1>You will need another query to fetch smiles and merge it into the dataframe</h1>
<h1>For the example, let's assume you have a 'smiles' column in your df</h1>
<h1>Example only - Generating random SMILES (replace with your actual smiles data)</h1>
<p>import random
df['smiles'] = [Chem.MolToSmiles(Chem.MolFromSmiles('C' * random.randint(1, 10))) for _ in range(len(df))]</p>
<p>def calculate_molecular_weight(smiles):
    try:
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return np.nan
        return Descriptors.MolWt(mol)
    except:
        return np.nan</p>
<p>df['molecular_weight'] = df['smiles'].apply(calculate_molecular_weight)
print(df[['smiles', 'molecular_weight']].head())
```</p>
<p><strong>Explanation:</strong> This example demonstrates how to use RDKit to calculate a single molecular descriptor (molecular weight) from SMILES strings. It includes error handling for invalid SMILES.  Remember to replace the example SMILES generation with <em>your actual SMILES data</em> from the database.</p>
<p><strong>Vietnamese:</strong> V√≠ d·ª• n√†y minh h·ªça c√°ch s·ª≠ d·ª•ng RDKit ƒë·ªÉ t√≠nh to√°n m·ªôt m√¥ t·∫£ ph√¢n t·ª≠ duy nh·∫•t (tr·ªçng l∆∞·ª£ng ph√¢n t·ª≠) t·ª´ chu·ªói SMILES. N√≥ bao g·ªìm x·ª≠ l√Ω l·ªói cho SMILES kh√¥ng h·ª£p l·ªá. H√£y nh·ªõ thay th·∫ø vi·ªác t·∫°o SMILES m·∫´u b·∫±ng <em>d·ªØ li·ªáu SMILES th·ª±c t·∫ø c·ªßa b·∫°n</em> t·ª´ c∆° s·ªü d·ªØ li·ªáu.</p>
<p><strong>Example 5: Correlation Analysis (V√≠ d·ª• 5: Ph√¢n t√≠ch T∆∞∆°ng quan)</strong></p>
<p>```python
import pandas as pd
import numpy as np
import os
from rdkit import Chem
from rdkit.Chem import Descriptors</p>
<p>base_path = "../data"
csv_file_path = os.path.join(base_path, "chembl_data.csv")</p>
<p>try:
    df = pd.read_csv(csv_file_path)
except FileNotFoundError:
    print(f"Error: File not found at {csv_file_path}.")
    exit()</p>
<p>df = df.dropna(subset=['standard_value']) # Drop rows with missing standard values
df = df[pd.to_numeric(df['standard_value'], errors='coerce').notna()] # Ensure standard_value is numeric after reading from csv
df['standard_value'] = pd.to_numeric(df['standard_value'])
df = df[df['standard_type'] == 'IC50']
df['pIC50'] = -np.log10(df['standard_value'] * 1e-9)</p>
<h1>Fetch canonical smiles from molecule_dictionary.</h1>
<h1>You will need another query to fetch smiles and merge it into the dataframe</h1>
<h1>For the example, let's assume you have a 'smiles' column in your df</h1>
<h1>Example only - Generating random SMILES (replace with your actual smiles data)</h1>
<p>import random
df['smiles'] = [Chem.MolToSmiles(Chem.MolFromSmiles('C' * random.randint(1, 10))) for _ in range(len(df))]</p>
<p>def calculate_molecular_weight(smiles):
    try:
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return np.nan
        return Descriptors.MolWt(mol)
    except:
        return np.nan</p>
<p>df['molecular_weight'] = df['smiles'].apply(calculate_molecular_weight)
df = df.dropna(subset=['molecular_weight'])  # Drop rows where molecular weight calculation failed</p>
<p>correlation = df['pIC50'].corr(df['molecular_weight']) # Calculate the correlation between pIC50 and molecular weight</p>
<p>print(f"Correlation between pIC50 and Molecular Weight: {correlation}")
```</p>
<p><strong>Explanation:</strong> This example calculates the Pearson correlation coefficient between pIC50 and molecular weight.  It first calculates the molecular weight using RDKit and then uses the <code>.corr()</code> method to find the correlation.</p>
<p><strong>Vietnamese:</strong> V√≠ d·ª• n√†y t√≠nh to√°n h·ªá s·ªë t∆∞∆°ng quan Pearson gi·ªØa pIC50 v√† tr·ªçng l∆∞·ª£ng ph√¢n t·ª≠. ƒê·∫ßu ti√™n, n√≥ t√≠nh to√°n tr·ªçng l∆∞·ª£ng ph√¢n t·ª≠ b·∫±ng RDKit, sau ƒë√≥ s·ª≠ d·ª•ng ph∆∞∆°ng th·ª©c <code>.corr()</code> ƒë·ªÉ t√¨m t∆∞∆°ng quan.</p>
<p><strong>Important Considerations:</strong></p>
<ul>
<li><strong>SMILES Data:</strong>  The most crucial part is getting the SMILES strings for your compounds. You'll need a separate SQL query to retrieve the SMILES from the <code>molecule_dictionary</code> table (using <code>md.molregno</code> to join) and then merge that data into your main DataFrame.  The example uses random SMILES <em>only</em> to make the code runnable without the full dataset.</li>
<li><strong>Data Validation:</strong> Thoroughly validate your data, especially the SMILES strings.  Invalid SMILES will cause errors in RDKit.</li>
<li><strong>Feature Selection:</strong>  When building models, carefully select the most relevant molecular descriptors.  Not all descriptors are useful or informative.</li>
<li><strong>Model Selection:</strong> Linear Regression is a simple starting point, but more complex models (e.g., Random Forest, Support Vector Machines) might provide better performance.</li>
<li><strong>Units:</strong>  Always pay close attention to units (e.g., nM for IC50).  Ensure consistency before performing calculations.</li>
</ul>
<p>This comprehensive guide should help you analyze your Chembl 35 data effectively. Remember to adapt the code to your specific needs and data.  Good luck with your project!</p>
        </body>
        </html>
        